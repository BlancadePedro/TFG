{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Detección de la Dislexia aplicando Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a desarrollar un modelo en Machine Learning que sea capaz de detectar si, tras contestar a 32 questiones y teniendo en cuenta el género, la lengua y la edad, una persona es disléxica o no. Cada modelo se va a entrenar y testear con dos datasets distintos: desktop.csv (Train) y tablet.csv (Test).\n",
    "\n",
    "\n",
    "Para ello se va a emplear Machine Learning, importando las librerías de python. Los algoritmos que se van a implementar son:\n",
    "1. K-Nearest Neighbors\n",
    "2. Logistic Regression\n",
    "3. Support Vector Machines\n",
    "4. Random Forest\n",
    "5. Tree Decision\n",
    "\n",
    "Y finalmente, en caso de que de tiempo:\n",
    "\n",
    "6. Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contiuación, se van a importar las librerías necesarias para desarrollar el modelo de Machine Learning:\n",
    "- Pandas: proporcina herramientas para el análisis de datos. Mediante esta herramienta se va leer el documento .csv donde se encuentran los datos y se van a manipular con el propósito de diseñar el modelo de Mchine Learning.\n",
    "- NumPy y Matplotlib: se emplearán para el análisis y la visualización de datos. NumPy permite realizar operación y  matemáticas y manejar datos numéricos de manera eficiente y efectiva. Por otro lado, Matplotlib permite crear gráficas para visualizar los datos de manera simple y clara. \n",
    "- Seaborn: al igual que Matplotlib, se trata de una librería de visualización de datos. Sin embargo, ofrece una visualización estadística, la cua va a ser de gran utilidad para analizar la distribución de los datos.\n",
    "- Warnings: gestionará las advertencias que surjan durante la ejecución del programa. En concreto se va a hacer uso de `warnings.filterwarnings('ignore')` consiguiendo ignorar las posibles advertencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, para el entrenamiento y el testeo de los distintos algoritmos de Machine Learning, se van a importar las librerías **Scikit-Learn** y para el manejo de desproporción entre casos positivos y negativos se va a importar **Imbalanced-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a comenzar leyendo los datos y exportándolos a la variable *data*, la cual va a contener la información con la que se va a construir el modelo. Mediante la librería **pandas** se va a acceder a la información, siendo capaz de:\n",
    "- Comprobar si existen valores nulos\n",
    "- Transformar todos los datos a valores numéricos\n",
    "- Gestionar los valores nulos\n",
    "- Analizar si hay variedad dentro de cada dataset\n",
    "\n",
    "La información que se va a obtener es:\n",
    "\n",
    "1. Genero (hombre o mujer)\n",
    "2. Lengua nativa es el español\n",
    "3. Lengua nativa distinta al español\n",
    "4. Edad \n",
    "5. Información relacionada con las preguntas\n",
    "6. Disléxico: sí o no\n",
    "\n",
    "La información relacionada con las preguntas contiene el número de clicks que se realizan en cada ejercicio (*Clicks*), diferenciando en respuestas correctas (*Hits*) e incorrectas (*Misses*). A su vez, se cuenta con el resultado final (*Score*), que se obtiene a partir de la cantidad de aciertos por cuestión, junto con la precisión de la respuesta (*Accuracy = Hits/Clicks*) y el ratio de fallo (*Missrate = Misses/Clicks*).\n",
    "\n",
    "Mediante estos valores se pretende predecir si una persona tiene dislexia o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/Dyt-desktop.csv\", delimiter=\";\")\n",
    "pd.set_option(\"display.max_columns\" , None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3644, 197)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look train dataset\n",
    "data.head()\n",
    "data.iloc[:, :10].dtypes\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha creado una función `prep_Data(df)`que toma como atributo de entrada un dataset y transforma los valores de las columnas *Gender, Nativelang, Otherlang y Dyslexia* en 0's o 1's, en función de su valor incial. De esta forma solo se trabajará con valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_Data(ds) :\n",
    "    #ds.column -> access to the column specified\n",
    "    #map() -> itarates through the column specified\n",
    "    ds['Gender']=ds.Gender.map({'Male': 0, 'Female': 1})\n",
    "    ds['Dyslexia']=ds.Dyslexia.map({'No': 0, 'Yes': 1})\n",
    "    ds['Nativelang']=ds.Nativelang.map({'No': 0, 'Yes': 1})\n",
    "    ds['Otherlang']=ds.Otherlang.map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_Data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nativelang</th>\n",
       "      <th>Otherlang</th>\n",
       "      <th>Age</th>\n",
       "      <th>Clicks1</th>\n",
       "      <th>Hits1</th>\n",
       "      <th>Misses1</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Accuracy1</th>\n",
       "      <th>Missrate1</th>\n",
       "      <th>Clicks2</th>\n",
       "      <th>Hits2</th>\n",
       "      <th>Misses2</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Accuracy2</th>\n",
       "      <th>Missrate2</th>\n",
       "      <th>Clicks3</th>\n",
       "      <th>Hits3</th>\n",
       "      <th>Misses3</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Accuracy3</th>\n",
       "      <th>Missrate3</th>\n",
       "      <th>Clicks4</th>\n",
       "      <th>Hits4</th>\n",
       "      <th>Misses4</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Accuracy4</th>\n",
       "      <th>Missrate4</th>\n",
       "      <th>Clicks5</th>\n",
       "      <th>Hits5</th>\n",
       "      <th>Misses5</th>\n",
       "      <th>Score5</th>\n",
       "      <th>Accuracy5</th>\n",
       "      <th>Missrate5</th>\n",
       "      <th>Clicks6</th>\n",
       "      <th>Hits6</th>\n",
       "      <th>Misses6</th>\n",
       "      <th>Score6</th>\n",
       "      <th>Accuracy6</th>\n",
       "      <th>Missrate6</th>\n",
       "      <th>Clicks7</th>\n",
       "      <th>Hits7</th>\n",
       "      <th>Misses7</th>\n",
       "      <th>Score7</th>\n",
       "      <th>Accuracy7</th>\n",
       "      <th>Missrate7</th>\n",
       "      <th>Clicks8</th>\n",
       "      <th>Hits8</th>\n",
       "      <th>Misses8</th>\n",
       "      <th>Score8</th>\n",
       "      <th>Accuracy8</th>\n",
       "      <th>Missrate8</th>\n",
       "      <th>Clicks9</th>\n",
       "      <th>Hits9</th>\n",
       "      <th>Misses9</th>\n",
       "      <th>Score9</th>\n",
       "      <th>Accuracy9</th>\n",
       "      <th>Missrate9</th>\n",
       "      <th>Clicks10</th>\n",
       "      <th>Hits10</th>\n",
       "      <th>Misses10</th>\n",
       "      <th>Score10</th>\n",
       "      <th>Accuracy10</th>\n",
       "      <th>Missrate10</th>\n",
       "      <th>Clicks11</th>\n",
       "      <th>Hits11</th>\n",
       "      <th>Misses11</th>\n",
       "      <th>Score11</th>\n",
       "      <th>Accuracy11</th>\n",
       "      <th>Missrate11</th>\n",
       "      <th>Clicks12</th>\n",
       "      <th>Hits12</th>\n",
       "      <th>Misses12</th>\n",
       "      <th>Score12</th>\n",
       "      <th>Accuracy12</th>\n",
       "      <th>Missrate12</th>\n",
       "      <th>Clicks13</th>\n",
       "      <th>Hits13</th>\n",
       "      <th>Misses13</th>\n",
       "      <th>Score13</th>\n",
       "      <th>Accuracy13</th>\n",
       "      <th>Missrate13</th>\n",
       "      <th>Clicks14</th>\n",
       "      <th>Hits14</th>\n",
       "      <th>Misses14</th>\n",
       "      <th>Score14</th>\n",
       "      <th>Accuracy14</th>\n",
       "      <th>Missrate14</th>\n",
       "      <th>Clicks15</th>\n",
       "      <th>Hits15</th>\n",
       "      <th>Misses15</th>\n",
       "      <th>Score15</th>\n",
       "      <th>Accuracy15</th>\n",
       "      <th>Missrate15</th>\n",
       "      <th>Clicks16</th>\n",
       "      <th>Hits16</th>\n",
       "      <th>Misses16</th>\n",
       "      <th>Score16</th>\n",
       "      <th>Accuracy16</th>\n",
       "      <th>Missrate16</th>\n",
       "      <th>Clicks17</th>\n",
       "      <th>Hits17</th>\n",
       "      <th>Misses17</th>\n",
       "      <th>Score17</th>\n",
       "      <th>Accuracy17</th>\n",
       "      <th>Missrate17</th>\n",
       "      <th>Clicks18</th>\n",
       "      <th>Hits18</th>\n",
       "      <th>Misses18</th>\n",
       "      <th>Score18</th>\n",
       "      <th>Accuracy18</th>\n",
       "      <th>Missrate18</th>\n",
       "      <th>Clicks19</th>\n",
       "      <th>Hits19</th>\n",
       "      <th>Misses19</th>\n",
       "      <th>Score19</th>\n",
       "      <th>Accuracy19</th>\n",
       "      <th>Missrate19</th>\n",
       "      <th>Clicks20</th>\n",
       "      <th>Hits20</th>\n",
       "      <th>Misses20</th>\n",
       "      <th>Score20</th>\n",
       "      <th>Accuracy20</th>\n",
       "      <th>Missrate20</th>\n",
       "      <th>Clicks21</th>\n",
       "      <th>Hits21</th>\n",
       "      <th>Misses21</th>\n",
       "      <th>Score21</th>\n",
       "      <th>Accuracy21</th>\n",
       "      <th>Missrate21</th>\n",
       "      <th>Clicks22</th>\n",
       "      <th>Hits22</th>\n",
       "      <th>Misses22</th>\n",
       "      <th>Score22</th>\n",
       "      <th>Accuracy22</th>\n",
       "      <th>Missrate22</th>\n",
       "      <th>Clicks23</th>\n",
       "      <th>Hits23</th>\n",
       "      <th>Misses23</th>\n",
       "      <th>Score23</th>\n",
       "      <th>Accuracy23</th>\n",
       "      <th>Missrate23</th>\n",
       "      <th>Clicks24</th>\n",
       "      <th>Hits24</th>\n",
       "      <th>Misses24</th>\n",
       "      <th>Score24</th>\n",
       "      <th>Accuracy24</th>\n",
       "      <th>Missrate24</th>\n",
       "      <th>Clicks25</th>\n",
       "      <th>Hits25</th>\n",
       "      <th>Misses25</th>\n",
       "      <th>Score25</th>\n",
       "      <th>Accuracy25</th>\n",
       "      <th>Missrate25</th>\n",
       "      <th>Clicks26</th>\n",
       "      <th>Hits26</th>\n",
       "      <th>Misses26</th>\n",
       "      <th>Score26</th>\n",
       "      <th>Accuracy26</th>\n",
       "      <th>Missrate26</th>\n",
       "      <th>Clicks27</th>\n",
       "      <th>Hits27</th>\n",
       "      <th>Misses27</th>\n",
       "      <th>Score27</th>\n",
       "      <th>Accuracy27</th>\n",
       "      <th>Missrate27</th>\n",
       "      <th>Clicks28</th>\n",
       "      <th>Hits28</th>\n",
       "      <th>Misses28</th>\n",
       "      <th>Score28</th>\n",
       "      <th>Accuracy28</th>\n",
       "      <th>Missrate28</th>\n",
       "      <th>Clicks29</th>\n",
       "      <th>Hits29</th>\n",
       "      <th>Misses29</th>\n",
       "      <th>Score29</th>\n",
       "      <th>Accuracy29</th>\n",
       "      <th>Missrate29</th>\n",
       "      <th>Clicks30</th>\n",
       "      <th>Hits30</th>\n",
       "      <th>Misses30</th>\n",
       "      <th>Score30</th>\n",
       "      <th>Accuracy30</th>\n",
       "      <th>Missrate30</th>\n",
       "      <th>Clicks31</th>\n",
       "      <th>Hits31</th>\n",
       "      <th>Misses31</th>\n",
       "      <th>Score31</th>\n",
       "      <th>Accuracy31</th>\n",
       "      <th>Missrate31</th>\n",
       "      <th>Clicks32</th>\n",
       "      <th>Hits32</th>\n",
       "      <th>Misses32</th>\n",
       "      <th>Score32</th>\n",
       "      <th>Accuracy32</th>\n",
       "      <th>Missrate32</th>\n",
       "      <th>Dyslexia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Nativelang  Otherlang  Age  Clicks1  Hits1  Misses1  Score1  \\\n",
       "0       0           0          1    7       10     10        0      10   \n",
       "1       1           1          1   13       12     12        0      12   \n",
       "2       1           0          1    7        6      6        0       6   \n",
       "3       1           0          1    7        0      0        0       0   \n",
       "4       1           0          1    8        4      4        0       4   \n",
       "\n",
       "   Accuracy1  Missrate1  Clicks2  Hits2  Misses2  Score2  Accuracy2  \\\n",
       "0        1.0        0.0        5      5        0       5        1.0   \n",
       "1        1.0        0.0       11     11        0      11        1.0   \n",
       "2        1.0        0.0        6      6        0       6        1.0   \n",
       "3        0.0        0.0        0      0        0       0        0.0   \n",
       "4        1.0        0.0        8      8        0       8        1.0   \n",
       "\n",
       "   Missrate2  Clicks3  Hits3  Misses3  Score3  Accuracy3  Missrate3  Clicks4  \\\n",
       "0        0.0        6      6        0       6        1.0        0.0        2   \n",
       "1        0.0       10     10        0      10        1.0        0.0        4   \n",
       "2        0.0        6      6        0       6        1.0        0.0        3   \n",
       "3        0.0        1      1        0       1        1.0        0.0        0   \n",
       "4        0.0        5      5        0       5        1.0        0.0        5   \n",
       "\n",
       "   Hits4  Misses4  Score4  Accuracy4  Missrate4  Clicks5  Hits5  Misses5  \\\n",
       "0      2        0       2        1.0        0.0        3      3        0   \n",
       "1      4        0       4        1.0        0.0        5      5        0   \n",
       "2      3        0       3        1.0        0.0        4      4        0   \n",
       "3      0        0       0        0.0        0.0        2      1        1   \n",
       "4      2        3       2        0.4        0.6        4      4        0   \n",
       "\n",
       "   Score5  Accuracy5  Missrate5  Clicks6  Hits6  Misses6  Score6  Accuracy6  \\\n",
       "0       3        1.0        0.0        4      1        3       1       0.25   \n",
       "1       5        1.0        0.0        5      5        0       5       1.00   \n",
       "2       4        1.0        0.0        2      2        0       2       1.00   \n",
       "3       1        0.5        0.5        0      0        0       0       0.00   \n",
       "4       4        1.0        0.0        5      3        2       3       0.60   \n",
       "\n",
       "   Missrate6  Clicks7  Hits7  Misses7  Score7  Accuracy7  Missrate7  Clicks8  \\\n",
       "0       0.75        5      5        0       5   1.000000   0.000000        4   \n",
       "1       0.00        5      4        1       4   0.800000   0.200000        6   \n",
       "2       0.00        7      5        2       5   0.714286   0.285714        5   \n",
       "3       0.00        4      0        4       0   0.000000   1.000000        2   \n",
       "4       0.40        6      5        1       5   0.833333   0.166667        6   \n",
       "\n",
       "   Hits8  Misses8  Score8  Accuracy8  Missrate8  Clicks9  Hits9  Misses9  \\\n",
       "0      3        1       3   0.750000   0.250000        1      0        1   \n",
       "1      5        1       5   0.833333   0.166667        5      4        1   \n",
       "2      3        2       3   0.600000   0.400000        3      3        0   \n",
       "3      0        2       0   0.000000   1.000000        3      0        3   \n",
       "4      4        2       4   0.666667   0.333333        5      3        2   \n",
       "\n",
       "   Score9  Accuracy9  Missrate9  Clicks10  Hits10  Misses10  Score10  \\\n",
       "0       0        0.0        1.0         1       1         0        1   \n",
       "1       4        0.8        0.2        10      10         0       10   \n",
       "2       3        1.0        0.0         7       5         2        5   \n",
       "3       0        0.0        1.0         2       1         1        1   \n",
       "4       3        0.6        0.4         7       7         0        7   \n",
       "\n",
       "   Accuracy10  Missrate10  Clicks11  Hits11  Misses11  Score11  Accuracy11  \\\n",
       "0    1.000000    0.000000         3       1         2        1    0.333333   \n",
       "1    1.000000    0.000000         5       4         1        4    0.800000   \n",
       "2    0.714286    0.285714         6       5         1        5    0.833333   \n",
       "3    0.500000    0.500000         3       0         3        0    0.000000   \n",
       "4    1.000000    0.000000         5       4         1        4    0.800000   \n",
       "\n",
       "   Missrate11  Clicks12  Hits12  Misses12  Score12  Accuracy12  Missrate12  \\\n",
       "0    0.666667         3       3         0        3         1.0         0.0   \n",
       "1    0.200000         5       5         0        5         1.0         0.0   \n",
       "2    0.166667         6       6         0        6         1.0         0.0   \n",
       "3    1.000000         2       0         2        0         0.0         1.0   \n",
       "4    0.200000         3       3         0        3         1.0         0.0   \n",
       "\n",
       "   Clicks13  Hits13  Misses13  Score13  Accuracy13  Missrate13  Clicks14  \\\n",
       "0         3       3         0        3         1.0         0.0         4   \n",
       "1         4       4         0        4         1.0         0.0        10   \n",
       "2         3       3         0        3         1.0         0.0         6   \n",
       "3         0       0         0        0         0.0         0.0         5   \n",
       "4         4       4         0        4         1.0         0.0         2   \n",
       "\n",
       "   Hits14  Misses14  Score14  Accuracy14  Missrate14  Clicks15  Hits15  \\\n",
       "0       4         0        4         1.0         0.0         2       2   \n",
       "1      10         0       10         1.0         0.0         5       5   \n",
       "2       6         0        6         1.0         0.0         3       3   \n",
       "3       5         0        5         1.0         0.0         4       4   \n",
       "4       2         0        2         1.0         0.0         3       3   \n",
       "\n",
       "   Misses15  Score15  Accuracy15  Missrate15  Clicks16  Hits16  Misses16  \\\n",
       "0         0        2         1.0         0.0         2       2         0   \n",
       "1         0        5         1.0         0.0         4       4         0   \n",
       "2         0        3         1.0         0.0         4       4         0   \n",
       "3         0        4         1.0         0.0         4       4         0   \n",
       "4         0        3         1.0         0.0         3       3         0   \n",
       "\n",
       "   Score16  Accuracy16  Missrate16  Clicks17  Hits17  Misses17  Score17  \\\n",
       "0        2         1.0         0.0         3       3         0        3   \n",
       "1        4         1.0         0.0         4       4         0        4   \n",
       "2        4         1.0         0.0         2       2         0        2   \n",
       "3        4         1.0         0.0         3       3         0        3   \n",
       "4        3         1.0         0.0         4       4         0        4   \n",
       "\n",
       "   Accuracy17  Missrate17  Clicks18  Hits18  Misses18  Score18  Accuracy18  \\\n",
       "0         1.0         0.0         2       2         0        2        1.00   \n",
       "1         1.0         0.0         4       3         1        3        0.75   \n",
       "2         1.0         0.0         2       1         1        1        0.50   \n",
       "3         1.0         0.0         0       0         0        0        0.00   \n",
       "4         1.0         0.0         5       5         0        5        1.00   \n",
       "\n",
       "   Missrate18  Clicks19  Hits19  Misses19  Score19  Accuracy19  Missrate19  \\\n",
       "0        0.00         4       3         1        3    0.750000    0.250000   \n",
       "1        0.25         8       3         5        3  375.000000  625.000000   \n",
       "2        0.50         5       4         1        4    0.800000    0.200000   \n",
       "3        0.00         6       1         5        1    0.166667    0.833333   \n",
       "4        0.00         4       3         1        3    0.750000    0.250000   \n",
       "\n",
       "   Clicks20  Hits20  Misses20  Score20  Accuracy20  Missrate20  Clicks21  \\\n",
       "0         5       1         4        1    0.200000    0.800000         3   \n",
       "1         3       1         2        1    0.333333    0.666667         3   \n",
       "2         6       1         5        1    0.166667    0.833333         6   \n",
       "3         1       0         1        0    0.000000    1.000000         1   \n",
       "4         2       2         0        2    1.000000    0.000000         3   \n",
       "\n",
       "   Hits21  Misses21  Score21  Accuracy21  Missrate21  Clicks22  Hits22  \\\n",
       "0       1         2        1    0.333333    0.666667         4       1   \n",
       "1       1         2        1    0.333333    0.666667         9       7   \n",
       "2       3         3        3    0.500000    0.500000         6       5   \n",
       "3       0         1        0    0.000000    1.000000         5       2   \n",
       "4       1         2        1    0.333333    0.666667         7       5   \n",
       "\n",
       "   Misses22  Score22  Accuracy22  Missrate22  Clicks23  Hits23  Misses23  \\\n",
       "0         3        1    0.250000    0.750000         4       3         1   \n",
       "1         2        7    0.777778    0.222222         6       5         1   \n",
       "2         1        5    0.833333    0.166667         5       3         2   \n",
       "3         3        2    0.400000    0.600000         4       3         1   \n",
       "4         2        5    0.714286    0.285714         5       2         3   \n",
       "\n",
       "   Score23  Accuracy23  Missrate23  Clicks24  Hits24  Misses24  Score24  \\\n",
       "0        3    0.750000    0.250000         3       2         1        2   \n",
       "1        5    0.833333    0.166667         3       2         1        2   \n",
       "2        3    0.600000    0.400000         4       3         1        3   \n",
       "3        3    0.750000    0.250000         3       3         0        3   \n",
       "4        2    0.400000    0.600000         4       2         2        2   \n",
       "\n",
       "   Accuracy24  Missrate24  Clicks25  Hits25  Misses25  Score25  Accuracy25  \\\n",
       "0    0.666667    0.333333         3       3         0        3         1.0   \n",
       "1    0.666667    0.333333         5       5         0        5         1.0   \n",
       "2    0.750000    0.250000         5       4         1        4         0.8   \n",
       "3    1.000000    0.000000         3       3         0        3         1.0   \n",
       "4    0.500000    0.500000         4       4         0        4         1.0   \n",
       "\n",
       "   Missrate25  Clicks26  Hits26  Misses26  Score26  Accuracy26  Missrate26  \\\n",
       "0         0.0         5       3         2        3    0.600000    0.400000   \n",
       "1         0.0        12       8         4        8    0.666667    0.333333   \n",
       "2         0.2         5       2         3        2    0.400000    0.600000   \n",
       "3         0.0         2       2         0        2    1.000000    0.000000   \n",
       "4         0.0         9       6         3        6    0.666667    0.333333   \n",
       "\n",
       "   Clicks27  Hits27  Misses27  Score27  Accuracy27  Missrate27  Clicks28  \\\n",
       "0         9       1         1        1    0.111111    0.111111         6   \n",
       "1        16       2         1        2  125.000000    0.062500         9   \n",
       "2        17       2         1        2    0.117647    0.058824        13   \n",
       "3         4       0         0        0    0.000000    0.000000         6   \n",
       "4        15       1         2        1    0.066667    0.133333        13   \n",
       "\n",
       "   Hits28  Misses28  Score28  Accuracy28  Missrate28  Clicks29  Hits29  \\\n",
       "0       2         0        2    0.333333    0.000000         4       1   \n",
       "1       2         1        2    0.222222    0.111111         5       0   \n",
       "2       3         1        3    0.230769    0.076923         5       0   \n",
       "3       2         0        2    0.333333    0.000000         1       0   \n",
       "4       4         0        4    0.307692    0.000000         4       1   \n",
       "\n",
       "   Misses29  Score29  Accuracy29  Missrate29  Clicks30  Hits30  Misses30  \\\n",
       "0         1        1        0.25        0.25        14       1         2   \n",
       "1         2        0        0.00        0.40        17       2         2   \n",
       "2         2        0        0.00        0.40        17       1         3   \n",
       "3         1        0        0.00        1.00         8       0         1   \n",
       "4         1        1        0.25        0.25        17       0         4   \n",
       "\n",
       "   Score30  Accuracy30  Missrate30  Clicks31  Hits31  Misses31  Score31  \\\n",
       "0        1    0.071429    0.142857        18       0         0        0   \n",
       "1        2    0.117647    0.117647        35       4         0        4   \n",
       "2        1    0.058824    0.176471        35       4         0        4   \n",
       "3        0    0.000000  125.000000         4       0         0        0   \n",
       "4        0    0.000000    0.235294        40       1         2        1   \n",
       "\n",
       "   Accuracy31  Missrate31  Clicks32  Hits32  Misses32  Score32  Accuracy32  \\\n",
       "0    0.000000        0.00        17       2         0        2    0.117647   \n",
       "1    0.114286        0.00        26       2         2        2    0.076923   \n",
       "2    0.114286        0.00        26       1         3        1    0.038462   \n",
       "3    0.000000        0.00         1       0         0        0    0.000000   \n",
       "4   25.000000        0.05        26       2         2        2    0.076923   \n",
       "\n",
       "   Missrate32  Dyslexia  \n",
       "0    0.000000         0  \n",
       "1    0.076923         1  \n",
       "2    0.115385         0  \n",
       "3    0.000000         0  \n",
       "4    0.076923         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras transformar todos los valores del dataframe en numéricos, se va a asegurar que todos los valores sean tipo flotantes mediante la instrucción: `dataset.apply(lambda x: x.astype('float', errors='ignore'))` donde se aplica el cambio de *int* a *flot* mediante la función `astype()` dentro de una función *lambda* que recorre cada columna, accediendo a su contenido y modificándolo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.astype('float', errors='ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se haya transformado el tipo de valor con el que se está trabajando se va a comprobar que solo contiene valores del tipo *float64*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data type of each column\n",
    "for col in data.columns:\n",
    "    if data[col].dtypes != \"float64\":\n",
    "        print(\"Column {} is not a float, it is {}\".format(col, data[col].dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez exportados los datos se va a comporbar si hay valores nulos mediante la función `[col for col in test_df.columns if train_df[col].isnull().any()]`. \n",
    "- Mediante el bucle `for col in` se van a recorrer todas las columna y acceder a sus valores.  \n",
    "- Mediante el condicional `if train_df[col].isnull().any()`se va a comprobar si alguno de los datos de la columna que se está analizando es nulo o no. \n",
    "\n",
    "En caso de que se encuentre un valor nulo, el atributo de salida `col` tomará el valor de dicha columna y se añadirá a una lista (función entre `[ ]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = [np.number])\n",
    "data.isnull().values.any()\n",
    "data_null_values = data.isna().sum().sum()\n",
    "data_null_col = [col for col in data.columns if data[col].isnull().any()]\n",
    "data_null_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a prescindir de todos los valores mayores a uno en las columnas *Accuracy* y *Missrate*. Los valores mencionados representan porcentajes, por lo que no pueden superar la unidad, sin embargo, si se estudia en detalle cada variable existen valores que no cumplen este requisito dando lugar a error si no se corrige."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_manually(df):\n",
    "    print(\"Old Shape: \", df.shape)\n",
    "    \n",
    "    #Accuracy and Missrate\n",
    "    for i in range(int(df.shape[1]/6)):\n",
    "        col_acc_rate = df.columns[8+6*i:10+6*i]\n",
    "        for j in col_acc_rate:\n",
    "            df.drop(df[df[j] > 1].index, inplace=True)\n",
    "    print(\"New Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Shape:  (3644, 197)\n",
      "New Shape:  (2051, 197)\n"
     ]
    }
   ],
   "source": [
    "remove_outliers_manually(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se va a proceder con la eliminación de los outliers, es decir, se va a prescindir de aquellos valores que se consideren anómalos. Para ello se van a emplear dos funciones *.describe()* y *sns.distplot(col)*. La primera  se utiliza para representar la distribución de los datos en un gráfico. Va a permitir visualizar la forma en que los datos están distribuidos en los datasets disponibles. A simple vista, se puede identificar como hay valores máximos que están muy alejados del percentil 75, por lo que se puede intuir que se trata de un outlier.\n",
    "\n",
    "A su vez, la función `countplot` es útil para identificar cuantos valores positivos y negativos hay de dislexia. Se va a representar visualmente, permitiendo comparar si la muestra que se está usando es representativa de la población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nativelang</th>\n",
       "      <th>Otherlang</th>\n",
       "      <th>Age</th>\n",
       "      <th>Clicks1</th>\n",
       "      <th>Hits1</th>\n",
       "      <th>Misses1</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Accuracy1</th>\n",
       "      <th>Missrate1</th>\n",
       "      <th>Clicks2</th>\n",
       "      <th>Hits2</th>\n",
       "      <th>Misses2</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Accuracy2</th>\n",
       "      <th>Missrate2</th>\n",
       "      <th>Clicks3</th>\n",
       "      <th>Hits3</th>\n",
       "      <th>Misses3</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Accuracy3</th>\n",
       "      <th>Missrate3</th>\n",
       "      <th>Clicks4</th>\n",
       "      <th>Hits4</th>\n",
       "      <th>Misses4</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Accuracy4</th>\n",
       "      <th>Missrate4</th>\n",
       "      <th>Clicks5</th>\n",
       "      <th>Hits5</th>\n",
       "      <th>Misses5</th>\n",
       "      <th>Score5</th>\n",
       "      <th>Accuracy5</th>\n",
       "      <th>Missrate5</th>\n",
       "      <th>Clicks6</th>\n",
       "      <th>Hits6</th>\n",
       "      <th>Misses6</th>\n",
       "      <th>Score6</th>\n",
       "      <th>Accuracy6</th>\n",
       "      <th>Missrate6</th>\n",
       "      <th>Clicks7</th>\n",
       "      <th>Hits7</th>\n",
       "      <th>Misses7</th>\n",
       "      <th>Score7</th>\n",
       "      <th>Accuracy7</th>\n",
       "      <th>Missrate7</th>\n",
       "      <th>Clicks8</th>\n",
       "      <th>Hits8</th>\n",
       "      <th>Misses8</th>\n",
       "      <th>Score8</th>\n",
       "      <th>Accuracy8</th>\n",
       "      <th>Missrate8</th>\n",
       "      <th>Clicks9</th>\n",
       "      <th>Hits9</th>\n",
       "      <th>Misses9</th>\n",
       "      <th>Score9</th>\n",
       "      <th>Accuracy9</th>\n",
       "      <th>Missrate9</th>\n",
       "      <th>Clicks10</th>\n",
       "      <th>Hits10</th>\n",
       "      <th>Misses10</th>\n",
       "      <th>Score10</th>\n",
       "      <th>Accuracy10</th>\n",
       "      <th>Missrate10</th>\n",
       "      <th>Clicks11</th>\n",
       "      <th>Hits11</th>\n",
       "      <th>Misses11</th>\n",
       "      <th>Score11</th>\n",
       "      <th>Accuracy11</th>\n",
       "      <th>Missrate11</th>\n",
       "      <th>Clicks12</th>\n",
       "      <th>Hits12</th>\n",
       "      <th>Misses12</th>\n",
       "      <th>Score12</th>\n",
       "      <th>Accuracy12</th>\n",
       "      <th>Missrate12</th>\n",
       "      <th>Clicks13</th>\n",
       "      <th>Hits13</th>\n",
       "      <th>Misses13</th>\n",
       "      <th>Score13</th>\n",
       "      <th>Accuracy13</th>\n",
       "      <th>Missrate13</th>\n",
       "      <th>Clicks14</th>\n",
       "      <th>Hits14</th>\n",
       "      <th>Misses14</th>\n",
       "      <th>Score14</th>\n",
       "      <th>Accuracy14</th>\n",
       "      <th>Missrate14</th>\n",
       "      <th>Clicks15</th>\n",
       "      <th>Hits15</th>\n",
       "      <th>Misses15</th>\n",
       "      <th>Score15</th>\n",
       "      <th>Accuracy15</th>\n",
       "      <th>Missrate15</th>\n",
       "      <th>Clicks16</th>\n",
       "      <th>Hits16</th>\n",
       "      <th>Misses16</th>\n",
       "      <th>Score16</th>\n",
       "      <th>Accuracy16</th>\n",
       "      <th>Missrate16</th>\n",
       "      <th>Clicks17</th>\n",
       "      <th>Hits17</th>\n",
       "      <th>Misses17</th>\n",
       "      <th>Score17</th>\n",
       "      <th>Accuracy17</th>\n",
       "      <th>Missrate17</th>\n",
       "      <th>Clicks18</th>\n",
       "      <th>Hits18</th>\n",
       "      <th>Misses18</th>\n",
       "      <th>Score18</th>\n",
       "      <th>Accuracy18</th>\n",
       "      <th>Missrate18</th>\n",
       "      <th>Clicks19</th>\n",
       "      <th>Hits19</th>\n",
       "      <th>Misses19</th>\n",
       "      <th>Score19</th>\n",
       "      <th>Accuracy19</th>\n",
       "      <th>Missrate19</th>\n",
       "      <th>Clicks20</th>\n",
       "      <th>Hits20</th>\n",
       "      <th>Misses20</th>\n",
       "      <th>Score20</th>\n",
       "      <th>Accuracy20</th>\n",
       "      <th>Missrate20</th>\n",
       "      <th>Clicks21</th>\n",
       "      <th>Hits21</th>\n",
       "      <th>Misses21</th>\n",
       "      <th>Score21</th>\n",
       "      <th>Accuracy21</th>\n",
       "      <th>Missrate21</th>\n",
       "      <th>Clicks22</th>\n",
       "      <th>Hits22</th>\n",
       "      <th>Misses22</th>\n",
       "      <th>Score22</th>\n",
       "      <th>Accuracy22</th>\n",
       "      <th>Missrate22</th>\n",
       "      <th>Clicks23</th>\n",
       "      <th>Hits23</th>\n",
       "      <th>Misses23</th>\n",
       "      <th>Score23</th>\n",
       "      <th>Accuracy23</th>\n",
       "      <th>Missrate23</th>\n",
       "      <th>Clicks24</th>\n",
       "      <th>Hits24</th>\n",
       "      <th>Misses24</th>\n",
       "      <th>Score24</th>\n",
       "      <th>Accuracy24</th>\n",
       "      <th>Missrate24</th>\n",
       "      <th>Clicks25</th>\n",
       "      <th>Hits25</th>\n",
       "      <th>Misses25</th>\n",
       "      <th>Score25</th>\n",
       "      <th>Accuracy25</th>\n",
       "      <th>Missrate25</th>\n",
       "      <th>Clicks26</th>\n",
       "      <th>Hits26</th>\n",
       "      <th>Misses26</th>\n",
       "      <th>Score26</th>\n",
       "      <th>Accuracy26</th>\n",
       "      <th>Missrate26</th>\n",
       "      <th>Clicks27</th>\n",
       "      <th>Hits27</th>\n",
       "      <th>Misses27</th>\n",
       "      <th>Score27</th>\n",
       "      <th>Accuracy27</th>\n",
       "      <th>Missrate27</th>\n",
       "      <th>Clicks28</th>\n",
       "      <th>Hits28</th>\n",
       "      <th>Misses28</th>\n",
       "      <th>Score28</th>\n",
       "      <th>Accuracy28</th>\n",
       "      <th>Missrate28</th>\n",
       "      <th>Clicks29</th>\n",
       "      <th>Hits29</th>\n",
       "      <th>Misses29</th>\n",
       "      <th>Score29</th>\n",
       "      <th>Accuracy29</th>\n",
       "      <th>Missrate29</th>\n",
       "      <th>Clicks30</th>\n",
       "      <th>Hits30</th>\n",
       "      <th>Misses30</th>\n",
       "      <th>Score30</th>\n",
       "      <th>Accuracy30</th>\n",
       "      <th>Missrate30</th>\n",
       "      <th>Clicks31</th>\n",
       "      <th>Hits31</th>\n",
       "      <th>Misses31</th>\n",
       "      <th>Score31</th>\n",
       "      <th>Accuracy31</th>\n",
       "      <th>Missrate31</th>\n",
       "      <th>Clicks32</th>\n",
       "      <th>Hits32</th>\n",
       "      <th>Misses32</th>\n",
       "      <th>Score32</th>\n",
       "      <th>Accuracy32</th>\n",
       "      <th>Missrate32</th>\n",
       "      <th>Dyslexia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.00000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.00000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.00000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.498294</td>\n",
       "      <td>0.266212</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>10.153584</td>\n",
       "      <td>5.691858</td>\n",
       "      <td>3.725012</td>\n",
       "      <td>0.663091</td>\n",
       "      <td>3.78352</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.140790</td>\n",
       "      <td>8.663091</td>\n",
       "      <td>4.777182</td>\n",
       "      <td>0.739152</td>\n",
       "      <td>4.829839</td>\n",
       "      <td>0.611531</td>\n",
       "      <td>0.091236</td>\n",
       "      <td>9.158947</td>\n",
       "      <td>3.969283</td>\n",
       "      <td>0.557777</td>\n",
       "      <td>4.056070</td>\n",
       "      <td>0.579409</td>\n",
       "      <td>0.073146</td>\n",
       "      <td>5.083374</td>\n",
       "      <td>3.295466</td>\n",
       "      <td>1.787908</td>\n",
       "      <td>4.051195</td>\n",
       "      <td>0.689115</td>\n",
       "      <td>0.295770</td>\n",
       "      <td>5.334959</td>\n",
       "      <td>4.10824</td>\n",
       "      <td>1.226719</td>\n",
       "      <td>4.181863</td>\n",
       "      <td>0.797373</td>\n",
       "      <td>0.182646</td>\n",
       "      <td>5.560702</td>\n",
       "      <td>4.338859</td>\n",
       "      <td>1.221843</td>\n",
       "      <td>4.357874</td>\n",
       "      <td>0.749269</td>\n",
       "      <td>0.235631</td>\n",
       "      <td>5.639688</td>\n",
       "      <td>5.105802</td>\n",
       "      <td>0.533886</td>\n",
       "      <td>5.128230</td>\n",
       "      <td>0.843841</td>\n",
       "      <td>0.107441</td>\n",
       "      <td>4.804973</td>\n",
       "      <td>3.854217</td>\n",
       "      <td>0.950756</td>\n",
       "      <td>3.863481</td>\n",
       "      <td>0.823412</td>\n",
       "      <td>0.165872</td>\n",
       "      <td>4.198927</td>\n",
       "      <td>3.347148</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>3.356412</td>\n",
       "      <td>0.752922</td>\n",
       "      <td>0.201739</td>\n",
       "      <td>7.019015</td>\n",
       "      <td>6.283764</td>\n",
       "      <td>0.735251</td>\n",
       "      <td>6.308142</td>\n",
       "      <td>0.857771</td>\n",
       "      <td>0.125657</td>\n",
       "      <td>4.574354</td>\n",
       "      <td>3.839590</td>\n",
       "      <td>0.734764</td>\n",
       "      <td>3.873720</td>\n",
       "      <td>0.801198</td>\n",
       "      <td>0.182732</td>\n",
       "      <td>3.903949</td>\n",
       "      <td>3.297903</td>\n",
       "      <td>0.606046</td>\n",
       "      <td>3.308630</td>\n",
       "      <td>0.851060</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>3.711360</td>\n",
       "      <td>3.290102</td>\n",
       "      <td>0.421258</td>\n",
       "      <td>3.290102</td>\n",
       "      <td>0.875646</td>\n",
       "      <td>0.080965</td>\n",
       "      <td>5.215505</td>\n",
       "      <td>4.165773</td>\n",
       "      <td>1.049732</td>\n",
       "      <td>4.183325</td>\n",
       "      <td>0.789527</td>\n",
       "      <td>0.185119</td>\n",
       "      <td>4.337396</td>\n",
       "      <td>3.942467</td>\n",
       "      <td>0.394929</td>\n",
       "      <td>3.964895</td>\n",
       "      <td>0.871217</td>\n",
       "      <td>0.087828</td>\n",
       "      <td>3.891273</td>\n",
       "      <td>3.076060</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>3.082886</td>\n",
       "      <td>0.795510</td>\n",
       "      <td>0.168415</td>\n",
       "      <td>3.659678</td>\n",
       "      <td>3.180887</td>\n",
       "      <td>0.478791</td>\n",
       "      <td>3.185275</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.102639</td>\n",
       "      <td>4.063871</td>\n",
       "      <td>3.01999</td>\n",
       "      <td>1.043881</td>\n",
       "      <td>3.025353</td>\n",
       "      <td>0.744595</td>\n",
       "      <td>0.221290</td>\n",
       "      <td>4.927353</td>\n",
       "      <td>2.844466</td>\n",
       "      <td>2.082886</td>\n",
       "      <td>2.861043</td>\n",
       "      <td>0.600672</td>\n",
       "      <td>0.388129</td>\n",
       "      <td>4.990249</td>\n",
       "      <td>2.302292</td>\n",
       "      <td>2.687957</td>\n",
       "      <td>2.311068</td>\n",
       "      <td>0.470582</td>\n",
       "      <td>0.514308</td>\n",
       "      <td>4.168211</td>\n",
       "      <td>1.737201</td>\n",
       "      <td>2.431009</td>\n",
       "      <td>1.747440</td>\n",
       "      <td>0.479720</td>\n",
       "      <td>0.498832</td>\n",
       "      <td>5.178450</td>\n",
       "      <td>3.843003</td>\n",
       "      <td>1.335446</td>\n",
       "      <td>3.847879</td>\n",
       "      <td>0.728310</td>\n",
       "      <td>0.262924</td>\n",
       "      <td>4.780595</td>\n",
       "      <td>3.368113</td>\n",
       "      <td>1.412482</td>\n",
       "      <td>3.379815</td>\n",
       "      <td>0.729324</td>\n",
       "      <td>0.253645</td>\n",
       "      <td>4.576304</td>\n",
       "      <td>2.311068</td>\n",
       "      <td>2.265236</td>\n",
       "      <td>2.313018</td>\n",
       "      <td>0.550476</td>\n",
       "      <td>0.428071</td>\n",
       "      <td>5.335934</td>\n",
       "      <td>3.446124</td>\n",
       "      <td>1.889810</td>\n",
       "      <td>3.461238</td>\n",
       "      <td>0.666739</td>\n",
       "      <td>0.321076</td>\n",
       "      <td>5.909313</td>\n",
       "      <td>4.073135</td>\n",
       "      <td>1.836177</td>\n",
       "      <td>4.166748</td>\n",
       "      <td>0.694528</td>\n",
       "      <td>0.294312</td>\n",
       "      <td>8.104827</td>\n",
       "      <td>1.277913</td>\n",
       "      <td>2.059971</td>\n",
       "      <td>1.284252</td>\n",
       "      <td>0.206474</td>\n",
       "      <td>0.329062</td>\n",
       "      <td>7.453925</td>\n",
       "      <td>2.587031</td>\n",
       "      <td>1.208191</td>\n",
       "      <td>2.637250</td>\n",
       "      <td>0.451267</td>\n",
       "      <td>0.177168</td>\n",
       "      <td>12.526085</td>\n",
       "      <td>1.103852</td>\n",
       "      <td>1.345685</td>\n",
       "      <td>1.108727</td>\n",
       "      <td>0.161232</td>\n",
       "      <td>0.200361</td>\n",
       "      <td>9.784008</td>\n",
       "      <td>1.448074</td>\n",
       "      <td>2.083862</td>\n",
       "      <td>1.477328</td>\n",
       "      <td>0.319011</td>\n",
       "      <td>0.249576</td>\n",
       "      <td>34.581180</td>\n",
       "      <td>2.255485</td>\n",
       "      <td>1.171136</td>\n",
       "      <td>2.469039</td>\n",
       "      <td>0.096389</td>\n",
       "      <td>0.047644</td>\n",
       "      <td>19.342760</td>\n",
       "      <td>1.564115</td>\n",
       "      <td>1.913213</td>\n",
       "      <td>1.750853</td>\n",
       "      <td>0.103553</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.133593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500119</td>\n",
       "      <td>0.442084</td>\n",
       "      <td>0.388220</td>\n",
       "      <td>2.414653</td>\n",
       "      <td>3.869408</td>\n",
       "      <td>4.029822</td>\n",
       "      <td>1.027475</td>\n",
       "      <td>4.00304</td>\n",
       "      <td>0.445090</td>\n",
       "      <td>0.223003</td>\n",
       "      <td>4.638976</td>\n",
       "      <td>3.564539</td>\n",
       "      <td>1.614786</td>\n",
       "      <td>3.573590</td>\n",
       "      <td>0.412077</td>\n",
       "      <td>0.209912</td>\n",
       "      <td>6.490300</td>\n",
       "      <td>2.981657</td>\n",
       "      <td>1.401028</td>\n",
       "      <td>3.019655</td>\n",
       "      <td>0.440283</td>\n",
       "      <td>0.187149</td>\n",
       "      <td>3.814270</td>\n",
       "      <td>2.881137</td>\n",
       "      <td>2.505091</td>\n",
       "      <td>4.606974</td>\n",
       "      <td>0.349742</td>\n",
       "      <td>0.341133</td>\n",
       "      <td>6.921895</td>\n",
       "      <td>2.57606</td>\n",
       "      <td>5.867628</td>\n",
       "      <td>2.655612</td>\n",
       "      <td>0.314846</td>\n",
       "      <td>0.294673</td>\n",
       "      <td>4.569741</td>\n",
       "      <td>3.161930</td>\n",
       "      <td>3.257267</td>\n",
       "      <td>3.218492</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.325526</td>\n",
       "      <td>3.582391</td>\n",
       "      <td>3.237738</td>\n",
       "      <td>1.721371</td>\n",
       "      <td>3.291473</td>\n",
       "      <td>0.287802</td>\n",
       "      <td>0.216581</td>\n",
       "      <td>3.892957</td>\n",
       "      <td>2.072045</td>\n",
       "      <td>3.318538</td>\n",
       "      <td>2.081249</td>\n",
       "      <td>0.279985</td>\n",
       "      <td>0.267093</td>\n",
       "      <td>3.411804</td>\n",
       "      <td>2.632705</td>\n",
       "      <td>2.738608</td>\n",
       "      <td>2.647269</td>\n",
       "      <td>0.359299</td>\n",
       "      <td>0.322633</td>\n",
       "      <td>3.037349</td>\n",
       "      <td>3.312272</td>\n",
       "      <td>2.096599</td>\n",
       "      <td>3.372432</td>\n",
       "      <td>0.310774</td>\n",
       "      <td>0.290582</td>\n",
       "      <td>2.618267</td>\n",
       "      <td>2.404693</td>\n",
       "      <td>1.860201</td>\n",
       "      <td>2.477439</td>\n",
       "      <td>0.323724</td>\n",
       "      <td>0.307972</td>\n",
       "      <td>4.491188</td>\n",
       "      <td>2.119478</td>\n",
       "      <td>3.857567</td>\n",
       "      <td>2.143355</td>\n",
       "      <td>0.322644</td>\n",
       "      <td>0.246519</td>\n",
       "      <td>3.754745</td>\n",
       "      <td>2.050626</td>\n",
       "      <td>3.324120</td>\n",
       "      <td>2.050626</td>\n",
       "      <td>0.291316</td>\n",
       "      <td>0.224421</td>\n",
       "      <td>3.960460</td>\n",
       "      <td>2.685248</td>\n",
       "      <td>3.332686</td>\n",
       "      <td>2.714646</td>\n",
       "      <td>0.328570</td>\n",
       "      <td>0.304347</td>\n",
       "      <td>3.099215</td>\n",
       "      <td>2.700064</td>\n",
       "      <td>1.994395</td>\n",
       "      <td>2.753753</td>\n",
       "      <td>0.300320</td>\n",
       "      <td>0.241023</td>\n",
       "      <td>2.927644</td>\n",
       "      <td>1.780399</td>\n",
       "      <td>2.544527</td>\n",
       "      <td>1.796733</td>\n",
       "      <td>0.324488</td>\n",
       "      <td>0.287498</td>\n",
       "      <td>3.084063</td>\n",
       "      <td>1.956838</td>\n",
       "      <td>2.445885</td>\n",
       "      <td>1.966003</td>\n",
       "      <td>0.301033</td>\n",
       "      <td>0.240836</td>\n",
       "      <td>3.434874</td>\n",
       "      <td>1.88682</td>\n",
       "      <td>3.129096</td>\n",
       "      <td>1.895654</td>\n",
       "      <td>0.344570</td>\n",
       "      <td>0.317578</td>\n",
       "      <td>4.670205</td>\n",
       "      <td>1.840650</td>\n",
       "      <td>4.169220</td>\n",
       "      <td>1.905499</td>\n",
       "      <td>0.309791</td>\n",
       "      <td>0.305913</td>\n",
       "      <td>5.407484</td>\n",
       "      <td>2.225635</td>\n",
       "      <td>4.575347</td>\n",
       "      <td>2.233617</td>\n",
       "      <td>0.340602</td>\n",
       "      <td>0.341576</td>\n",
       "      <td>4.512258</td>\n",
       "      <td>1.738706</td>\n",
       "      <td>4.300028</td>\n",
       "      <td>1.761814</td>\n",
       "      <td>0.413466</td>\n",
       "      <td>0.413961</td>\n",
       "      <td>2.879252</td>\n",
       "      <td>2.347126</td>\n",
       "      <td>2.199469</td>\n",
       "      <td>2.350977</td>\n",
       "      <td>0.294676</td>\n",
       "      <td>0.287675</td>\n",
       "      <td>3.247007</td>\n",
       "      <td>1.938201</td>\n",
       "      <td>2.732554</td>\n",
       "      <td>1.955745</td>\n",
       "      <td>0.274286</td>\n",
       "      <td>0.259054</td>\n",
       "      <td>4.924048</td>\n",
       "      <td>2.009919</td>\n",
       "      <td>4.443999</td>\n",
       "      <td>2.011315</td>\n",
       "      <td>0.376076</td>\n",
       "      <td>0.372566</td>\n",
       "      <td>5.239416</td>\n",
       "      <td>2.525653</td>\n",
       "      <td>3.930686</td>\n",
       "      <td>2.546702</td>\n",
       "      <td>0.289515</td>\n",
       "      <td>0.282138</td>\n",
       "      <td>4.087287</td>\n",
       "      <td>2.673541</td>\n",
       "      <td>3.253438</td>\n",
       "      <td>2.899703</td>\n",
       "      <td>0.293322</td>\n",
       "      <td>0.285558</td>\n",
       "      <td>7.896170</td>\n",
       "      <td>1.288900</td>\n",
       "      <td>4.645881</td>\n",
       "      <td>1.301646</td>\n",
       "      <td>0.266211</td>\n",
       "      <td>0.374586</td>\n",
       "      <td>6.495041</td>\n",
       "      <td>2.125021</td>\n",
       "      <td>3.665668</td>\n",
       "      <td>2.486658</td>\n",
       "      <td>0.353263</td>\n",
       "      <td>0.253909</td>\n",
       "      <td>10.643339</td>\n",
       "      <td>0.978520</td>\n",
       "      <td>0.981763</td>\n",
       "      <td>0.981476</td>\n",
       "      <td>0.233242</td>\n",
       "      <td>0.236199</td>\n",
       "      <td>7.219868</td>\n",
       "      <td>1.374900</td>\n",
       "      <td>3.571949</td>\n",
       "      <td>1.443183</td>\n",
       "      <td>0.382922</td>\n",
       "      <td>0.280197</td>\n",
       "      <td>16.672268</td>\n",
       "      <td>1.374351</td>\n",
       "      <td>1.820069</td>\n",
       "      <td>1.797937</td>\n",
       "      <td>0.161469</td>\n",
       "      <td>0.114639</td>\n",
       "      <td>6.733464</td>\n",
       "      <td>1.012680</td>\n",
       "      <td>1.087524</td>\n",
       "      <td>1.282849</td>\n",
       "      <td>0.142387</td>\n",
       "      <td>0.128048</td>\n",
       "      <td>0.340298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.929285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gender   Nativelang    Otherlang          Age      Clicks1  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.498294     0.266212     0.815212    10.153584     5.691858   \n",
       "std       0.500119     0.442084     0.388220     2.414653     3.869408   \n",
       "min       0.000000     0.000000     0.000000     7.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     8.000000     3.000000   \n",
       "50%       0.000000     0.000000     1.000000    10.000000     5.000000   \n",
       "75%       1.000000     1.000000     1.000000    11.000000     7.000000   \n",
       "max       1.000000     1.000000     1.000000    17.000000    42.000000   \n",
       "\n",
       "             Hits1      Misses1      Score1    Accuracy1    Missrate1  \\\n",
       "count  2051.000000  2051.000000  2051.00000  2051.000000  2051.000000   \n",
       "mean      3.725012     0.663091     3.78352     0.585515     0.140790   \n",
       "std       4.029822     1.027475     4.00304     0.445090     0.223003   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     1.00000     0.100000     0.000000   \n",
       "50%       1.000000     0.000000     2.00000     1.000000     0.000000   \n",
       "75%       7.000000     1.000000     7.00000     1.000000     0.250000   \n",
       "max      19.000000    10.000000    19.00000     1.000000     1.000000   \n",
       "\n",
       "           Clicks2        Hits2      Misses2       Score2    Accuracy2  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      8.663091     4.777182     0.739152     4.829839     0.611531   \n",
       "std       4.638976     3.564539     1.614786     3.573590     0.412077   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       6.000000     2.000000     0.000000     2.000000     0.222222   \n",
       "50%       8.000000     4.000000     0.000000     4.000000     1.000000   \n",
       "75%      11.000000     7.000000     1.000000     7.000000     1.000000   \n",
       "max      57.000000    16.000000    18.000000    18.000000     1.000000   \n",
       "\n",
       "         Missrate2      Clicks3        Hits3      Misses3       Score3  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.091236     9.158947     3.969283     0.557777     4.056070   \n",
       "std       0.209912     6.490300     2.981657     1.401028     3.019655   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     5.000000     2.000000     0.000000     2.000000   \n",
       "50%       0.000000     7.000000     3.000000     0.000000     4.000000   \n",
       "75%       0.111111    11.500000     6.000000     1.000000     6.000000   \n",
       "max       1.000000    39.000000    14.000000    32.000000    18.000000   \n",
       "\n",
       "         Accuracy3    Missrate3      Clicks4        Hits4      Misses4  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.579409     0.073146     5.083374     3.295466     1.787908   \n",
       "std       0.440283     0.187149     3.814270     2.881137     2.505091   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.120000     0.000000     3.000000     2.000000     0.000000   \n",
       "50%       0.857143     0.000000     4.000000     3.000000     1.000000   \n",
       "75%       1.000000     0.066667     7.000000     4.000000     3.000000   \n",
       "max       1.000000     1.000000    88.000000    65.000000    27.000000   \n",
       "\n",
       "            Score4    Accuracy4    Missrate4      Clicks5       Hits5  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.00000   \n",
       "mean      4.051195     0.689115     0.295770     5.334959     4.10824   \n",
       "std       4.606974     0.349742     0.341133     6.921895     2.57606   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "25%       2.000000     0.454545     0.000000     3.000000     2.00000   \n",
       "50%       3.000000     0.800000     0.170000     5.000000     4.00000   \n",
       "75%       5.000000     1.000000     0.500000     6.000000     6.00000   \n",
       "max      65.000000     1.000000     1.000000   159.000000    32.00000   \n",
       "\n",
       "           Misses5       Score5    Accuracy5    Missrate5      Clicks6  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      1.226719     4.181863     0.797373     0.182646     5.560702   \n",
       "std       5.867628     2.655612     0.314846     0.294673     4.569741   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     2.000000     0.666667     0.000000     3.000000   \n",
       "50%       0.000000     4.000000     1.000000     0.000000     5.000000   \n",
       "75%       1.000000     6.000000     1.000000     0.250000     7.000000   \n",
       "max     127.000000    32.000000     1.000000     1.000000   108.000000   \n",
       "\n",
       "             Hits6      Misses6       Score6    Accuracy6    Missrate6  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      4.338859     1.221843     4.357874     0.749269     0.235631   \n",
       "std       3.161930     3.257267     3.218492     0.337240     0.325526   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     2.000000     0.600000     0.000000   \n",
       "50%       4.000000     0.000000     4.000000     1.000000     0.000000   \n",
       "75%       6.000000     1.000000     6.000000     1.000000     0.400000   \n",
       "max      43.000000    65.000000    43.000000     1.000000     1.000000   \n",
       "\n",
       "           Clicks7        Hits7      Misses7       Score7    Accuracy7  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      5.639688     5.105802     0.533886     5.128230     0.843841   \n",
       "std       3.582391     3.237738     1.721371     3.291473     0.287802   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       4.000000     3.000000     0.000000     3.000000     0.800000   \n",
       "50%       5.000000     5.000000     0.000000     5.000000     1.000000   \n",
       "75%       7.000000     7.000000     1.000000     7.000000     1.000000   \n",
       "max      76.000000    18.000000    60.000000    28.000000     1.000000   \n",
       "\n",
       "         Missrate7      Clicks8        Hits8      Misses8       Score8  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.107441     4.804973     3.854217     0.950756     3.863481   \n",
       "std       0.216581     3.892957     2.072045     3.318538     2.081249   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     3.000000     2.000000     0.000000     2.000000   \n",
       "50%       0.000000     4.000000     4.000000     0.000000     4.000000   \n",
       "75%       0.166667     6.000000     5.000000     1.000000     5.000000   \n",
       "max       1.000000    79.000000    13.000000    70.000000    13.000000   \n",
       "\n",
       "         Accuracy8    Missrate8      Clicks9        Hits9      Misses9  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.823412     0.165872     4.198927     3.347148     0.851780   \n",
       "std       0.279985     0.267093     3.411804     2.632705     2.738608   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.750000     0.000000     2.000000     1.000000     0.000000   \n",
       "50%       1.000000     0.000000     4.000000     3.000000     0.000000   \n",
       "75%       1.000000     0.250000     6.000000     5.000000     1.000000   \n",
       "max       1.000000     1.000000    88.000000    13.000000    84.000000   \n",
       "\n",
       "            Score9    Accuracy9    Missrate9     Clicks10       Hits10  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      3.356412     0.752922     0.201739     7.019015     6.283764   \n",
       "std       2.647269     0.359299     0.322633     3.037349     3.312272   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.500000     0.000000     5.000000     4.000000   \n",
       "50%       3.000000     1.000000     0.000000     7.000000     6.000000   \n",
       "75%       5.000000     1.000000     0.333333     9.000000     9.000000   \n",
       "max      13.000000     1.000000     1.000000    34.000000    17.000000   \n",
       "\n",
       "          Misses10      Score10   Accuracy10   Missrate10     Clicks11  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.735251     6.308142     0.857771     0.125657     4.574354   \n",
       "std       2.096599     3.372432     0.310774     0.290582     2.618267   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     4.000000     0.929285     0.000000     3.000000   \n",
       "50%       0.000000     6.000000     1.000000     0.000000     4.000000   \n",
       "75%       0.000000     9.000000     1.000000     0.000000     6.000000   \n",
       "max      30.000000    24.000000     1.000000     1.000000    43.000000   \n",
       "\n",
       "            Hits11     Misses11      Score11   Accuracy11   Missrate11  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      3.839590     0.734764     3.873720     0.801198     0.182732   \n",
       "std       2.404693     1.860201     2.477439     0.323724     0.307972   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     2.000000     0.670000     0.000000   \n",
       "50%       4.000000     0.000000     4.000000     1.000000     0.000000   \n",
       "75%       5.000000     1.000000     5.000000     1.000000     0.250000   \n",
       "max      12.000000    36.000000    18.000000     1.000000     1.000000   \n",
       "\n",
       "          Clicks12       Hits12     Misses12      Score12   Accuracy12  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      3.903949     3.297903     0.606046     3.308630     0.851060   \n",
       "std       4.491188     2.119478     3.857567     2.143355     0.322644   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     2.000000     0.000000     2.000000     1.000000   \n",
       "50%       3.000000     3.000000     0.000000     3.000000     1.000000   \n",
       "75%       5.000000     5.000000     0.000000     5.000000     1.000000   \n",
       "max     116.000000    13.000000   103.000000    16.000000     1.000000   \n",
       "\n",
       "        Missrate12     Clicks13       Hits13     Misses13      Score13  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.091900     3.711360     3.290102     0.421258     3.290102   \n",
       "std       0.246519     3.754745     2.050626     3.324120     2.050626   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     2.000000     2.000000     0.000000     2.000000   \n",
       "50%       0.000000     3.000000     3.000000     0.000000     3.000000   \n",
       "75%       0.000000     5.000000     5.000000     0.000000     5.000000   \n",
       "max       1.000000   109.000000    12.000000   107.000000    12.000000   \n",
       "\n",
       "        Accuracy13   Missrate13     Clicks14       Hits14     Misses14  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.875646     0.080965     5.215505     4.165773     1.049732   \n",
       "std       0.291316     0.224421     3.960460     2.685248     3.332686   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     3.000000     2.000000     0.000000   \n",
       "50%       1.000000     0.000000     5.000000     4.000000     0.000000   \n",
       "75%       1.000000     0.000000     6.000000     6.000000     1.000000   \n",
       "max       1.000000     1.000000    71.000000    13.000000    59.000000   \n",
       "\n",
       "           Score14   Accuracy14   Missrate14     Clicks15       Hits15  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      4.183325     0.789527     0.185119     4.337396     3.942467   \n",
       "std       2.714646     0.328570     0.304347     3.099215     2.700064   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.666667     0.000000     2.000000     2.000000   \n",
       "50%       4.000000     1.000000     0.000000     4.000000     4.000000   \n",
       "75%       6.000000     1.000000     0.250000     6.000000     6.000000   \n",
       "max      21.000000     1.000000     1.000000    64.000000    16.000000   \n",
       "\n",
       "          Misses15      Score15   Accuracy15   Missrate15     Clicks16  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.394929     3.964895     0.871217     0.087828     3.891273   \n",
       "std       1.994395     2.753753     0.300320     0.241023     2.927644   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     2.000000     1.000000     0.000000     3.000000   \n",
       "50%       0.000000     4.000000     1.000000     0.000000     4.000000   \n",
       "75%       0.000000     6.000000     1.000000     0.000000     5.000000   \n",
       "max      60.000000    24.000000     1.000000     1.000000    61.000000   \n",
       "\n",
       "            Hits16     Misses16      Score16   Accuracy16   Missrate16  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      3.076060     0.815212     3.082886     0.795510     0.168415   \n",
       "std       1.780399     2.544527     1.796733     0.324488     0.287498   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     2.000000     0.666667     0.000000   \n",
       "50%       3.000000     0.000000     3.000000     1.000000     0.000000   \n",
       "75%       4.000000     1.000000     4.000000     1.000000     0.250000   \n",
       "max      12.000000    59.000000    12.000000     1.000000     1.000000   \n",
       "\n",
       "          Clicks17       Hits17     Misses17      Score17   Accuracy17  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      3.659678     3.180887     0.478791     3.185275     0.853968   \n",
       "std       3.084063     1.956838     2.445885     1.966003     0.301033   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     2.000000     0.000000     2.000000     1.000000   \n",
       "50%       3.000000     3.000000     0.000000     3.000000     1.000000   \n",
       "75%       5.000000     4.000000     0.000000     4.000000     1.000000   \n",
       "max      82.000000    11.000000    72.000000    12.000000     1.000000   \n",
       "\n",
       "        Missrate17     Clicks18      Hits18     Misses18      Score18  \\\n",
       "count  2051.000000  2051.000000  2051.00000  2051.000000  2051.000000   \n",
       "mean      0.102639     4.063871     3.01999     1.043881     3.025353   \n",
       "std       0.240836     3.434874     1.88682     3.129096     1.895654   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       0.000000     3.000000     2.00000     0.000000     2.000000   \n",
       "50%       0.000000     4.000000     3.00000     0.000000     3.000000   \n",
       "75%       0.000000     5.000000     4.00000     1.000000     4.000000   \n",
       "max       1.000000    74.000000    10.00000    65.000000    10.000000   \n",
       "\n",
       "        Accuracy18   Missrate18     Clicks19       Hits19     Misses19  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.744595     0.221290     4.927353     2.844466     2.082886   \n",
       "std       0.344570     0.317578     4.670205     1.840650     4.169220   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.500000     0.000000     3.000000     2.000000     1.000000   \n",
       "50%       1.000000     0.000000     5.000000     3.000000     1.000000   \n",
       "75%       1.000000     0.333333     6.000000     4.000000     3.000000   \n",
       "max       1.000000     1.000000   106.000000    18.000000    94.000000   \n",
       "\n",
       "           Score19   Accuracy19   Missrate19     Clicks20       Hits20  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      2.861043     0.600672     0.388129     4.990249     2.302292   \n",
       "std       1.905499     0.309791     0.305913     5.407484     2.225635   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.400000     0.166667     3.000000     1.000000   \n",
       "50%       3.000000     0.666667     0.333333     4.000000     2.000000   \n",
       "75%       4.000000     0.833333     0.600000     6.000000     3.000000   \n",
       "max      24.000000     1.000000     1.000000   111.000000    20.000000   \n",
       "\n",
       "          Misses20      Score20   Accuracy20   Missrate20     Clicks21  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      2.687957     2.311068     0.470582     0.514308     4.168211   \n",
       "std       4.575347     2.233617     0.340602     0.341576     4.512258   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     0.200000     0.250000     2.000000   \n",
       "50%       2.000000     2.000000     0.500000     0.500000     3.000000   \n",
       "75%       3.000000     3.000000     0.750000     0.800000     5.000000   \n",
       "max      91.000000    20.000000     1.000000     1.000000    87.000000   \n",
       "\n",
       "            Hits21     Misses21      Score21   Accuracy21   Missrate21  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      1.737201     2.431009     1.747440     0.479720     0.498832   \n",
       "std       1.738706     4.300028     1.761814     0.413466     0.413961   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     1.000000     1.000000     0.500000     0.500000   \n",
       "75%       3.000000     3.000000     3.000000     1.000000     1.000000   \n",
       "max      13.000000    74.000000    13.000000     1.000000     1.000000   \n",
       "\n",
       "          Clicks22       Hits22     Misses22      Score22   Accuracy22  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      5.178450     3.843003     1.335446     3.847879     0.728310   \n",
       "std       2.879252     2.347126     2.199469     2.350977     0.294676   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       4.000000     2.000000     0.000000     2.000000     0.571429   \n",
       "50%       5.000000     4.000000     1.000000     4.000000     0.800000   \n",
       "75%       6.000000     5.000000     2.000000     5.000000     1.000000   \n",
       "max      36.000000    15.000000    31.000000    15.000000     1.000000   \n",
       "\n",
       "        Missrate22     Clicks23       Hits23     Misses23      Score23  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.262924     4.780595     3.368113     1.412482     3.379815   \n",
       "std       0.287675     3.247007     1.938201     2.732554     1.955745   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     3.000000     2.000000     0.000000     2.000000   \n",
       "50%       0.200000     4.000000     3.000000     1.000000     3.000000   \n",
       "75%       0.400000     6.000000     4.000000     2.000000     4.000000   \n",
       "max       1.000000    79.000000    15.000000    77.000000    15.000000   \n",
       "\n",
       "        Accuracy23   Missrate23     Clicks24       Hits24     Misses24  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.729324     0.253645     4.576304     2.311068     2.265236   \n",
       "std       0.274286     0.259054     4.924048     2.009919     4.443999   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.600000     0.000000     2.000000     1.000000     0.000000   \n",
       "50%       0.777778     0.200000     4.000000     2.000000     1.000000   \n",
       "75%       1.000000     0.400000     5.000000     3.000000     3.000000   \n",
       "max       1.000000     1.000000    92.000000    15.000000    79.000000   \n",
       "\n",
       "           Score24   Accuracy24   Missrate24     Clicks25       Hits25  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      2.313018     0.550476     0.428071     5.335934     3.446124   \n",
       "std       2.011315     0.376076     0.372566     5.239416     2.525653   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.222222     0.000000     3.000000     2.000000   \n",
       "50%       2.000000     0.500000     0.400000     5.000000     3.000000   \n",
       "75%       3.000000     1.000000     0.750000     6.000000     5.000000   \n",
       "max      15.000000     1.000000     1.000000   146.000000    57.000000   \n",
       "\n",
       "          Misses25      Score25   Accuracy25   Missrate25     Clicks26  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      1.889810     3.461238     0.666739     0.321076     5.909313   \n",
       "std       3.930686     2.546702     0.289515     0.282138     4.087287   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     2.000000     0.500000     0.076923     4.000000   \n",
       "50%       1.000000     3.000000     0.714286     0.250000     5.000000   \n",
       "75%       2.000000     5.000000     0.888889     0.500000     7.000000   \n",
       "max      89.000000    57.000000     1.000000     1.000000   105.000000   \n",
       "\n",
       "            Hits26     Misses26      Score26   Accuracy26   Missrate26  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      4.073135     1.836177     4.166748     0.694528     0.294312   \n",
       "std       2.673541     3.253438     2.899703     0.293322     0.285558   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     2.000000     0.500000     0.000000   \n",
       "50%       4.000000     1.000000     4.000000     0.750000     0.250000   \n",
       "75%       6.000000     3.000000     6.000000     1.000000     0.500000   \n",
       "max      36.000000    98.000000    36.000000     1.000000     1.000000   \n",
       "\n",
       "          Clicks27       Hits27     Misses27      Score27   Accuracy27  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      8.104827     1.277913     2.059971     1.284252     0.206474   \n",
       "std       7.896170     1.288900     4.645881     1.301646     0.266211   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       3.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       5.000000     1.000000     1.000000     1.000000     0.130435   \n",
       "75%      12.000000     2.000000     2.000000     2.000000     0.250000   \n",
       "max      97.000000    11.000000    87.000000    11.000000     1.000000   \n",
       "\n",
       "        Missrate27     Clicks28       Hits28     Misses28      Score28  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.329062     7.453925     2.587031     1.208191     2.637250   \n",
       "std       0.374586     6.495041     2.125021     3.665668     2.486658   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     3.000000     1.000000     0.000000     1.000000   \n",
       "50%       0.117647     6.000000     2.000000     1.000000     2.000000   \n",
       "75%       0.666667     9.000000     4.000000     1.000000     4.000000   \n",
       "max       1.000000   138.000000    40.000000    98.000000    57.000000   \n",
       "\n",
       "        Accuracy28   Missrate28     Clicks29       Hits29     Misses29  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      0.451267     0.177168    12.526085     1.103852     1.345685   \n",
       "std       0.353263     0.253909    10.643339     0.978520     0.981763   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.200000     0.000000     3.000000     0.000000     1.000000   \n",
       "50%       0.333333     0.076923     6.000000     1.000000     1.000000   \n",
       "75%       0.800000     0.250000    26.000000     2.000000     2.000000   \n",
       "max       1.000000     1.000000    34.000000     4.000000     5.000000   \n",
       "\n",
       "           Score29   Accuracy29   Missrate29     Clicks30       Hits30  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      1.108727     0.161232     0.200361     9.784008     1.448074   \n",
       "std       0.981476     0.233242     0.236199     7.219868     1.374900   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.038462     3.000000     0.000000   \n",
       "50%       1.000000     0.076923     0.115385     9.000000     1.000000   \n",
       "75%       2.000000     0.200000     0.300000    17.000000     2.000000   \n",
       "max       4.000000     1.000000     1.000000    81.000000     8.000000   \n",
       "\n",
       "          Misses30      Score30   Accuracy30   Missrate30     Clicks31  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      2.083862     1.477328     0.319011     0.249576    34.581180   \n",
       "std       3.571949     1.443183     0.382922     0.280197    16.672268   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.058824    30.000000   \n",
       "50%       2.000000     1.000000     0.117647     0.176471    35.000000   \n",
       "75%       3.000000     2.000000     0.666667     0.250000    41.000000   \n",
       "max      73.000000    16.000000     1.000000     1.000000   430.000000   \n",
       "\n",
       "            Hits31     Misses31      Score31   Accuracy31   Missrate31  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean      2.255485     1.171136     2.469039     0.096389     0.047644   \n",
       "std       1.374351     1.820069     1.797937     0.161469     0.114639   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     1.000000     0.032787     0.000000   \n",
       "50%       2.000000     1.000000     2.000000     0.062500     0.026316   \n",
       "75%       3.000000     2.000000     4.000000     0.110000     0.047619   \n",
       "max       4.000000    50.000000    16.000000     1.000000     1.000000   \n",
       "\n",
       "          Clicks32       Hits32     Misses32      Score32   Accuracy32  \\\n",
       "count  2051.000000  2051.000000  2051.000000  2051.000000  2051.000000   \n",
       "mean     19.342760     1.564115     1.913213     1.750853     0.103553   \n",
       "std       6.733464     1.012680     1.087524     1.282849     0.142387   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      17.000000     1.000000     1.000000     1.000000     0.042572   \n",
       "50%      17.000000     2.000000     2.000000     2.000000     0.076923   \n",
       "75%      26.000000     2.000000     3.000000     2.000000     0.115385   \n",
       "max      26.000000     4.000000     4.000000    10.000000     1.000000   \n",
       "\n",
       "        Missrate32     Dyslexia  \n",
       "count  2051.000000  2051.000000  \n",
       "mean      0.124700     0.133593  \n",
       "std       0.128048     0.340298  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.043478     0.000000  \n",
       "50%       0.100000     0.000000  \n",
       "75%       0.176471     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras observar la distribución del *dataset* original y comprobar como sí presenta outliers, se va a proceder con el análisis y la eliminación de aquellos valores que no aporten información válida y vayan a afectar negativamente al modelo.\n",
    "\n",
    "La función `distplot` se va a emplear para identificar la forma en que los datos están distribuidos, verificando si siguen una distribución normal o no, como afecta la presencia de outliers a la distribución y cual es la media y la desviación estándar. Es decir, se va a representar visualmente la distribución de los datos de cada variable.\n",
    "\n",
    "La función `boxplot`representa el rango intercuartílico (IQR) de los datos. La caja (gráfico) va desde el primer cuartil (Q1) hasta el tercer cuartil (Q3), y su longitud representa el rango intercuartílico (IQR = Q3 - Q1). Los valores atípicos (outliers) son aquellos que están fuera del rango definido por 1,5 veces el IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(df):\n",
    "    \n",
    "    rest = df.shape[1] % 4\n",
    "    rows = df.shape[1]//4\n",
    "    \n",
    "    if rest == 0:\n",
    "        rows = rows\n",
    "    else:\n",
    "        rows = rows + 1\n",
    "        \n",
    "    fig, ax = plt.subplots(ncols = 4, nrows = rows, figsize = (15, 150))\n",
    "    i = 0\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for col in df.columns:\n",
    "        plt.title(col)\n",
    "        sns.distplot(df[col], ax=ax[i])\n",
    "        i+=1\n",
    "    plt.tight_layout(pad = 0.5, w_pad = 0.7, h_pad = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_whisker(df):\n",
    "    \n",
    "    rest = df.shape[1] % 4\n",
    "    rows = df.shape[1]//4\n",
    "    \n",
    "    if rest == 0:\n",
    "        rows = rows\n",
    "    else:\n",
    "        rows = rows + 1\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 4, nrows = rows, figsize = (15, 150))\n",
    "    i = 0\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        plt.title(col)\n",
    "        df.boxplot([col], ax=ax[i])\n",
    "        i+=1\n",
    "    plt.tight_layout(pad = 0.5, w_pad = 0.7, h_pad = 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a trabajar solo con las variables relativas a las preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Q = data.drop(columns = ['Gender','Nativelang','Otherlang','Age','Dyslexia'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(data_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentile method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la eleminación de outliers existen varias técnicas, como Z-score method, Inter Quartile Range Method o Percentile method. la técnica que se ha elegido es el método de percentil ya que es fácil de entender y aplicar, y no requiere de una distribución específica. Como se ha podido observar, no todas las variables tienen la misma distribución, lo que podría suponer un problema utilizando Z-score o el método del Intercuartil.\n",
    "\n",
    "Se trata de un método robusto a la presencia de valores atípicos en los datos, lo que lo hace menos propenso a ser afectado por ellos, y permite ajustar los límites al dataset con el que se esté trabajando. En este caso, para no prescindir de un gran número de datos, aun eliminando aquellos datos que influían negativamente al modelo, se han establecido como umbral superior el 0.999 e inferior el 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(ds):\n",
    "    print(\"Old Shape: \", ds.shape)\n",
    "    \n",
    "    rng = ds.columns\n",
    "    for col in rng:\n",
    "        #first percentile\n",
    "        min_threshold = ds[col].quantile(0.001)\n",
    "        #third percentile\n",
    "        max_threshold = ds[col].quantile(0.999)\n",
    "        \n",
    "        ds.drop(ds[(ds[col] < min_threshold) | (ds[col] > max_threshold)].index, inplace=True)\n",
    "        \n",
    "    print(\"New Shape: \", ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Shape:  (2051, 192)\n",
      "New Shape:  (1857, 192)\n"
     ]
    }
   ],
   "source": [
    "remove_outliers(data_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representando de nuevo los gráficos de distribución se puede observar como la presencia de outliers ha disminuido considerablemente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(data_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan aquellas filas que contienen valores anómalos de los datasets inciales, recuperando las columnas: 'Gender', 'Nativelang', 'Otherlang', 'Age', 'Dyslexia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data_Q.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se van a definir dos funciones nuevas, `corr_hit_miss`y `corr_acc_missrate`, para comparar como de correladas están las variables *Clicks*, *Hits*, *Misses* y *Score* y la suma de las variables *Hits y Misses* con *Clicks*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_hit_miss(ds_orig, nombre):\n",
    "    ds = ds_orig.copy()\n",
    "    print(nombre+\" dataset\")\n",
    "    for i in range(32):\n",
    "        try:        \n",
    "            print(\"Question\", str(i+1))\n",
    "            #Pearson correlation coef\n",
    "            correlation_misses = ds['Clicks'+str(i+1)].corr(ds['Misses'+str(i+1)])\n",
    "            correlation_hits = ds['Clicks'+str(i+1)].corr(ds['Hits'+str(i+1)])\n",
    "            correlation_score = ds['Clicks'+str(i+1)].corr(ds['Score'+str(i+1)])\n",
    "\n",
    "            ds['Hits + Misses'+str(i+1)] = ds['Hits'+str(i+1)] + ds['Misses'+str(i+1)]\n",
    "            correlation_sum = ds['Clicks'+str(i+1)].corr(ds['Hits + Misses'+str(i+1)])\n",
    "\n",
    "            print(\"Misses\", str(i+1), correlation_misses)\n",
    "            print(\"Hits\", str(i+1), correlation_hits)\n",
    "            print(\"Score\", str(i+1), correlation_score)\n",
    "            print(\"Hits + Misses\", str(i+1), correlation_sum)\n",
    "        except KeyError:\n",
    "            print(\"Question \"+str(i+1)+\" not in the dataset\")\n",
    "            \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_acc_missrate(ds_orig, nombre):\n",
    "    ds = ds_orig.copy()\n",
    "    print(nombre+\" dataset\")\n",
    "    for i in  range(32):\n",
    "        try:\n",
    "            print(\"Question\"+str(i+1))\n",
    "            #Pearson correlation coeff\n",
    "            correlation_acc = ds['Hits'+str(i+1)].corr(ds['Accuracy'+str(i+1)])\n",
    "            correlation_missrate = ds['Misses'+str(i+1)].corr(ds['Missrate'+str(i+1)])\n",
    "            correlation_accs_rate = ds['Accuracy'+str(i+1)].corr(ds['Missrate'+str(i+1)])\n",
    "\n",
    "            print(\"Accuracy\"+str(i+1),correlation_acc)\n",
    "            print(\"Missrate\"+str(i+1),correlation_missrate)\n",
    "            print(\"Between Accuracy and Missrate\"+str(i+1),correlation_accs_rate)\n",
    "        except KeyError:\n",
    "            print(\"Question \"+str(i+1)+\" not in the dataset\")\n",
    "            \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprobará tanto para los dataset de entrenamiento, como de prueba y diferenciando entre los cuatro casos distintos tras aplicar las técnicas de gestión de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dataset\n",
      "Question 1\n",
      "Misses 1 0.13909494166217035\n",
      "Hits 1 0.7267067215102139\n",
      "Score 1 0.7240506573474914\n",
      "Hits + Misses 1 0.833858973072691\n",
      "Question 2\n",
      "Misses 2 0.1944054874370857\n",
      "Hits 2 0.25613131412336504\n",
      "Score 2 0.2677005871888611\n",
      "Hits + Misses 2 0.379035817771675\n",
      "Question 3\n",
      "Misses 3 0.22727789549467217\n",
      "Hits 3 0.007214598829241977\n",
      "Score 3 0.045355205985139806\n",
      "Hits + Misses 3 0.08620335666036467\n",
      "Question 4\n",
      "Misses 4 0.5964425379615595\n",
      "Hits 4 0.6728343183906031\n",
      "Score 4 0.6379578245425894\n",
      "Hits + Misses 4 1.0\n",
      "Question 5\n",
      "Misses 5 0.4553458461896815\n",
      "Hits 5 0.722071924284282\n",
      "Score 5 0.7148362716249598\n",
      "Hits + Misses 5 1.0\n",
      "Question 6\n",
      "Misses 6 0.1182438753817822\n",
      "Hits 6 0.8457770065454226\n",
      "Score 6 0.8457770065454226\n",
      "Hits + Misses 6 1.0\n",
      "Question 7\n",
      "Misses 7 0.06407697414534584\n",
      "Hits 7 0.9602516470974922\n",
      "Score 7 0.9596942516283573\n",
      "Hits + Misses 7 1.0\n",
      "Question 8\n",
      "Misses 8 0.3826527766421042\n",
      "Hits 8 0.7493547798528235\n",
      "Score 8 0.7466898036548122\n",
      "Hits + Misses 8 1.0\n",
      "Question 9\n",
      "Misses 9 0.1956260100687589\n",
      "Hits 9 0.8514402063106646\n",
      "Score 9 0.8498874597380998\n",
      "Hits + Misses 9 1.0\n",
      "Question 10\n",
      "Misses 10 0.09006021711417513\n",
      "Hits 10 0.8284359093433326\n",
      "Score 10 0.8284359093433326\n",
      "Hits + Misses 10 1.0\n",
      "Question 11\n",
      "Misses 11 0.0651384187988828\n",
      "Hits 11 0.8678236485323149\n",
      "Score 11 0.8631244074557441\n",
      "Hits + Misses 11 0.9999999999999998\n",
      "Question 12\n",
      "Misses 12 0.3389190827785687\n",
      "Hits 12 0.8403066637241204\n",
      "Score 12 0.839975717014992\n",
      "Hits + Misses 12 1.0\n",
      "Question 13\n",
      "Misses 13 0.16897741208525158\n",
      "Hits 13 0.9144127729295154\n",
      "Score 13 0.9144127729295154\n",
      "Hits + Misses 13 0.9999999999999999\n",
      "Question 14\n",
      "Misses 14 0.18315577089154866\n",
      "Hits 14 0.8140092885029291\n",
      "Score 14 0.81328465825118\n",
      "Hits + Misses 14 0.9999999999999998\n",
      "Question 15\n",
      "Misses 15 0.08729509409622922\n",
      "Hits 15 0.9400833109482208\n",
      "Score 15 0.9384937060010303\n",
      "Hits + Misses 15 0.9999999999999998\n",
      "Question 16\n",
      "Misses 16 0.3898840177978317\n",
      "Hits 16 0.7624016075421457\n",
      "Score 16 0.7632167187692774\n",
      "Hits + Misses 16 1.0\n",
      "Question 17\n",
      "Misses 17 0.18974604612463072\n",
      "Hits 17 0.8983282020623153\n",
      "Score 17 0.8981752039472384\n",
      "Hits + Misses 17 1.0\n",
      "Question 18\n",
      "Misses 18 0.3353557186077011\n",
      "Hits 18 0.7300495571489473\n",
      "Score 18 0.7294502048811953\n",
      "Hits + Misses 18 1.0\n",
      "Question 19\n",
      "Misses 19 0.5388548303449575\n",
      "Hits 19 0.5862574171089266\n",
      "Score 19 0.5846179543377491\n",
      "Hits + Misses 19 0.9999999999999999\n",
      "Question 20\n",
      "Misses 20 0.6802469411283423\n",
      "Hits 20 0.5070502117200372\n",
      "Score 20 0.5053078738858602\n",
      "Hits + Misses 20 1.0\n",
      "Question 21\n",
      "Misses 21 0.7975400038683048\n",
      "Hits 21 0.2570327269371924\n",
      "Score 21 0.2548437554499261\n",
      "Hits + Misses 21 1.0\n",
      "Question 22\n",
      "Misses 22 0.4019449290540807\n",
      "Hits 22 0.753663932073829\n",
      "Score 22 0.7523443859278105\n",
      "Hits + Misses 22 0.9999999999999998\n",
      "Question 23\n",
      "Misses 23 0.5738917450799752\n",
      "Hits 23 0.7645126814741057\n",
      "Score 23 0.7608321741839649\n",
      "Hits + Misses 23 1.0\n",
      "Question 24\n",
      "Misses 24 0.7151115046429896\n",
      "Hits 24 0.4339541859859855\n",
      "Score 24 0.43341208351568783\n",
      "Hits + Misses 24 0.9999999999999998\n",
      "Question 25\n",
      "Misses 25 0.6333264468745678\n",
      "Hits 25 0.6419268162515577\n",
      "Score 25 0.6363996607398423\n",
      "Hits + Misses 25 0.9999999999999998\n",
      "Question 26\n",
      "Misses 26 0.46137308208883393\n",
      "Hits 26 0.7856299926547873\n",
      "Score 26 0.7678178046111132\n",
      "Hits + Misses 26 1.0\n",
      "Question 27\n",
      "Misses 27 0.13299982959286627\n",
      "Hits 27 0.5718317735229269\n",
      "Score 27 0.5664490122431337\n",
      "Hits + Misses 27 0.3855772726738375\n",
      "Question 28\n",
      "Misses 28 0.2762711453579281\n",
      "Hits 28 0.3093400562368487\n",
      "Score 28 0.30181426397882255\n",
      "Hits + Misses 28 0.4861893988678005\n",
      "Question 29\n",
      "Misses 29 0.4101683074722402\n",
      "Hits 29 0.6905897885515798\n",
      "Score 29 0.6839152366553033\n",
      "Hits + Misses 29 0.881876408774583\n",
      "Question 30\n",
      "Misses 30 0.5763898707736852\n",
      "Hits 30 -0.22585728084631787\n",
      "Score 30 -0.22718799814452778\n",
      "Hits + Misses 30 0.39120317817892925\n",
      "Question 31\n",
      "Misses 31 0.49719201641496613\n",
      "Hits 31 0.28773039537887213\n",
      "Score 31 0.23466329162469513\n",
      "Hits + Misses 31 0.6336997074030638\n",
      "Question 32\n",
      "Misses 32 0.013760783530990452\n",
      "Hits 32 0.3490008128936424\n",
      "Score 32 0.20687932031519773\n",
      "Hits + Misses 32 0.3858812494242556\n",
      "\n",
      "\n",
      "Model dataset\n",
      "Question1\n",
      "Accuracy1 0.7497735349745501\n",
      "Missrate1 0.764729583697781\n",
      "Between Accuracy and Missrate1 -0.696213611143275\n",
      "Question2\n",
      "Accuracy2 0.7789612997224872\n",
      "Missrate2 0.8215242741813353\n",
      "Between Accuracy and Missrate2 -0.5264919202397346\n",
      "Question3\n",
      "Accuracy3 0.7680721531484703\n",
      "Missrate3 0.7557264512146968\n",
      "Between Accuracy and Missrate3 -0.35435027791818996\n",
      "Question4\n",
      "Accuracy4 0.4983951197286851\n",
      "Missrate4 0.8212817499378552\n",
      "Between Accuracy and Missrate4 -0.9360272931265557\n",
      "Question5\n",
      "Accuracy5 0.6772971048941288\n",
      "Missrate5 0.6192505042831634\n",
      "Between Accuracy and Missrate5 -0.8921978806051298\n",
      "Question6\n",
      "Accuracy6 0.6864796261895824\n",
      "Missrate6 0.768071069329287\n",
      "Between Accuracy and Missrate6 -0.9336416495782552\n",
      "Question7\n",
      "Accuracy7 0.5555220803060095\n",
      "Missrate7 0.7920601362260388\n",
      "Between Accuracy and Missrate7 -0.6623719762057279\n",
      "Question8\n",
      "Accuracy8 0.5953060209900147\n",
      "Missrate8 0.7700569595183198\n",
      "Between Accuracy and Missrate8 -0.9299622864854196\n",
      "Question9\n",
      "Accuracy9 0.6256500653391933\n",
      "Missrate9 0.7692090905939708\n",
      "Between Accuracy and Missrate9 -0.8174539262778692\n",
      "Question10\n",
      "Accuracy10 0.6966871960840852\n",
      "Missrate10 0.8060543706532868\n",
      "Between Accuracy and Missrate10 -0.9192063843016928\n",
      "Question11\n",
      "Accuracy11 0.6679907316015841\n",
      "Missrate11 0.8031021039899457\n",
      "Between Accuracy and Missrate11 -0.9154478920620948\n",
      "Question12\n",
      "Accuracy12 0.5677268361270663\n",
      "Missrate12 0.7418526742518039\n",
      "Between Accuracy and Missrate12 -0.6741938538406291\n",
      "Question13\n",
      "Accuracy13 0.5255773242019389\n",
      "Missrate13 0.7830612591443721\n",
      "Between Accuracy and Missrate13 -0.6955161100671466\n",
      "Question14\n",
      "Accuracy14 0.6616787945032041\n",
      "Missrate14 0.8037737539362871\n",
      "Between Accuracy and Missrate14 -0.8692359507968114\n",
      "Question15\n",
      "Accuracy15 0.5052987662865633\n",
      "Missrate15 0.7814459302623603\n",
      "Between Accuracy and Missrate15 -0.7270250149930888\n",
      "Question16\n",
      "Accuracy16 0.6265820814479423\n",
      "Missrate16 0.8185994316192977\n",
      "Between Accuracy and Missrate16 -0.8113572125479839\n",
      "Question17\n",
      "Accuracy17 0.5614822367831301\n",
      "Missrate17 0.7773669116242498\n",
      "Between Accuracy and Missrate17 -0.7173177292182698\n",
      "Question18\n",
      "Accuracy18 0.7009969269706446\n",
      "Missrate18 0.833263118350406\n",
      "Between Accuracy and Missrate18 -0.8439605485911269\n",
      "Question19\n",
      "Accuracy19 0.7404890076335179\n",
      "Missrate19 0.7573527398363038\n",
      "Between Accuracy and Missrate19 -0.9431922009580886\n",
      "Question20\n",
      "Accuracy20 0.7605776094975593\n",
      "Missrate20 0.6212317094319205\n",
      "Between Accuracy and Missrate20 -0.9326015641643771\n",
      "Question21\n",
      "Accuracy21 0.7910906143874216\n",
      "Missrate21 0.6506668865649303\n",
      "Between Accuracy and Missrate21 -0.9396676359827189\n",
      "Question22\n",
      "Accuracy22 0.6670457803659321\n",
      "Missrate22 0.7112920811611335\n",
      "Between Accuracy and Missrate22 -0.9468949011057052\n",
      "Question23\n",
      "Accuracy23 0.47985531780729906\n",
      "Missrate23 0.7903561943606204\n",
      "Between Accuracy and Missrate23 -0.877993706608998\n",
      "Question24\n",
      "Accuracy24 0.7361703017076828\n",
      "Missrate24 0.6694445038578525\n",
      "Between Accuracy and Missrate24 -0.9176338633306336\n",
      "Question25\n",
      "Accuracy25 0.6541819704004194\n",
      "Missrate25 0.6384108513057111\n",
      "Between Accuracy and Missrate25 -0.9217810768242236\n",
      "Question26\n",
      "Accuracy26 0.5856448933293747\n",
      "Missrate26 0.7731700854275285\n",
      "Between Accuracy and Missrate26 -0.9331264870568164\n",
      "Question27\n",
      "Accuracy27 0.5369437006289564\n",
      "Missrate27 0.6415182598957527\n",
      "Between Accuracy and Missrate27 -0.12281689168960579\n",
      "Question28\n",
      "Accuracy28 0.5987164088779369\n",
      "Missrate28 0.6220363446599865\n",
      "Between Accuracy and Missrate28 -0.3447298901682969\n",
      "Question29\n",
      "Accuracy29 0.11040109818374796\n",
      "Missrate29 0.27006999798070574\n",
      "Between Accuracy and Missrate29 -0.35540910361019645\n",
      "Question30\n",
      "Accuracy30 0.717880079108357\n",
      "Missrate30 0.45118736300806256\n",
      "Between Accuracy and Missrate30 -0.2892288014440556\n",
      "Question31\n",
      "Accuracy31 0.2977174937014198\n",
      "Missrate31 0.38131688532829766\n",
      "Between Accuracy and Missrate31 0.2945677192122469\n",
      "Question32\n",
      "Accuracy32 0.43363761287108765\n",
      "Missrate32 0.48464581727629275\n",
      "Between Accuracy and Missrate32 0.23678830519659574\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corr_hit_miss(data, \"Model\")\n",
    "corr_acc_missrate(data, \"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    columns = ['Accuracy'+str(i+1), 'Missrate'+str(i+1), 'Score'+str(i+1)]\n",
    "    try:\n",
    "        data = data.drop(columns, axis=1)\n",
    "    except KeyError:\n",
    "        print(\"Colmuns not found: \",columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar la limpieza y preparar los datos que se van a emplear para diseñar el modelo, se va a proceder con la separación entre las variables que se van a empelar para entrenar el modelo y la variable que se quiere predecir. Es decir, se va a diferenciar entre **X**, set con todas las variables excepto si una persona es disléxica o no, e **y**, set que contiene los valores corresondientes a la variable *Dyslexia*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener muchos más casos negativos que positivos se va hacer uso de **SMOTE**, que es técnica de sobremuestreo utilizada en Machine Learning para tratar el problema del desequilibrio de clases, en este caso la desproporción de síes frente a noes. Se va a conseguir que el número de valores positivos sea equivalente al de negativos y de esta manera se mejorará el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "y = data['Dyslexia']\n",
    "X = data.loc[:, data.columns != 'Dyslexia']\n",
    "\n",
    "smote = SMOTE(sampling_strategy = 'minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=4, stratify=y_sm)\n",
    "\n",
    "# Data Standardization -> Good practice working with KNN & LR(based on the distance)\n",
    "X_train_st = preprocessing.StandardScaler().fit(X_train).transform(X_train.astype(float))\n",
    "X_test_st = preprocessing.StandardScaler().fit(X_test).transform(X_test.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dyslexia histogram\n",
    "dyslexia_train = y_train.value_counts()\n",
    "dyslexia_test = y_test.value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "sns.barplot(x=dyslexia_train.index, y=dyslexia_train.values, ax=ax[0])\n",
    "ax[0].set_title('Train set')\n",
    "ax[0].set_ylim([0, 2000])\n",
    "ax[0].grid(True)\n",
    "ax[0].annotate('Non dyslexia values: ' + str(dyslexia_train[0]), xy=(1, dyslexia_train[0]), xytext=(-0.25, dyslexia_train[0] + 20))\n",
    "ax[0].annotate('Dyslexia values: ' + str(dyslexia_train[1]), xy=(1, dyslexia_train[1]), xytext=(0.82, dyslexia_train[1] + 20))\n",
    "\n",
    "sns.barplot(x=dyslexia_test.index, y=dyslexia_test.values, ax=ax[1])\n",
    "ax[1].set_title('Test set')\n",
    "ax[1].set_ylim([0, 600])\n",
    "ax[1].grid(True)\n",
    "ax[1].annotate('Non dyslexia values: ' + str(dyslexia_test[0]), xy=(1, dyslexia_test[0]), xytext=(-0.25, dyslexia_test[0] + 5))\n",
    "ax[1].annotate('Dyslexia values: ' + str(dyslexia_test[1]), xy=(1, dyslexia_test[1]), xytext=(0.82, dyslexia_test[1] + 5))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a proceder a entrenar el modelo. Como se mencionó al inicio del documento se van a emplear cinco algoritmos distintos de Machine Learning, de los cuales se eligirá el que prediga los casos positivos y negativos.\n",
    "\n",
    "Antes de comenzar con el entrenamiento del modelo se van a definir varias funciones con el objetivo de simplificar el código:\n",
    "\n",
    "- `plot_confusion_matrix(cm, classes)`: toma como argumentos de entrada la matriz de confusión del modelo y los valores que se quieren evaluar, en este caso 0's y 1's. Mostrará por pantalla la representación de los aciertos y fallos comparando que casos se han predicho correctamente y cuales no.\n",
    "- `knn_accuracy(X_train, y_train, X_test, y_test, Ks)`: uno de los algoritmos de Machine Learning que se va a entrenar es K-Nearest Neighbors, por lo que es necesario escoger cuidadosamente el número de clusters con el que se va a entrenar el modelo. Mediante esta función, pasando como argumentos de entrada los datos usados para el train y el test y el máximo de clusters que se quieren probar, se imprimirá por pantalla la exactitud (*accuracy*) que tiene el modelo en función de los distintos valores de k\n",
    "- `k_fold_cv(X, y, n, model)`: K-fold  cross-validation se emplea como técnica de evaluación del modelo recursiva. Pasando como argumentos de entrada los datos, el modelo que se quiere testear y la cantidad de iteración que se van a realizar, la función va a dividir de diferente forma los datos n veces y calcular la media de los resultados obtenidos en cada iteración al final. Se ha especificado que devuelva la excatitud del modelo (*score*) y el F1-score de las dos clases, es decir, tanto de los 0's como de los 1's\n",
    "- `evaluate_model(X_train, y_train, X_test, y_test, model)`: esta función va a devolver distintas evaluaciones del modelo, como por ejemplo *Recall*, *Accuracy*, *Jaccard index* o *F1-score*, así como la representación de la matriz de confusión del modelo que se especifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, cmap='Blues')\n",
    "\n",
    "    #add value count to each cell\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 3.\n",
    "    \n",
    "    #labels value count\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #set axis labels\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "\n",
    "    #colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate nº clusters KNN\n",
    "def knn_accuracy(X_train, y_train, X_test, y_test, Ks):\n",
    "    \n",
    "    for n in range(1,Ks):\n",
    "        model = KNeighborsClassifier(n_neighbors=n).fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        acc = metrics.accuracy_score(y_test, y_hat)\n",
    "        print(f\"Value of k: {n} - Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(X, y, n, model):\n",
    "    kf = KFold(n_splits = n)\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    #accuracy\n",
    "    scores = []\n",
    "    #f1 score\n",
    "    f1_score_0 = []\n",
    "    f1_score_1 = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index].values, X.iloc[test_index].values\n",
    "        y_train, y_test = y.iloc[train_index].values, y.iloc[test_index].values\n",
    "        #model prediction \n",
    "        y_hat = model.predict(X_test)\n",
    "        #evaluate the performance of a model (accuracy score)\n",
    "        score = model.score(X_test,y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "    \n",
    "    return \"Accuracy: \"+str(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    #different evaluations\n",
    "    print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, model.predict(X_train)))\n",
    "    print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_hat))\n",
    "    print(\"F1 score: \", f1_score(y_test, y_hat))\n",
    "    print(\"Recall 0's: \", recall_score(y_test, y_hat, pos_label=0))\n",
    "    print(\"Recall 1's: \", recall_score(y_test, y_hat, pos_label=1))\n",
    "    print(\"Jaccard index 0's: \", jaccard_score(y_test, y_hat, pos_label = 0))\n",
    "    print(\"Jaccard index 1's: \", jaccard_score(y_test, y_hat, pos_label = 1))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #classification report\n",
    "    print (classification_report(y_test, y_hat))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_hat, labels=[0,1])\n",
    "    np.set_printoptions(precision = 2)\n",
    "\n",
    "    #plot confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=['No = 0','Yes = 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k: 1 - Accuracy: 0.79\n",
      "Value of k: 2 - Accuracy: 0.84\n",
      "Value of k: 3 - Accuracy: 0.75\n",
      "Value of k: 4 - Accuracy: 0.77\n",
      "Value of k: 5 - Accuracy: 0.70\n",
      "Value of k: 6 - Accuracy: 0.74\n",
      "Value of k: 7 - Accuracy: 0.71\n",
      "Value of k: 8 - Accuracy: 0.73\n",
      "Value of k: 9 - Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy(X_train_st, y_train, X_test_st, y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "#Train Model and Predict  \n",
    "neighbor = KNeighborsClassifier(n_neighbors = k).fit(X_train_st,y_train)\n",
    "y_hat_KNN = neighbor.predict(X_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.8588404533565823'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X, y, 10, neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.999607535321821\n",
      "Test set Accuracy:  0.8385579937304075\n",
      "F1 score:  0.8609986504723347\n",
      "Recall 0's:  0.677115987460815\n",
      "Recall 1's:  1.0\n",
      "Jaccard index 0's:  0.677115987460815\n",
      "Jaccard index 1's:  0.7559241706161137\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.68      0.81       319\n",
      "         1.0       0.76      1.00      0.86       319\n",
      "\n",
      "    accuracy                           0.84       638\n",
      "   macro avg       0.88      0.84      0.83       638\n",
      "weighted avg       0.88      0.84      0.83       638\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_train_st, y_train, X_test_st, y_test, neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict  \n",
    "mod_LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train_st,y_train)\n",
    "y_hat_LR = mod_LR.predict(X_test_st)\n",
    "\n",
    "# Predict the probability of each class for a given input\n",
    "y_hat_prob = mod_LR.predict_proba(X_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.873435047951177'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X, y, 10, mod_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.8685243328100472\n",
      "Test set Accuracy:  0.841692789968652\n",
      "F1 score:  0.8443759630200308\n",
      "Recall 0's:  0.8244514106583072\n",
      "Recall 1's:  0.8589341692789969\n",
      "Jaccard index 0's:  0.7225274725274725\n",
      "Jaccard index 1's:  0.7306666666666667\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.82      0.84       319\n",
      "         1.0       0.83      0.86      0.84       319\n",
      "\n",
      "    accuracy                           0.84       638\n",
      "   macro avg       0.84      0.84      0.84       638\n",
      "weighted avg       0.84      0.84      0.84       638\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_train_st, y_train, X_test_st, y_test, mod_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: svm.SVC(kernel='rbf')\n",
    "# kernel='rbf'\" where 'rbf' stands for radial basis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict \n",
    "mod_SVM = svm.SVC(kernel='poly', degree=15, coef0=7).fit(X_train, y_train) \n",
    "y_hat_SVM = mod_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.9789799476896253'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X, y, 10, mod_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  1.0\n",
      "Test set Accuracy:  0.9388714733542319\n",
      "F1 score:  0.9422222222222223\n",
      "Recall 0's:  0.8808777429467085\n",
      "Recall 1's:  0.9968652037617555\n",
      "Jaccard index 0's:  0.878125\n",
      "Jaccard index 1's:  0.8907563025210085\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.88      0.94       319\n",
      "         1.0       0.89      1.00      0.94       319\n",
      "\n",
      "    accuracy                           0.94       638\n",
      "   macro avg       0.94      0.94      0.94       638\n",
      "weighted avg       0.94      0.94      0.94       638\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_train, y_train, X_test, y_test, mod_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict \n",
    "mod_rfc = RandomForestClassifier(n_estimators = 6, max_depth = 5, min_samples_leaf = 5).fit(X_train , y_train)\n",
    "y_hat_RF = mod_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.866422551583842'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X, y, 10, mod_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.9105180533751962\n",
      "Test set Accuracy:  0.8699059561128527\n",
      "F1 score:  0.8709175738724727\n",
      "Recall 0's:  0.8620689655172413\n",
      "Recall 1's:  0.877742946708464\n",
      "Jaccard index 0's:  0.7681564245810056\n",
      "Jaccard index 1's:  0.7713498622589532\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.86      0.87       319\n",
      "         1.0       0.86      0.88      0.87       319\n",
      "\n",
      "    accuracy                           0.87       638\n",
      "   macro avg       0.87      0.87      0.87       638\n",
      "weighted avg       0.87      0.87      0.87       638\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_train, y_train, X_test, y_test, mod_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tree Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict \n",
    "tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 10).fit(X_train, y_train)\n",
    "y_hat_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.9520691659401337'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X, y, 10, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.9894034536891679\n",
      "Test set Accuracy:  0.8871473354231975\n",
      "F1 score:  0.8905775075987843\n",
      "Recall 0's:  0.8557993730407524\n",
      "Recall 1's:  0.9184952978056427\n",
      "Jaccard index 0's:  0.7913043478260869\n",
      "Jaccard index 1's:  0.8027397260273973\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88       319\n",
      "         1.0       0.86      0.92      0.89       319\n",
      "\n",
      "    accuracy                           0.89       638\n",
      "   macro avg       0.89      0.89      0.89       638\n",
      "weighted avg       0.89      0.89      0.89       638\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_train, y_train, X_test, y_test, tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
