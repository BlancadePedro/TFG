{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Detección de la Dislexia aplicando Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a desarrollar un modelo en Machine Learning que sea capaz de detectar si, tras contestar a 32 questiones y teniendo en cuenta el género, la lengua y la edad, una persona es disléxica o no. Cada modelo se va a entrenar y testear con dos datasets distintos: desktop.csv (Train) y tablet.csv (Test).\n",
    "\n",
    "\n",
    "Para ello se va a emplear Machine Learning, importando las librerías de python. Los algoritmos que se van a implementar son:\n",
    "1. K-Nearest Neighbors\n",
    "2. Logistic Regression\n",
    "3. Support Vector Machines\n",
    "4. Random Forest\n",
    "5. Tree Decision\n",
    "\n",
    "Y finalmente, en caso de que de tiempo:\n",
    "\n",
    "6. Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contiuación, se van a importar las librerías necesarias para desarrollar el modelo de Machine Learning:\n",
    "- Pandas: proporcina herramientas para el análisis de datos. Mediante esta herramienta se va leer el documento .csv donde se encuentran los datos y se van a manipular con el propósito de diseñar el modelo de Mchine Learning.\n",
    "- NumPy y Matplotlib: se emplearán para el análisis y la visualización de datos. NumPy permite realizar operación y  matemáticas y manejar datos numéricos de manera eficiente y efectiva. Por otro lado, Matplotlib permite crear gráficas para visualizar los datos de manera simple y clara. \n",
    "- Seaborn: al igual que Matplotlib, se trata de una librería de visualización de datos. Sin embargo, ofrece una visualización estadística, la cua va a ser de gran utilidad para analizar la distribución de los datos.\n",
    "- Warnings: gestionará las advertencias que surjan durante la ejecución del programa. En concreto se va a hacer uso de `warnings.filterwarnings('ignore')` consiguiendo ignorar las posibles advertencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, para el entrenamiento y el testeo de los distintos algoritmos de Machine Learning, se van a importar las librerías **Scikit-Learn** y para el manejo de desproporción entre casos positivos y negativos se va a importar **Imbalanced-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn\n",
    "# ! pip install imblearn\n",
    "# ! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a comenzar leyendo los datos y exportándolos a la variable *data*, la cual va a contener la información con la que se va a construir el modelo. Mediante la librería **pandas** se va a acceder a la información, siendo capaz de:\n",
    "- Comprobar si existen valores nulos\n",
    "- Transformar todos los datos a valores numéricos\n",
    "- Gestionar los valores nulos\n",
    "- Analizar si hay variedad dentro de cada dataset\n",
    "\n",
    "La información que se va a obtener es:\n",
    "\n",
    "1. Genero (hombre o mujer)\n",
    "2. Lengua nativa es el español\n",
    "3. Lengua nativa distinta al español\n",
    "4. Edad \n",
    "5. Información relacionada con las preguntas\n",
    "6. Disléxico: sí o no\n",
    "\n",
    "La información relacionada con las preguntas contiene el número de clicks que se realizan en cada ejercicio (*Clicks*), diferenciando en respuestas correctas (*Hits*) e incorrectas (*Misses*). A su vez, se cuenta con el resultado final (*Score*), que se obtiene a partir de la cantidad de aciertos por cuestión, junto con la precisión de la respuesta (*Accuracy = Hits/Clicks*) y el ratio de fallo (*Missrate = Misses/Clicks*).\n",
    "\n",
    "Mediante estos valores se pretende predecir si una persona tiene dislexia o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/Dyt-desktop.csv\", delimiter=\";\")\n",
    "pd.set_option(\"display.max_columns\" , None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first look train dataset\n",
    "data.head()\n",
    "data.iloc[:, :10].dtypes\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha creado una función `prep_Data(df)`que toma como atributo de entrada un dataset y transforma los valores de las columnas *Gender, Nativelang, Otherlang y Dyslexia* en 0's o 1's, en función de su valor incial. De esta forma solo se trabajará con valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_Data(ds) :\n",
    "    #ds.column -> access to the column specified\n",
    "    #map() -> itarates through the column specified\n",
    "    ds['Gender']=ds.Gender.map({'Male': 0, 'Female': 1})\n",
    "    ds['Dyslexia']=ds.Dyslexia.map({'No': 0, 'Yes': 1})\n",
    "    ds['Nativelang']=ds.Nativelang.map({'No': 0, 'Yes': 1})\n",
    "    ds['Otherlang']=ds.Otherlang.map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_Data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al contar con una desproporción muy elevada entre casos positivos y negativos de dislexia entre los datos se va a optar por aumentar el número de datos del dataset, mediante la librería **RandomOverSampler**, de forma que la cantidad de sies sea igual que la de noes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_dyslexia_no, count_dyslexia_yes = data.Dyslexia.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "dyslexia_no_df = data[data['Dyslexia'] == 0]\n",
    "dyslexia_yes_df = data[data['Dyslexia'] == 1]\n",
    "\n",
    "# Oversample 0-class and concat the DataFrames of both class\n",
    "dyslexia_yes_df = dyslexia_yes_df.sample(count_dyslexia_no, replace = True)\n",
    "data = pd.concat([dyslexia_no_df, dyslexia_yes_df], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(data.Dyslexia.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicated data from  Data Set: \",data.index.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras transformar todos los valores del dataframe en numéricos, se va a asegurar que todos los valores sean tipo flotantes mediante la instrucción: `dataset.apply(lambda x: x.astype('float', errors='ignore'))` donde se aplica el cambio de *int* a *flot* mediante la función `astype()` dentro de una función *lambda* que recorre cada columna, accediendo a su contenido y modificándolo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.astype('float', errors='ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se haya transformado el tipo de valor con el que se está trabajando se va a comprobar que solo contiene valores del tipo *float64*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data type of each column\n",
    "for col in data.columns:\n",
    "    if data[col].dtypes != \"float64\":\n",
    "        print(\"Column {} is not a float, it is {}\".format(col, data[col].dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez exportados los datos se va a comporbar si hay valores nulos mediante la función `[col for col in test_df.columns if train_df[col].isnull().any()]`. \n",
    "- Mediante el bucle `for col in` se van a recorrer todas las columna y acceder a sus valores.  \n",
    "- Mediante el condicional `if train_df[col].isnull().any()`se va a comprobar si alguno de los datos de la columna que se está analizando es nulo o no. \n",
    "\n",
    "En caso de que se encuentre un valor nulo, el atributo de salida `col` tomará el valor de dicha columna y se añadirá a una lista (función entre `[ ]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = [np.number])\n",
    "data.isnull().values.any()\n",
    "data_null_values = data.isna().sum().sum()\n",
    "data_null_col = [col for col in data.columns if data[col].isnull().any()]\n",
    "data_null_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a prescindir de todos los valores mayores a uno en las columnas *Accuracy* y *Missrate*. Los valores mencionados representan porcentajes, por lo que no pueden superar la unidad, sin embargo, si se estudia en detalle cada variable existen valores que no cumplen este requisito dando lugar a error si no se corrige."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_manually(df):\n",
    "    print(\"Old Shape: \", df.shape)\n",
    "    \n",
    "    #Accuracy and Missrate\n",
    "    for i in range(int(df.shape[1]/6)):\n",
    "        col_acc_rate = df.columns[8+6*i:10+6*i]\n",
    "        for j in col_acc_rate:\n",
    "            df.drop(df[df[j] > 1].index, inplace=True)\n",
    "    print(\"New Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers_manually(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se va a proceder con la eliminación de los outliers, es decir, se va a prescindir de aquellos valores que se consideren anómalos. Para ello se van a emplear dos funciones *.describe()* y *sns.distplot(col)*. La primera  se utiliza para representar la distribución de los datos en un gráfico. Va a permitir visualizar la forma en que los datos están distribuidos en los datasets disponibles. A simple vista, se puede identificar como hay valores máximos que están muy alejados del percentil 75, por lo que se puede intuir que se trata de un outlier.\n",
    "\n",
    "A su vez, la función `countplot` es útil para identificar cuantos valores positivos y negativos hay de dislexia. Se va a representar visualmente, permitiendo comparar si la muestra que se está usando es representativa de la población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras observar la distribución del *dataset* original y comprobar como sí presenta outliers, se va a proceder con el análisis y la eliminación de aquellos valores que no aporten información válida y vayan a afectar negativamente al modelo.\n",
    "\n",
    "La función `distplot` se va a emplear para identificar la forma en que los datos están distribuidos, verificando si siguen una distribución normal o no, como afecta la presencia de outliers a la distribución y cual es la media y la desviación estándar. Es decir, se va a representar visualmente la distribución de los datos de cada variable.\n",
    "\n",
    "La función `boxplot` representa el rango intercuartílico (IQR) de los datos. La caja (gráfico) va desde el primer cuartil (Q1) hasta el tercer cuartil (Q3), y su longitud representa el rango intercuartílico (IQR = Q3 - Q1). Los valores atípicos (outliers) son aquellos que están fuera del rango definido por 1,5 veces el IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(df):\n",
    "    \n",
    "    rest = df.shape[1] % 4\n",
    "    rows = df.shape[1]//4\n",
    "    \n",
    "    if rest == 0:\n",
    "        rows = rows\n",
    "    else:\n",
    "        rows = rows + 1\n",
    "        \n",
    "    fig, ax = plt.subplots(ncols = 4, nrows = rows, figsize = (15, 150))\n",
    "    i = 0\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for col in df.columns:\n",
    "        plt.title(col)\n",
    "        sns.distplot(df[col], ax=ax[i])\n",
    "        i+=1\n",
    "    plt.tight_layout(pad = 0.5, w_pad = 0.7, h_pad = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_whisker(df):\n",
    "    \n",
    "    rest = df.shape[1] % 4\n",
    "    rows = df.shape[1]//4\n",
    "    \n",
    "    if rest == 0:\n",
    "        rows = rows\n",
    "    else:\n",
    "        rows = rows + 1\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 4, nrows = rows, figsize = (15, 150))\n",
    "    i = 0\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        plt.title(col)\n",
    "        df.boxplot([col], ax=ax[i])\n",
    "        i+=1\n",
    "    plt.tight_layout(pad = 0.5, w_pad = 0.7, h_pad = 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a trabajar solo con las variables relativas a las preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Q = data.drop(columns = ['Gender','Nativelang','Otherlang','Age','Dyslexia'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(data_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentile method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la eleminación de outliers existen varias técnicas, como Z-score method, Inter Quartile Range Method o Percentile method. la técnica que se ha elegido es el método de percentil ya que es fácil de entender y aplicar, y no requiere de una distribución específica. Como se ha podido observar, no todas las variables tienen la misma distribución, lo que podría suponer un problema utilizando Z-score o el método del Intercuartil.\n",
    "\n",
    "Se trata de un método robusto a la presencia de valores atípicos en los datos, lo que lo hace menos propenso a ser afectado por ellos, y permite ajustar los límites al dataset con el que se esté trabajando. En este caso, para no prescindir de un gran número de datos, aun eliminando aquellos datos que influían negativamente al modelo, se han establecido como umbral superior el 0.999 e inferior el 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(ds):\n",
    "    print(\"Old Shape: \", ds.shape)\n",
    "    \n",
    "    rng = ds.columns\n",
    "    for col in rng:\n",
    "        #first percentile\n",
    "        min_threshold = ds[col].quantile(0.001)\n",
    "        #third percentile\n",
    "        max_threshold = ds[col].quantile(0.999)\n",
    "        \n",
    "        ds.drop(ds[(ds[col] < min_threshold) | (ds[col] > max_threshold)].index, inplace=True)\n",
    "        \n",
    "    print(\"New Shape: \", ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers(data_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representando de nuevo los gráficos de distribución se puede observar como la presencia de outliers ha disminuido considerablemente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(data_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan aquellas filas que contienen valores anómalos de los datasets inciales, recuperando las columnas: 'Gender', 'Nativelang', 'Otherlang', 'Age', 'Dyslexia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data_Q.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se van a definir dos funciones nuevas, `corr_hit_miss`y `corr_acc_missrate`, para comparar como de correladas están las variables *Clicks*, *Hits*, *Misses* y *Score* y la suma de las variables *Hits y Misses* con *Clicks*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_hit_miss(ds_orig, nombre):\n",
    "    ds = ds_orig.copy()\n",
    "    print(nombre+\" dataset\")\n",
    "    for i in range(32):\n",
    "        try:        \n",
    "            print(\"Question\", str(i+1))\n",
    "            #Pearson correlation coef\n",
    "            correlation_misses = ds['Clicks'+str(i+1)].corr(ds['Misses'+str(i+1)])\n",
    "            correlation_hits = ds['Clicks'+str(i+1)].corr(ds['Hits'+str(i+1)])\n",
    "            correlation_score = ds['Clicks'+str(i+1)].corr(ds['Score'+str(i+1)])\n",
    "\n",
    "            ds['Hits + Misses'+str(i+1)] = ds['Hits'+str(i+1)] + ds['Misses'+str(i+1)]\n",
    "            correlation_sum = ds['Clicks'+str(i+1)].corr(ds['Hits + Misses'+str(i+1)])\n",
    "\n",
    "            print(\"Misses\", str(i+1), correlation_misses)\n",
    "            print(\"Hits\", str(i+1), correlation_hits)\n",
    "            print(\"Score\", str(i+1), correlation_score)\n",
    "            print(\"Hits + Misses\", str(i+1), correlation_sum)\n",
    "        except KeyError:\n",
    "            print(\"Question \"+str(i+1)+\" not in the dataset\")\n",
    "            \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_acc_missrate(ds_orig, nombre):\n",
    "    ds = ds_orig.copy()\n",
    "    print(nombre+\" dataset\")\n",
    "    for i in  range(32):\n",
    "        try:\n",
    "            print(\"Question\"+str(i+1))\n",
    "            #Pearson correlation coeff\n",
    "            correlation_acc = ds['Hits'+str(i+1)].corr(ds['Accuracy'+str(i+1)])\n",
    "            correlation_missrate = ds['Misses'+str(i+1)].corr(ds['Missrate'+str(i+1)])\n",
    "            correlation_accs_rate = ds['Accuracy'+str(i+1)].corr(ds['Missrate'+str(i+1)])\n",
    "\n",
    "            print(\"Accuracy\"+str(i+1),correlation_acc)\n",
    "            print(\"Missrate\"+str(i+1),correlation_missrate)\n",
    "            print(\"Between Accuracy and Missrate\"+str(i+1),correlation_accs_rate)\n",
    "        except KeyError:\n",
    "            print(\"Question \"+str(i+1)+\" not in the dataset\")\n",
    "            \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprobará tanto para los dataset de entrenamiento, como de prueba y diferenciando entre los cuatro casos distintos tras aplicar las técnicas de gestión de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_hit_miss(data, \"Model\")\n",
    "corr_acc_missrate(data, \"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    columns = ['Accuracy'+str(i+1), 'Missrate'+str(i+1), 'Score'+str(i+1)]\n",
    "    try:\n",
    "        \n",
    "        data = data.drop(columns, axis=1)\n",
    "    except KeyError:\n",
    "        print(\"Colmuns not found: \",columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar la limpieza y preparar los datos que se van a emplear para diseñar el modelo, se va a proceder con la separación entre las variables que se van a empelar para entrenar el modelo y la variable que se quiere predecir. Es decir, se va a diferenciar entre **X**, set con todas las variables excepto si una persona es disléxica o no, e **y**, set que contiene los valores corresondientes a la variable *Dyslexia*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data['Dyslexia']\n",
    "X = data.loc[:, data.columns != 'Dyslexia']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, stratify = y)\n",
    "\n",
    "# Data Standardization -> Good practice working with KNN (based on the distance)\n",
    "X_train_st = preprocessing.StandardScaler().fit(X_train).transform(X_train.astype(float))\n",
    "X_test_st = preprocessing.StandardScaler().fit(X_test).transform(X_test.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type\n",
    "print(\"Tipo de datos de X_train_st:\", type(X_train))\n",
    "print(\"Tipo de datos de y_train:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dyslexia histogram \n",
    "dyslexia_train = y_train.value_counts()\n",
    "dyslexia_test = y_test.value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "sns.barplot(x=dyslexia_train.index, y=dyslexia_train.values, ax=ax[0])\n",
    "ax[0].set_title('Train set')\n",
    "ax[0].set_ylim([0, 2000])\n",
    "ax[0].grid(True)\n",
    "ax[0].annotate('Non dyslexia values: ' + str(dyslexia_train[0]), xy=(1, dyslexia_train[0]), xytext=(-0.25, dyslexia_train[0] + 20))\n",
    "ax[0].annotate('Dyslexia values: ' + str(dyslexia_train[1]), xy=(1, dyslexia_train[1]), xytext=(0.82, dyslexia_train[1] + 20))\n",
    "\n",
    "sns.barplot(x=dyslexia_test.index, y=dyslexia_test.values, ax=ax[1])\n",
    "ax[1].set_title('Test set')\n",
    "ax[1].set_ylim([0, 600])\n",
    "ax[1].grid(True)\n",
    "ax[1].annotate('Non dyslexia values: ' + str(dyslexia_test[0]), xy=(1, dyslexia_test[0]), xytext=(-0.25, dyslexia_test[0] + 5))\n",
    "ax[1].annotate('Dyslexia values: ' + str(dyslexia_test[1]), xy=(1, dyslexia_test[1]), xytext=(0.82, dyslexia_test[1] + 5))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a proceder a entrenar el modelo. Como se mencionó al inicio del documento se van a emplear cinco algoritmos distintos de Machine Learning, de los cuales se eligirá el que prediga los casos positivos y negativos.\n",
    "\n",
    "Antes de comenzar con el entrenamiento del modelo se van a definir varias funciones con el objetivo de simplificar el código:\n",
    "\n",
    "- `plot_confusion_matrix(cm, classes)`: toma como argumentos de entrada la matriz de confusión del modelo y los valores que se quieren evaluar, en este caso 0's y 1's. Mostrará por pantalla la representación de los aciertos y fallos comparando que casos se han predicho correctamente y cuales no.\n",
    "- `knn_accuracy(X_train, y_train, X_test, y_test, Ks)`: uno de los algoritmos de Machine Learning que se va a entrenar es K-Nearest Neighbors, por lo que es necesario escoger cuidadosamente el número de clusters con el que se va a entrenar el modelo. Mediante esta función, pasando como argumentos de entrada los datos usados para el train y el test y el máximo de clusters que se quieren probar, se imprimirá por pantalla la exactitud (*accuracy*) que tiene el modelo en función de los distintos valores de k\n",
    "- `k_fold_cv(X, y, n, model)`: K-fold  cross-validation se emplea como técnica de evaluación del modelo recursiva. Pasando como argumentos de entrada los datos, el modelo que se quiere testear y la cantidad de iteración que se van a realizar, la función va a dividir de diferente forma los datos n veces y calcular la media de los resultados obtenidos en cada iteración al final. Se ha especificado que devuelva la excatitud del modelo (*score*) y el F1-score de las dos clases, es decir, tanto de los 0's como de los 1's\n",
    "- `evaluate_model(X_train, y_train, X_test, y_test, model)`: esta función va a devolver distintas evaluaciones del modelo, como por ejemplo *Recall*, *Accuracy*, *Jaccard index* o *F1-score*, así como la representación de la matriz de confusión del modelo que se especifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, cmap='Blues')\n",
    "\n",
    "    #add value count to each cell\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 3.\n",
    "    \n",
    "    #labels value count\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #set axis labels\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "\n",
    "    #colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate nº clusters KNN\n",
    "def knn_accuracy(X_train, y_train, X_test, y_test, Ks):\n",
    "    \n",
    "    for n in range(1,Ks):\n",
    "        model = KNeighborsClassifier(n_neighbors=n).fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        acc = metrics.accuracy_score(y_test, y_hat)\n",
    "        print(f\"Value of k: {n} - Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(X, y, n, model):\n",
    "    kf = KFold(n_splits = n)\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    #accuracy\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index].values, X.iloc[test_index].values\n",
    "        y_train, y_test = y.iloc[train_index].values, y.iloc[test_index].values\n",
    "        #model prediction \n",
    "        y_hat = model.predict(X_test)\n",
    "        #evaluate the performance of a model (accuracy score)\n",
    "        score = model.score(X_test,y_test)\n",
    "        scores.append(score)\n",
    "        \n",
    "    \n",
    "    return \"Accuracy: \"+str(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    #different evaluations\n",
    "    print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, model.predict(X_train)))\n",
    "    print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_hat))\n",
    "    '''\n",
    "    print(\"Recall 0's: \", recall_score(y_test, y_hat, pos_label=0))\n",
    "    print(\"Recall 1's: \", recall_score(y_test, y_hat, pos_label=1))\n",
    "    print(\"F1 score 0's: \", f1_score(y_test, y_hat, pos_label=0))\n",
    "    print(\"F1 score 1's: \", f1_score(y_test, y_hat, pos_label=1))\n",
    "    '''\n",
    "    print(\"Jaccard index 0's: \", jaccard_score(y_test, y_hat, pos_label = 0))\n",
    "    print(\"Jaccard index 1's: \", jaccard_score(y_test, y_hat, pos_label = 1))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #classification report\n",
    "    print (classification_report(y_test, y_hat))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_hat, labels=[0,1])\n",
    "    np.set_printoptions(precision = 2)\n",
    "\n",
    "    #plot confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=['No = 0','Yes = 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy(X_train_st, y_train, X_test_st, y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "#Train Model and Predict  \n",
    "neighbor = KNeighborsClassifier(n_neighbors = k).fit(X_train_st,y_train)\n",
    "y_hat_KNN = neighbor.predict(X_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cv(X, y, 10, neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_model(X_train_st, y_train, X_test_st, y_test, neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict  \n",
    "mod_LR = LogisticRegression(solver='liblinear').fit(X_train_st,y_train)\n",
    "y_hat_LR = mod_LR.predict(X_test_st)\n",
    "\n",
    "# Predict the probability of each class for a given input\n",
    "y_hat_prob = mod_LR.predict_proba(X_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cv(X, y, 10, mod_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_train_st, y_train, X_test_st, y_test, mod_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: svm.SVC(kernel='rbf')\n",
    "# kernel='rbf'\" where 'rbf' stands for radial basis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict \n",
    "mod_SVM = svm.SVC(kernel='poly', degree=15, coef0=7, random_state=42).fit(X_train, y_train) \n",
    "y_hat_SVM = mod_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cv(X, y, 10, mod_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_train, y_train, X_test, y_test, mod_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict \n",
    "mod_rfc = RandomForestClassifier(n_estimators = 30, max_depth = 7, min_samples_leaf = 7).fit(X_train , y_train)\n",
    "y_hat_RF = mod_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cv(X, y, 10, mod_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_train, y_train, X_test, y_test, mod_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tree Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict \n",
    "tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 15).fit(X_train, y_train)\n",
    "y_hat_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cv(X, y, 10, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_train, y_train, X_test, y_test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
