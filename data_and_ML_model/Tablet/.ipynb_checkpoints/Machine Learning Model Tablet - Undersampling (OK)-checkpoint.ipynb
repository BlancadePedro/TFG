{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Detección de la Dislexia aplicando Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a desarrollar un modelo en Machine Learning que sea capaz de detectar si, tras contestar a 32 questiones y teniendo en cuenta el género, la lengua y la edad, una persona es disléxica o no. Cada modelo se va a entrenar y testear con dos datasets distintos: desktop.csv (Train) y tablet.csv (Test).\n",
    "\n",
    "\n",
    "Para ello se va a emplear Machine Learning, importando las librerías de python. Los algoritmos que se van a implementar son:\n",
    "1. K-Nearest Neighbors\n",
    "2. Logistic Regression\n",
    "3. Support Vector Machines\n",
    "4. Random Forest\n",
    "5. Tree Decision\n",
    "\n",
    "Y finalmente, en caso de que de tiempo:\n",
    "\n",
    "6. Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contiuación, se van a importar las librerías necesarias para desarrollar el modelo de Machine Learning:\n",
    "- Pandas: proporcina herramientas para el análisis de datos. Mediante esta herramienta se va leer el documento .csv donde se encuentran los datos y se van a manipular con el propósito de diseñar el modelo de Mchine Learning.\n",
    "- NumPy y Matplotlib: se emplearán para el análisis y la visualización de datos. NumPy permite realizar operación y  matemáticas y manejar datos numéricos de manera eficiente y efectiva. Por otro lado, Matplotlib permite crear gráficas para visualizar los datos de manera simple y clara. \n",
    "- Seaborn: al igual que Matplotlib, se trata de una librería de visualización de datos. Sin embargo, ofrece una visualización estadística, la cua va a ser de gran utilidad para analizar la distribución de los datos.\n",
    "- Warnings: gestionará las advertencias que surjan durante la ejecución del programa. En concreto se va a hacer uso de `warnings.filterwarnings('ignore')` consiguiendo ignorar las posibles advertencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, para el entrenamiento y el testeo de los distintos algoritmos de Machine Learning, se van a importar las librerías **Scikit-Learn** y para el manejo de desproporción entre casos positivos y negativos se va a importar **Imbalanced-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U scikit-learn\n",
    "#!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a comenzar leyendo los datos y exportándolos a las variables *train_df* y *test_df*. Estos datasets van a contener la información con la que se va a construir el modelo. Mediante la librería **pandas** se va a acceder a ellos, siendo capaz de:\n",
    "- Comprobar si existen valores nulos\n",
    "- Transformar todos los datos a valores numéricos\n",
    "- Gestionar los valores nulos\n",
    "- Analizar si hay variedad dentro de cada dataset\n",
    "\n",
    "La información que se va a obtener de cada dataset es:\n",
    "\n",
    "1. Genero (hombre o mujer)\n",
    "2. Lengua nativa es el español\n",
    "3. Lengua nativa distinta al español\n",
    "4. Edad \n",
    "5. Información relacionada con las preguntas\n",
    "6. Disléxico: sí o no\n",
    "\n",
    "La información relacionada con las preguntas contiene el número de clicks que se realizan en cada ejercicio (*Clicks*), diferenciando en respuestas correctas (*Hits*) e incorrectas (*Misses*). A su vez, se cuenta con el resultado final (*Score*), que se obtiene a partir de la cantidad de aciertos por cuestión, junto con la precisión de la respuesta (*Accuracy = Hits/Clicks*) y el ratio de fallo (*Missrate = Misses/Clicks*).\n",
    "\n",
    "Mediante estos valores se pretende predecir si una persona tiene dislexia o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/Dyt-tablet.csv\", delimiter=\";\")\n",
    "pd.set_option(\"display.max_columns\" , None)\n",
    "\n",
    "pd.set_option(\"display.max_columns\" , None)\n",
    "pd.set_option(\"display.max_rows\" , None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1395, 197)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look train dataset\n",
    "data.head()\n",
    "data.iloc[:, :10].dtypes\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha creado una función `prep_Data(df)`que toma como atributo de entrada un dataset y transforma los valores de las columnas *Gender, Nativelang, Otherlang y Dyslexia* en 0's o 1's, en función de su valor incial. De esta forma solo se trabajará con valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_Data(df) :\n",
    "    #ds.column: access to the column specified\n",
    "    #map(): itarates through the column specified\n",
    "    df['Gender'] = df.Gender.map({'Male': 0, 'Female': 1})\n",
    "    df['Nativelang'] = df.Nativelang.map({'No': 0, 'Yes': 1})\n",
    "    df['Otherlang'] = df.Otherlang.map({'No': 0, 'Yes': 1})\n",
    "    df['Dyslexia'] = df.Dyslexia.map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data\n",
    "prep_Data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al contar con una desproporción muy elevada entre casos positivos y negativos de dislexia entre los datos se va a optar por disminuir el número de datos del dataset, mediante la librería **RandomOverSampler**, de forma que la cantidad de sies sea igual que la de noes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling Test:\n",
      "1    148\n",
      "0    148\n",
      "Name: Dyslexia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_D_no, count_D_yes = data.Dyslexia.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "D_no_df = data[data['Dyslexia'] == 0]\n",
    "D_yes_df = data[data['Dyslexia'] == 1]\n",
    "\n",
    "# Oversample 0-class and concat the DataFrames of both class\n",
    "D_no_df = D_no_df.sample(count_D_yes)\n",
    "data = pd.concat([D_no_df, D_yes_df], axis=0)\n",
    "\n",
    "print('Random under-sampling Test:')\n",
    "print(data.Dyslexia.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated data from Train Set:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated data from Train Set: \",data.index.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nativelang</th>\n",
       "      <th>Otherlang</th>\n",
       "      <th>Age</th>\n",
       "      <th>Clicks1</th>\n",
       "      <th>Hits1</th>\n",
       "      <th>Misses1</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Accuracy1</th>\n",
       "      <th>Missrate1</th>\n",
       "      <th>Clicks2</th>\n",
       "      <th>Hits2</th>\n",
       "      <th>Misses2</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Accuracy2</th>\n",
       "      <th>Missrate2</th>\n",
       "      <th>Clicks3</th>\n",
       "      <th>Hits3</th>\n",
       "      <th>Misses3</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Accuracy3</th>\n",
       "      <th>Missrate3</th>\n",
       "      <th>Clicks4</th>\n",
       "      <th>Hits4</th>\n",
       "      <th>Misses4</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Accuracy4</th>\n",
       "      <th>Missrate4</th>\n",
       "      <th>Clicks5</th>\n",
       "      <th>Hits5</th>\n",
       "      <th>Misses5</th>\n",
       "      <th>Score5</th>\n",
       "      <th>Accuracy5</th>\n",
       "      <th>Missrate5</th>\n",
       "      <th>Clicks6</th>\n",
       "      <th>Hits6</th>\n",
       "      <th>Misses6</th>\n",
       "      <th>Score6</th>\n",
       "      <th>Accuracy6</th>\n",
       "      <th>Missrate6</th>\n",
       "      <th>Clicks7</th>\n",
       "      <th>Hits7</th>\n",
       "      <th>Misses7</th>\n",
       "      <th>Score7</th>\n",
       "      <th>Accuracy7</th>\n",
       "      <th>Missrate7</th>\n",
       "      <th>Clicks8</th>\n",
       "      <th>Hits8</th>\n",
       "      <th>Misses8</th>\n",
       "      <th>Score8</th>\n",
       "      <th>Accuracy8</th>\n",
       "      <th>Missrate8</th>\n",
       "      <th>Clicks9</th>\n",
       "      <th>Hits9</th>\n",
       "      <th>Misses9</th>\n",
       "      <th>Score9</th>\n",
       "      <th>Accuracy9</th>\n",
       "      <th>Missrate9</th>\n",
       "      <th>Clicks10</th>\n",
       "      <th>Hits10</th>\n",
       "      <th>Misses10</th>\n",
       "      <th>Score10</th>\n",
       "      <th>Accuracy10</th>\n",
       "      <th>Missrate10</th>\n",
       "      <th>Clicks11</th>\n",
       "      <th>Hits11</th>\n",
       "      <th>Misses11</th>\n",
       "      <th>Score11</th>\n",
       "      <th>Accuracy11</th>\n",
       "      <th>Missrate11</th>\n",
       "      <th>Clicks12</th>\n",
       "      <th>Hits12</th>\n",
       "      <th>Misses12</th>\n",
       "      <th>Score12</th>\n",
       "      <th>Accuracy12</th>\n",
       "      <th>Missrate12</th>\n",
       "      <th>Clicks13</th>\n",
       "      <th>Hits13</th>\n",
       "      <th>Misses13</th>\n",
       "      <th>Score13</th>\n",
       "      <th>Accuracy13</th>\n",
       "      <th>Missrate13</th>\n",
       "      <th>Clicks14</th>\n",
       "      <th>Hits14</th>\n",
       "      <th>Misses14</th>\n",
       "      <th>Score14</th>\n",
       "      <th>Accuracy14</th>\n",
       "      <th>Missrate14</th>\n",
       "      <th>Clicks15</th>\n",
       "      <th>Hits15</th>\n",
       "      <th>Misses15</th>\n",
       "      <th>Score15</th>\n",
       "      <th>Accuracy15</th>\n",
       "      <th>Missrate15</th>\n",
       "      <th>Clicks16</th>\n",
       "      <th>Hits16</th>\n",
       "      <th>Misses16</th>\n",
       "      <th>Score16</th>\n",
       "      <th>Accuracy16</th>\n",
       "      <th>Missrate16</th>\n",
       "      <th>Clicks17</th>\n",
       "      <th>Hits17</th>\n",
       "      <th>Misses17</th>\n",
       "      <th>Score17</th>\n",
       "      <th>Accuracy17</th>\n",
       "      <th>Missrate17</th>\n",
       "      <th>Clicks18</th>\n",
       "      <th>Hits18</th>\n",
       "      <th>Misses18</th>\n",
       "      <th>Score18</th>\n",
       "      <th>Accuracy18</th>\n",
       "      <th>Missrate18</th>\n",
       "      <th>Clicks19</th>\n",
       "      <th>Hits19</th>\n",
       "      <th>Misses19</th>\n",
       "      <th>Score19</th>\n",
       "      <th>Accuracy19</th>\n",
       "      <th>Missrate19</th>\n",
       "      <th>Clicks20</th>\n",
       "      <th>Hits20</th>\n",
       "      <th>Misses20</th>\n",
       "      <th>Score20</th>\n",
       "      <th>Accuracy20</th>\n",
       "      <th>Missrate20</th>\n",
       "      <th>Clicks21</th>\n",
       "      <th>Hits21</th>\n",
       "      <th>Misses21</th>\n",
       "      <th>Score21</th>\n",
       "      <th>Accuracy21</th>\n",
       "      <th>Missrate21</th>\n",
       "      <th>Clicks22</th>\n",
       "      <th>Hits22</th>\n",
       "      <th>Misses22</th>\n",
       "      <th>Score22</th>\n",
       "      <th>Accuracy22</th>\n",
       "      <th>Missrate22</th>\n",
       "      <th>Clicks23</th>\n",
       "      <th>Hits23</th>\n",
       "      <th>Misses23</th>\n",
       "      <th>Score23</th>\n",
       "      <th>Accuracy23</th>\n",
       "      <th>Missrate23</th>\n",
       "      <th>Clicks24</th>\n",
       "      <th>Hits24</th>\n",
       "      <th>Misses24</th>\n",
       "      <th>Score24</th>\n",
       "      <th>Accuracy24</th>\n",
       "      <th>Missrate24</th>\n",
       "      <th>Clicks25</th>\n",
       "      <th>Hits25</th>\n",
       "      <th>Misses25</th>\n",
       "      <th>Score25</th>\n",
       "      <th>Accuracy25</th>\n",
       "      <th>Missrate25</th>\n",
       "      <th>Clicks26</th>\n",
       "      <th>Hits26</th>\n",
       "      <th>Misses26</th>\n",
       "      <th>Score26</th>\n",
       "      <th>Accuracy26</th>\n",
       "      <th>Missrate26</th>\n",
       "      <th>Clicks27</th>\n",
       "      <th>Hits27</th>\n",
       "      <th>Misses27</th>\n",
       "      <th>Score27</th>\n",
       "      <th>Accuracy27</th>\n",
       "      <th>Missrate27</th>\n",
       "      <th>Clicks28</th>\n",
       "      <th>Hits28</th>\n",
       "      <th>Misses28</th>\n",
       "      <th>Score28</th>\n",
       "      <th>Accuracy28</th>\n",
       "      <th>Missrate28</th>\n",
       "      <th>Clicks29</th>\n",
       "      <th>Hits29</th>\n",
       "      <th>Misses29</th>\n",
       "      <th>Score29</th>\n",
       "      <th>Accuracy29</th>\n",
       "      <th>Missrate29</th>\n",
       "      <th>Clicks30</th>\n",
       "      <th>Hits30</th>\n",
       "      <th>Misses30</th>\n",
       "      <th>Score30</th>\n",
       "      <th>Accuracy30</th>\n",
       "      <th>Missrate30</th>\n",
       "      <th>Clicks31</th>\n",
       "      <th>Hits31</th>\n",
       "      <th>Misses31</th>\n",
       "      <th>Score31</th>\n",
       "      <th>Accuracy31</th>\n",
       "      <th>Missrate31</th>\n",
       "      <th>Clicks32</th>\n",
       "      <th>Hits32</th>\n",
       "      <th>Misses32</th>\n",
       "      <th>Score32</th>\n",
       "      <th>Accuracy32</th>\n",
       "      <th>Missrate32</th>\n",
       "      <th>Dyslexia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>875.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Nativelang  Otherlang  Age  Clicks1  Hits1  Misses1  Score1  \\\n",
       "817        0           1          0   11       11     11        0      11   \n",
       "51         0           1          0    7        4      4        0       4   \n",
       "636        1           1          0   10       14     14        0      14   \n",
       "1300       1           1          0   15        9      9        0       9   \n",
       "1258       0           1          0   14       13     13        0      13   \n",
       "\n",
       "      Accuracy1  Missrate1  Clicks2  Hits2  Misses2  Score2  Accuracy2  \\\n",
       "817         1.0        0.0        8      8        0       8        1.0   \n",
       "51          1.0        0.0        5      5        0       5        1.0   \n",
       "636         1.0        0.0       10     10        0      10        1.0   \n",
       "1300        1.0        0.0        8      8        0       8        1.0   \n",
       "1258        1.0        0.0       11     11        0      11        1.0   \n",
       "\n",
       "      Missrate2  Clicks3  Hits3  Misses3  Score3  Accuracy3  Missrate3  \\\n",
       "817         0.0        7      7        0       7        1.0        0.0   \n",
       "51          0.0        2      2        0       2        1.0        0.0   \n",
       "636         0.0        8      8        0       8        1.0        0.0   \n",
       "1300        0.0        7      7        0       7        1.0        0.0   \n",
       "1258        0.0        8      8        0       8        1.0        0.0   \n",
       "\n",
       "      Clicks4  Hits4  Misses4  Score4  Accuracy4  Missrate4  Clicks5  Hits5  \\\n",
       "817         3      3        0       3        1.0        0.0        6      4   \n",
       "51          2      1        1       2        0.5        0.5        1      0   \n",
       "636         4      4        0       4        1.0        0.0        7      6   \n",
       "1300        3      3        0       3        1.0        0.0        4      4   \n",
       "1258        4      4        0       4        1.0        0.0        4      2   \n",
       "\n",
       "      Misses5  Score5  Accuracy5  Missrate5  Clicks6  Hits6  Misses6  Score6  \\\n",
       "817         2       6   0.666667   0.333333        5      4        1       5   \n",
       "51          1       1   0.000000   1.000000        3      3        0       3   \n",
       "636         1       7   0.857143   0.142857        3      3        0       3   \n",
       "1300        0       4   1.000000   0.000000        5      4        1       5   \n",
       "1258        2       4   0.500000   0.500000        5      3        2       5   \n",
       "\n",
       "      Accuracy6  Missrate6  Clicks7  Hits7  Misses7  Score7  Accuracy7  \\\n",
       "817         0.8        0.2        1      0        1       1        0.0   \n",
       "51          1.0        0.0        2      1        1       2        0.5   \n",
       "636         1.0        0.0        7      7        0       7        1.0   \n",
       "1300        0.8        0.2        5      5        0       5        1.0   \n",
       "1258        0.6        0.4        8      8        0       8        1.0   \n",
       "\n",
       "      Missrate7  Clicks8  Hits8  Misses8  Score8  Accuracy8  Missrate8  \\\n",
       "817         1.0        5      4        1       5       0.80       0.20   \n",
       "51          0.5        2      2        0       2       1.00       0.00   \n",
       "636         0.0        4      3        1       4       0.75       0.25   \n",
       "1300        0.0        4      4        0       4       1.00       0.00   \n",
       "1258        0.0        5      5        0       5       1.00       0.00   \n",
       "\n",
       "      Clicks9  Hits9  Misses9  Score9  Accuracy9  Missrate9  Clicks10  Hits10  \\\n",
       "817         4      4        0       4        1.0        0.0         7       7   \n",
       "51          2      0        2       2        0.0        1.0         2       0   \n",
       "636         5      3        2       5        0.6        0.4         8       8   \n",
       "1300        3      3        0       3        1.0        0.0         4       4   \n",
       "1258        2      2        0       2        1.0        0.0         6       6   \n",
       "\n",
       "      Misses10  Score10  Accuracy10  Missrate10  Clicks11  Hits11  Misses11  \\\n",
       "817          0        7         1.0         0.0         3       2         1   \n",
       "51           2        2         0.0         1.0         2       2         0   \n",
       "636          0        8         1.0         0.0         6       6         0   \n",
       "1300         0        4         1.0         0.0         4       4         0   \n",
       "1258         0        6         1.0         0.0         7       5         2   \n",
       "\n",
       "      Score11  Accuracy11  Missrate11  Clicks12  Hits12  Misses12  Score12  \\\n",
       "817         3    0.666667    0.333333         4       0         4        4   \n",
       "51          2    1.000000    0.000000         3       2         1        3   \n",
       "636         6    1.000000    0.000000         4       2         2        4   \n",
       "1300        4    1.000000    0.000000         6       6         0        6   \n",
       "1258        7    0.714286    0.285714         5       5         0        5   \n",
       "\n",
       "      Accuracy12  Missrate12  Clicks13  Hits13  Misses13  Score13  Accuracy13  \\\n",
       "817     0.000000    1.000000       4.0     1.0       3.0      4.0    0.250000   \n",
       "51      0.666667    0.333333       NaN     NaN       NaN      NaN         NaN   \n",
       "636     0.500000    0.500000       7.0     5.0       2.0      7.0    0.714286   \n",
       "1300    1.000000    0.000000       7.0     7.0       0.0      7.0    1.000000   \n",
       "1258    1.000000    0.000000       7.0     6.0       1.0      7.0    0.857143   \n",
       "\n",
       "      Missrate13  Clicks14  Hits14  Misses14  Score14  Accuracy14  Missrate14  \\\n",
       "817     0.750000         9       9         0        9         1.0         0.0   \n",
       "51           NaN         5       5         0        5         1.0         0.0   \n",
       "636     0.285714        11      11         0       11         1.0         0.0   \n",
       "1300    0.000000         8       8         0        8         1.0         0.0   \n",
       "1258    0.142857        10      10         0       10         1.0         0.0   \n",
       "\n",
       "      Clicks15  Hits15  Misses15  Score15  Accuracy15  Missrate15  Clicks16  \\\n",
       "817          7       7         0        7         1.0         0.0         5   \n",
       "51           1       1         0        1         1.0         0.0         4   \n",
       "636          5       4         1        5         0.8         0.2         7   \n",
       "1300         6       6         0        6         1.0         0.0         6   \n",
       "1258        10      10         0       10         1.0         0.0         4   \n",
       "\n",
       "      Hits16  Misses16  Score16  Accuracy16  Missrate16  Clicks17  Hits17  \\\n",
       "817        5         0        5         1.0         0.0         5       4   \n",
       "51         4         0        4         1.0         0.0         3       3   \n",
       "636        7         0        7         1.0         0.0         4       3   \n",
       "1300       6         0        6         1.0         0.0         4       4   \n",
       "1258       4         0        4         1.0         0.0         5       4   \n",
       "\n",
       "      Misses17  Score17  Accuracy17  Missrate17  Clicks18  Hits18  Misses18  \\\n",
       "817          1        5        0.80        0.20       5.0     4.0       1.0   \n",
       "51           0        3        1.00        0.00       NaN     NaN       NaN   \n",
       "636          1        4        0.75        0.25       5.0     2.0       3.0   \n",
       "1300         0        4        1.00        0.00       5.0     5.0       0.0   \n",
       "1258         1        5        0.80        0.20       8.0     8.0       0.0   \n",
       "\n",
       "      Score18  Accuracy18  Missrate18  Clicks19  Hits19  Misses19  Score19  \\\n",
       "817       5.0         0.8         0.2       7.0     4.0       3.0      7.0   \n",
       "51        NaN         NaN         NaN       NaN     NaN       NaN      NaN   \n",
       "636       5.0         0.4         0.6       9.0     1.0       8.0      9.0   \n",
       "1300      5.0         1.0         0.0       6.0     6.0       0.0      6.0   \n",
       "1258      8.0         1.0         0.0       5.0     3.0       2.0      5.0   \n",
       "\n",
       "      Accuracy19  Missrate19  Clicks20  Hits20  Misses20  Score20  Accuracy20  \\\n",
       "817     0.571429    0.428571       6.0     0.0       6.0      6.0    0.000000   \n",
       "51           NaN         NaN       NaN     NaN       NaN      NaN         NaN   \n",
       "636     0.111111    0.888889       4.0     1.0       3.0      4.0    0.250000   \n",
       "1300    1.000000    0.000000       3.0     1.0       2.0      3.0    0.333333   \n",
       "1258    0.600000    0.400000       4.0     1.0       3.0      4.0    0.250000   \n",
       "\n",
       "      Missrate20  Clicks21  Hits21  Misses21  Score21  Accuracy21  Missrate21  \\\n",
       "817     1.000000       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "51           NaN       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "636     0.750000       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "1300    0.666667       2.0     0.0       2.0      2.0        0.00        1.00   \n",
       "1258    0.750000       4.0     1.0       3.0      4.0        0.25        0.75   \n",
       "\n",
       "      Clicks22  Hits22  Misses22  Score22  Accuracy22  Missrate22  Clicks23  \\\n",
       "817        5.0     3.0       2.0      5.0    0.600000    0.400000       8.0   \n",
       "51         5.0     4.0       1.0      5.0    0.800000    0.200000       3.0   \n",
       "636        6.0     5.0       1.0      6.0    0.833333    0.166667      11.0   \n",
       "1300       6.0     6.0       0.0      6.0    1.000000    0.000000       6.0   \n",
       "1258      10.0     8.0       2.0     10.0    0.800000    0.200000       8.0   \n",
       "\n",
       "      Hits23  Misses23  Score23  Accuracy23  Missrate23  Clicks24  Hits24  \\\n",
       "817      7.0       1.0      8.0  875.000000  125.000000       5.0     3.0   \n",
       "51       1.0       2.0      3.0    0.333333    0.666667       NaN     NaN   \n",
       "636      6.0       5.0     11.0    0.545455    0.454545       7.0     4.0   \n",
       "1300     6.0       0.0      6.0    1.000000    0.000000       6.0     6.0   \n",
       "1258     5.0       3.0      8.0  625.000000  375.000000       8.0     8.0   \n",
       "\n",
       "      Misses24  Score24  Accuracy24  Missrate24  Clicks25  Hits25  Misses25  \\\n",
       "817        2.0      5.0    0.600000    0.400000       NaN     NaN       NaN   \n",
       "51         NaN      NaN         NaN         NaN       NaN     NaN       NaN   \n",
       "636        3.0      7.0    0.571429    0.428571       NaN     NaN       NaN   \n",
       "1300       0.0      6.0    1.000000    0.000000       6.0     6.0       0.0   \n",
       "1258       0.0      8.0    1.000000    0.000000       9.0     9.0       0.0   \n",
       "\n",
       "      Score25  Accuracy25  Missrate25  Clicks26  Hits26  Misses26  Score26  \\\n",
       "817       NaN         NaN         NaN      11.0    10.0       1.0     11.0   \n",
       "51        NaN         NaN         NaN       NaN     NaN       NaN      NaN   \n",
       "636       NaN         NaN         NaN      13.0     7.0       6.0     13.0   \n",
       "1300      6.0         1.0         0.0      12.0    11.0       1.0     12.0   \n",
       "1258      9.0         1.0         0.0      20.0     8.0      12.0     20.0   \n",
       "\n",
       "      Accuracy26  Missrate26  Clicks27  Hits27  Misses27  Score27  Accuracy27  \\\n",
       "817     0.909091    0.090909      54.0     2.0       3.0     54.0    0.037037   \n",
       "51           NaN         NaN       NaN     NaN       NaN      NaN         NaN   \n",
       "636     0.538462    0.461538      20.0     1.0       1.0     20.0    0.050000   \n",
       "1300    0.916667    0.083333      30.0     3.0       0.0     30.0    0.100000   \n",
       "1258    0.400000    0.600000      56.0     3.0       2.0     56.0    0.053571   \n",
       "\n",
       "      Missrate27  Clicks28  Hits28  Misses28  Score28  Accuracy28  Missrate28  \\\n",
       "817     0.055556      24.0     2.0       1.0     24.0    0.083333    0.041667   \n",
       "51           NaN       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "636     0.050000      38.0     6.0       0.0     38.0    0.157895    0.000000   \n",
       "1300    0.000000      26.0     3.0       1.0     26.0    0.115385    0.038462   \n",
       "1258    0.035714      46.0     5.0       2.0     46.0    0.108696    0.043478   \n",
       "\n",
       "      Clicks29  Hits29  Misses29  Score29  Accuracy29  Missrate29  Clicks30  \\\n",
       "817        NaN     NaN       NaN      NaN         NaN         NaN      21.0   \n",
       "51         NaN     NaN       NaN      NaN         NaN         NaN      11.0   \n",
       "636        NaN     NaN       NaN      NaN         NaN         NaN      21.0   \n",
       "1300       NaN     NaN       NaN      NaN         NaN         NaN      21.0   \n",
       "1258       NaN     NaN       NaN      NaN         NaN         NaN      21.0   \n",
       "\n",
       "      Hits30  Misses30  Score30  Accuracy30  Missrate30  Clicks31  Hits31  \\\n",
       "817      2.0       2.0     21.0    0.095238    0.095238       NaN     NaN   \n",
       "51       0.0       1.0     11.0    0.000000    0.090909       NaN     NaN   \n",
       "636      3.0       1.0     21.0    0.142857    0.047619       NaN     NaN   \n",
       "1300     2.0       2.0     21.0    0.095238    0.095238      35.0     4.0   \n",
       "1258     3.0       1.0     21.0    0.142857    0.047619      57.0     4.0   \n",
       "\n",
       "      Misses31  Score31  Accuracy31  Missrate31  Clicks32  Hits32  Misses32  \\\n",
       "817        NaN      NaN         NaN         NaN       NaN     NaN       NaN   \n",
       "51         NaN      NaN         NaN         NaN       NaN     NaN       NaN   \n",
       "636        NaN      NaN         NaN         NaN       NaN     NaN       NaN   \n",
       "1300       0.0     35.0    0.114286    0.000000      47.0     1.0      10.0   \n",
       "1258       4.0     57.0    0.070175    0.070175      40.0     4.0       4.0   \n",
       "\n",
       "      Score32  Accuracy32  Missrate32  Dyslexia  \n",
       "817       NaN         NaN         NaN         0  \n",
       "51        NaN         NaN         NaN         0  \n",
       "636       NaN         NaN         NaN         0  \n",
       "1300     47.0    0.021277    0.212766         0  \n",
       "1258     40.0    0.100000    0.100000         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras transformar todos los valores del dataframe en numéricos, se va a asegurar que todos los valores sean tipo flotantes mediante la instrucción: `dataset.apply(lambda x: x.astype('float', errors='ignore'))` donde se aplica el cambio de *int* a *flot* mediante la función `astype()` dentro de una función *lambda* que recorre cada columna, accediendo a su contenido y modificándolo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.astype('float', errors='ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se haya transformado el tipo de valor con el que se está trabajando se va a comprobar que los dataframes utilizados solo contienen valores del tipo *float64*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data type of each column\n",
    "for col in data.columns:\n",
    "    if data[col].dtypes != \"float64\":\n",
    "        print(\"Column {} is not a float, it is {}\".format(col, data[col].dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez exportados los datos se va a comporbar si hay valores nulos mediante la función `[col for col in test_df.columns if train_df[col].isnull().any()]`. \n",
    "- Mediante el bucle `for col in` se van a recorrer todas las columna y acceder a sus valores.  \n",
    "- Mediante el condicional `if train_df[col].isnull().any()`se va a comprobar si alguno de los datos de la columna que se está analizando es nulo o no. \n",
    "\n",
    "En caso de que se encuentre un valor nulo, el atributo de salida `col` tomará el valor de dicha columna y se añadirá a una lista (función entre `[ ]`).\n",
    "\n",
    "Se obtiene que el dataset correspondiente a los datos *train* no contienen ningún valor nulo, sin mebargo, los datos del dataset *test* sí. Cabe destacar que las columnas correspondientes a la *Question 29* ( 'Clicks29', 'Hits29', 'Misses29', 'Score29', 'Accuracy29', 'Missrate29') no contienen ningún valor. Es decir, dichas columnas solo están compuestas por valores nulos, por lo que no aportan información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = [np.number])\n",
    "data.isnull().values.any()\n",
    "data_null_values = data.isna().sum().sum()\n",
    "data_null_col = [col for col in data.columns if data[col].isnull().any()]\n",
    "#data_null_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha mencionado anteriormente, en el dataset correspondiente a *test* existen multitud de valores nulos, los cuales deben ser transformados para poder diseñar el modelo en Machine Learning adecuadamente. Para ello se van a emplear distintas técticas:\n",
    "1.  **Eliminación de las columnas con valores nulos**: si una fila presenta valores no numéricos, mediante la función `drop()`, se va a prescindir de ella y no se tendrá encuentra en el diseño del modelo.\n",
    "2. **Sustitución por cero**: si una columna presenta valores no numéricos, se sustituira el valor *Nan* por *0* mediante la función `fillna(0)`. Solo se modificará el dataset *test*, ya que no se está eliminando ninguna fila.\n",
    "3. **Sustitución por la media y la mediana**: si una columna presenta valores no numéricos, se calculará la media y la mediana de dicha columna mediante las funciones `mean()` y `median()`, respectivamente, se sustituirán los valores *Nan* de cada columna. En caso de que una columna no presente ningún valor numérico se eliminará, tanto en el dataset *test* como *train*, de froma análoga.\n",
    "\n",
    "Como se ha observado en la sección anterior, en el dataset que se va a usar para testear el modelo las columnas correspondientes a la cuestión 29 no presentan valores numéricos. Por ello, se ha decidido eliminarlas y no tenerlas en cuenta en el estudio, tanto del dataset *train* como *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to be removed\n",
    "column29 = ['Clicks29', 'Hits29', 'Misses29', 'Score29', 'Accuracy29', 'Missrate29']\n",
    "#drop Q29\n",
    "data = data.drop(column29, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nativelang</th>\n",
       "      <th>Otherlang</th>\n",
       "      <th>Age</th>\n",
       "      <th>Clicks1</th>\n",
       "      <th>Hits1</th>\n",
       "      <th>Misses1</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Accuracy1</th>\n",
       "      <th>Missrate1</th>\n",
       "      <th>Clicks2</th>\n",
       "      <th>Hits2</th>\n",
       "      <th>Misses2</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Accuracy2</th>\n",
       "      <th>Missrate2</th>\n",
       "      <th>Clicks3</th>\n",
       "      <th>Hits3</th>\n",
       "      <th>Misses3</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Accuracy3</th>\n",
       "      <th>Missrate3</th>\n",
       "      <th>Clicks4</th>\n",
       "      <th>Hits4</th>\n",
       "      <th>Misses4</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Accuracy4</th>\n",
       "      <th>Missrate4</th>\n",
       "      <th>Clicks5</th>\n",
       "      <th>Hits5</th>\n",
       "      <th>Misses5</th>\n",
       "      <th>Score5</th>\n",
       "      <th>Accuracy5</th>\n",
       "      <th>Missrate5</th>\n",
       "      <th>Clicks6</th>\n",
       "      <th>Hits6</th>\n",
       "      <th>Misses6</th>\n",
       "      <th>Score6</th>\n",
       "      <th>Accuracy6</th>\n",
       "      <th>Missrate6</th>\n",
       "      <th>Clicks7</th>\n",
       "      <th>Hits7</th>\n",
       "      <th>Misses7</th>\n",
       "      <th>Score7</th>\n",
       "      <th>Accuracy7</th>\n",
       "      <th>Missrate7</th>\n",
       "      <th>Clicks8</th>\n",
       "      <th>Hits8</th>\n",
       "      <th>Misses8</th>\n",
       "      <th>Score8</th>\n",
       "      <th>Accuracy8</th>\n",
       "      <th>Missrate8</th>\n",
       "      <th>Clicks9</th>\n",
       "      <th>Hits9</th>\n",
       "      <th>Misses9</th>\n",
       "      <th>Score9</th>\n",
       "      <th>Accuracy9</th>\n",
       "      <th>Missrate9</th>\n",
       "      <th>Clicks10</th>\n",
       "      <th>Hits10</th>\n",
       "      <th>Misses10</th>\n",
       "      <th>Score10</th>\n",
       "      <th>Accuracy10</th>\n",
       "      <th>Missrate10</th>\n",
       "      <th>Clicks11</th>\n",
       "      <th>Hits11</th>\n",
       "      <th>Misses11</th>\n",
       "      <th>Score11</th>\n",
       "      <th>Accuracy11</th>\n",
       "      <th>Missrate11</th>\n",
       "      <th>Clicks12</th>\n",
       "      <th>Hits12</th>\n",
       "      <th>Misses12</th>\n",
       "      <th>Score12</th>\n",
       "      <th>Accuracy12</th>\n",
       "      <th>Missrate12</th>\n",
       "      <th>Clicks13</th>\n",
       "      <th>Hits13</th>\n",
       "      <th>Misses13</th>\n",
       "      <th>Score13</th>\n",
       "      <th>Accuracy13</th>\n",
       "      <th>Missrate13</th>\n",
       "      <th>Clicks14</th>\n",
       "      <th>Hits14</th>\n",
       "      <th>Misses14</th>\n",
       "      <th>Score14</th>\n",
       "      <th>Accuracy14</th>\n",
       "      <th>Missrate14</th>\n",
       "      <th>Clicks15</th>\n",
       "      <th>Hits15</th>\n",
       "      <th>Misses15</th>\n",
       "      <th>Score15</th>\n",
       "      <th>Accuracy15</th>\n",
       "      <th>Missrate15</th>\n",
       "      <th>Clicks16</th>\n",
       "      <th>Hits16</th>\n",
       "      <th>Misses16</th>\n",
       "      <th>Score16</th>\n",
       "      <th>Accuracy16</th>\n",
       "      <th>Missrate16</th>\n",
       "      <th>Clicks17</th>\n",
       "      <th>Hits17</th>\n",
       "      <th>Misses17</th>\n",
       "      <th>Score17</th>\n",
       "      <th>Accuracy17</th>\n",
       "      <th>Missrate17</th>\n",
       "      <th>Clicks18</th>\n",
       "      <th>Hits18</th>\n",
       "      <th>Misses18</th>\n",
       "      <th>Score18</th>\n",
       "      <th>Accuracy18</th>\n",
       "      <th>Missrate18</th>\n",
       "      <th>Clicks19</th>\n",
       "      <th>Hits19</th>\n",
       "      <th>Misses19</th>\n",
       "      <th>Score19</th>\n",
       "      <th>Accuracy19</th>\n",
       "      <th>Missrate19</th>\n",
       "      <th>Clicks20</th>\n",
       "      <th>Hits20</th>\n",
       "      <th>Misses20</th>\n",
       "      <th>Score20</th>\n",
       "      <th>Accuracy20</th>\n",
       "      <th>Missrate20</th>\n",
       "      <th>Clicks21</th>\n",
       "      <th>Hits21</th>\n",
       "      <th>Misses21</th>\n",
       "      <th>Score21</th>\n",
       "      <th>Accuracy21</th>\n",
       "      <th>Missrate21</th>\n",
       "      <th>Clicks22</th>\n",
       "      <th>Hits22</th>\n",
       "      <th>Misses22</th>\n",
       "      <th>Score22</th>\n",
       "      <th>Accuracy22</th>\n",
       "      <th>Missrate22</th>\n",
       "      <th>Clicks23</th>\n",
       "      <th>Hits23</th>\n",
       "      <th>Misses23</th>\n",
       "      <th>Score23</th>\n",
       "      <th>Accuracy23</th>\n",
       "      <th>Missrate23</th>\n",
       "      <th>Clicks24</th>\n",
       "      <th>Hits24</th>\n",
       "      <th>Misses24</th>\n",
       "      <th>Score24</th>\n",
       "      <th>Accuracy24</th>\n",
       "      <th>Missrate24</th>\n",
       "      <th>Clicks25</th>\n",
       "      <th>Hits25</th>\n",
       "      <th>Misses25</th>\n",
       "      <th>Score25</th>\n",
       "      <th>Accuracy25</th>\n",
       "      <th>Missrate25</th>\n",
       "      <th>Clicks26</th>\n",
       "      <th>Hits26</th>\n",
       "      <th>Misses26</th>\n",
       "      <th>Score26</th>\n",
       "      <th>Accuracy26</th>\n",
       "      <th>Missrate26</th>\n",
       "      <th>Clicks27</th>\n",
       "      <th>Hits27</th>\n",
       "      <th>Misses27</th>\n",
       "      <th>Score27</th>\n",
       "      <th>Accuracy27</th>\n",
       "      <th>Missrate27</th>\n",
       "      <th>Clicks28</th>\n",
       "      <th>Hits28</th>\n",
       "      <th>Misses28</th>\n",
       "      <th>Score28</th>\n",
       "      <th>Accuracy28</th>\n",
       "      <th>Missrate28</th>\n",
       "      <th>Clicks30</th>\n",
       "      <th>Hits30</th>\n",
       "      <th>Misses30</th>\n",
       "      <th>Score30</th>\n",
       "      <th>Accuracy30</th>\n",
       "      <th>Missrate30</th>\n",
       "      <th>Clicks31</th>\n",
       "      <th>Hits31</th>\n",
       "      <th>Misses31</th>\n",
       "      <th>Score31</th>\n",
       "      <th>Accuracy31</th>\n",
       "      <th>Missrate31</th>\n",
       "      <th>Clicks32</th>\n",
       "      <th>Hits32</th>\n",
       "      <th>Misses32</th>\n",
       "      <th>Score32</th>\n",
       "      <th>Accuracy32</th>\n",
       "      <th>Missrate32</th>\n",
       "      <th>Dyslexia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>875.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Nativelang  Otherlang   Age  Clicks1  Hits1  Misses1  Score1  \\\n",
       "817      0.0         1.0        0.0  11.0     11.0   11.0      0.0    11.0   \n",
       "51       0.0         1.0        0.0   7.0      4.0    4.0      0.0     4.0   \n",
       "636      1.0         1.0        0.0  10.0     14.0   14.0      0.0    14.0   \n",
       "1300     1.0         1.0        0.0  15.0      9.0    9.0      0.0     9.0   \n",
       "1258     0.0         1.0        0.0  14.0     13.0   13.0      0.0    13.0   \n",
       "\n",
       "      Accuracy1  Missrate1  Clicks2  Hits2  Misses2  Score2  Accuracy2  \\\n",
       "817         1.0        0.0      8.0    8.0      0.0     8.0        1.0   \n",
       "51          1.0        0.0      5.0    5.0      0.0     5.0        1.0   \n",
       "636         1.0        0.0     10.0   10.0      0.0    10.0        1.0   \n",
       "1300        1.0        0.0      8.0    8.0      0.0     8.0        1.0   \n",
       "1258        1.0        0.0     11.0   11.0      0.0    11.0        1.0   \n",
       "\n",
       "      Missrate2  Clicks3  Hits3  Misses3  Score3  Accuracy3  Missrate3  \\\n",
       "817         0.0      7.0    7.0      0.0     7.0        1.0        0.0   \n",
       "51          0.0      2.0    2.0      0.0     2.0        1.0        0.0   \n",
       "636         0.0      8.0    8.0      0.0     8.0        1.0        0.0   \n",
       "1300        0.0      7.0    7.0      0.0     7.0        1.0        0.0   \n",
       "1258        0.0      8.0    8.0      0.0     8.0        1.0        0.0   \n",
       "\n",
       "      Clicks4  Hits4  Misses4  Score4  Accuracy4  Missrate4  Clicks5  Hits5  \\\n",
       "817       3.0    3.0      0.0     3.0        1.0        0.0      6.0    4.0   \n",
       "51        2.0    1.0      1.0     2.0        0.5        0.5      1.0    0.0   \n",
       "636       4.0    4.0      0.0     4.0        1.0        0.0      7.0    6.0   \n",
       "1300      3.0    3.0      0.0     3.0        1.0        0.0      4.0    4.0   \n",
       "1258      4.0    4.0      0.0     4.0        1.0        0.0      4.0    2.0   \n",
       "\n",
       "      Misses5  Score5  Accuracy5  Missrate5  Clicks6  Hits6  Misses6  Score6  \\\n",
       "817       2.0     6.0   0.666667   0.333333      5.0    4.0      1.0     5.0   \n",
       "51        1.0     1.0   0.000000   1.000000      3.0    3.0      0.0     3.0   \n",
       "636       1.0     7.0   0.857143   0.142857      3.0    3.0      0.0     3.0   \n",
       "1300      0.0     4.0   1.000000   0.000000      5.0    4.0      1.0     5.0   \n",
       "1258      2.0     4.0   0.500000   0.500000      5.0    3.0      2.0     5.0   \n",
       "\n",
       "      Accuracy6  Missrate6  Clicks7  Hits7  Misses7  Score7  Accuracy7  \\\n",
       "817         0.8        0.2      1.0    0.0      1.0     1.0        0.0   \n",
       "51          1.0        0.0      2.0    1.0      1.0     2.0        0.5   \n",
       "636         1.0        0.0      7.0    7.0      0.0     7.0        1.0   \n",
       "1300        0.8        0.2      5.0    5.0      0.0     5.0        1.0   \n",
       "1258        0.6        0.4      8.0    8.0      0.0     8.0        1.0   \n",
       "\n",
       "      Missrate7  Clicks8  Hits8  Misses8  Score8  Accuracy8  Missrate8  \\\n",
       "817         1.0      5.0    4.0      1.0     5.0       0.80       0.20   \n",
       "51          0.5      2.0    2.0      0.0     2.0       1.00       0.00   \n",
       "636         0.0      4.0    3.0      1.0     4.0       0.75       0.25   \n",
       "1300        0.0      4.0    4.0      0.0     4.0       1.00       0.00   \n",
       "1258        0.0      5.0    5.0      0.0     5.0       1.00       0.00   \n",
       "\n",
       "      Clicks9  Hits9  Misses9  Score9  Accuracy9  Missrate9  Clicks10  Hits10  \\\n",
       "817       4.0    4.0      0.0     4.0        1.0        0.0       7.0     7.0   \n",
       "51        2.0    0.0      2.0     2.0        0.0        1.0       2.0     0.0   \n",
       "636       5.0    3.0      2.0     5.0        0.6        0.4       8.0     8.0   \n",
       "1300      3.0    3.0      0.0     3.0        1.0        0.0       4.0     4.0   \n",
       "1258      2.0    2.0      0.0     2.0        1.0        0.0       6.0     6.0   \n",
       "\n",
       "      Misses10  Score10  Accuracy10  Missrate10  Clicks11  Hits11  Misses11  \\\n",
       "817        0.0      7.0         1.0         0.0       3.0     2.0       1.0   \n",
       "51         2.0      2.0         0.0         1.0       2.0     2.0       0.0   \n",
       "636        0.0      8.0         1.0         0.0       6.0     6.0       0.0   \n",
       "1300       0.0      4.0         1.0         0.0       4.0     4.0       0.0   \n",
       "1258       0.0      6.0         1.0         0.0       7.0     5.0       2.0   \n",
       "\n",
       "      Score11  Accuracy11  Missrate11  Clicks12  Hits12  Misses12  Score12  \\\n",
       "817       3.0    0.666667    0.333333       4.0     0.0       4.0      4.0   \n",
       "51        2.0    1.000000    0.000000       3.0     2.0       1.0      3.0   \n",
       "636       6.0    1.000000    0.000000       4.0     2.0       2.0      4.0   \n",
       "1300      4.0    1.000000    0.000000       6.0     6.0       0.0      6.0   \n",
       "1258      7.0    0.714286    0.285714       5.0     5.0       0.0      5.0   \n",
       "\n",
       "      Accuracy12  Missrate12  Clicks13  Hits13  Misses13  Score13  Accuracy13  \\\n",
       "817     0.000000    1.000000       4.0     1.0       3.0      4.0    0.250000   \n",
       "51      0.666667    0.333333       NaN     NaN       NaN      NaN         NaN   \n",
       "636     0.500000    0.500000       7.0     5.0       2.0      7.0    0.714286   \n",
       "1300    1.000000    0.000000       7.0     7.0       0.0      7.0    1.000000   \n",
       "1258    1.000000    0.000000       7.0     6.0       1.0      7.0    0.857143   \n",
       "\n",
       "      Missrate13  Clicks14  Hits14  Misses14  Score14  Accuracy14  Missrate14  \\\n",
       "817     0.750000       9.0     9.0       0.0      9.0         1.0         0.0   \n",
       "51           NaN       5.0     5.0       0.0      5.0         1.0         0.0   \n",
       "636     0.285714      11.0    11.0       0.0     11.0         1.0         0.0   \n",
       "1300    0.000000       8.0     8.0       0.0      8.0         1.0         0.0   \n",
       "1258    0.142857      10.0    10.0       0.0     10.0         1.0         0.0   \n",
       "\n",
       "      Clicks15  Hits15  Misses15  Score15  Accuracy15  Missrate15  Clicks16  \\\n",
       "817        7.0     7.0       0.0      7.0         1.0         0.0       5.0   \n",
       "51         1.0     1.0       0.0      1.0         1.0         0.0       4.0   \n",
       "636        5.0     4.0       1.0      5.0         0.8         0.2       7.0   \n",
       "1300       6.0     6.0       0.0      6.0         1.0         0.0       6.0   \n",
       "1258      10.0    10.0       0.0     10.0         1.0         0.0       4.0   \n",
       "\n",
       "      Hits16  Misses16  Score16  Accuracy16  Missrate16  Clicks17  Hits17  \\\n",
       "817      5.0       0.0      5.0         1.0         0.0       5.0     4.0   \n",
       "51       4.0       0.0      4.0         1.0         0.0       3.0     3.0   \n",
       "636      7.0       0.0      7.0         1.0         0.0       4.0     3.0   \n",
       "1300     6.0       0.0      6.0         1.0         0.0       4.0     4.0   \n",
       "1258     4.0       0.0      4.0         1.0         0.0       5.0     4.0   \n",
       "\n",
       "      Misses17  Score17  Accuracy17  Missrate17  Clicks18  Hits18  Misses18  \\\n",
       "817        1.0      5.0        0.80        0.20       5.0     4.0       1.0   \n",
       "51         0.0      3.0        1.00        0.00       NaN     NaN       NaN   \n",
       "636        1.0      4.0        0.75        0.25       5.0     2.0       3.0   \n",
       "1300       0.0      4.0        1.00        0.00       5.0     5.0       0.0   \n",
       "1258       1.0      5.0        0.80        0.20       8.0     8.0       0.0   \n",
       "\n",
       "      Score18  Accuracy18  Missrate18  Clicks19  Hits19  Misses19  Score19  \\\n",
       "817       5.0         0.8         0.2       7.0     4.0       3.0      7.0   \n",
       "51        NaN         NaN         NaN       NaN     NaN       NaN      NaN   \n",
       "636       5.0         0.4         0.6       9.0     1.0       8.0      9.0   \n",
       "1300      5.0         1.0         0.0       6.0     6.0       0.0      6.0   \n",
       "1258      8.0         1.0         0.0       5.0     3.0       2.0      5.0   \n",
       "\n",
       "      Accuracy19  Missrate19  Clicks20  Hits20  Misses20  Score20  Accuracy20  \\\n",
       "817     0.571429    0.428571       6.0     0.0       6.0      6.0    0.000000   \n",
       "51           NaN         NaN       NaN     NaN       NaN      NaN         NaN   \n",
       "636     0.111111    0.888889       4.0     1.0       3.0      4.0    0.250000   \n",
       "1300    1.000000    0.000000       3.0     1.0       2.0      3.0    0.333333   \n",
       "1258    0.600000    0.400000       4.0     1.0       3.0      4.0    0.250000   \n",
       "\n",
       "      Missrate20  Clicks21  Hits21  Misses21  Score21  Accuracy21  Missrate21  \\\n",
       "817     1.000000       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "51           NaN       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "636     0.750000       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "1300    0.666667       2.0     0.0       2.0      2.0        0.00        1.00   \n",
       "1258    0.750000       4.0     1.0       3.0      4.0        0.25        0.75   \n",
       "\n",
       "      Clicks22  Hits22  Misses22  Score22  Accuracy22  Missrate22  Clicks23  \\\n",
       "817        5.0     3.0       2.0      5.0    0.600000    0.400000       8.0   \n",
       "51         5.0     4.0       1.0      5.0    0.800000    0.200000       3.0   \n",
       "636        6.0     5.0       1.0      6.0    0.833333    0.166667      11.0   \n",
       "1300       6.0     6.0       0.0      6.0    1.000000    0.000000       6.0   \n",
       "1258      10.0     8.0       2.0     10.0    0.800000    0.200000       8.0   \n",
       "\n",
       "      Hits23  Misses23  Score23  Accuracy23  Missrate23  Clicks24  Hits24  \\\n",
       "817      7.0       1.0      8.0  875.000000  125.000000       5.0     3.0   \n",
       "51       1.0       2.0      3.0    0.333333    0.666667       NaN     NaN   \n",
       "636      6.0       5.0     11.0    0.545455    0.454545       7.0     4.0   \n",
       "1300     6.0       0.0      6.0    1.000000    0.000000       6.0     6.0   \n",
       "1258     5.0       3.0      8.0  625.000000  375.000000       8.0     8.0   \n",
       "\n",
       "      Misses24  Score24  Accuracy24  Missrate24  Clicks25  Hits25  Misses25  \\\n",
       "817        2.0      5.0    0.600000    0.400000       NaN     NaN       NaN   \n",
       "51         NaN      NaN         NaN         NaN       NaN     NaN       NaN   \n",
       "636        3.0      7.0    0.571429    0.428571       NaN     NaN       NaN   \n",
       "1300       0.0      6.0    1.000000    0.000000       6.0     6.0       0.0   \n",
       "1258       0.0      8.0    1.000000    0.000000       9.0     9.0       0.0   \n",
       "\n",
       "      Score25  Accuracy25  Missrate25  Clicks26  Hits26  Misses26  Score26  \\\n",
       "817       NaN         NaN         NaN      11.0    10.0       1.0     11.0   \n",
       "51        NaN         NaN         NaN       NaN     NaN       NaN      NaN   \n",
       "636       NaN         NaN         NaN      13.0     7.0       6.0     13.0   \n",
       "1300      6.0         1.0         0.0      12.0    11.0       1.0     12.0   \n",
       "1258      9.0         1.0         0.0      20.0     8.0      12.0     20.0   \n",
       "\n",
       "      Accuracy26  Missrate26  Clicks27  Hits27  Misses27  Score27  Accuracy27  \\\n",
       "817     0.909091    0.090909      54.0     2.0       3.0     54.0    0.037037   \n",
       "51           NaN         NaN       NaN     NaN       NaN      NaN         NaN   \n",
       "636     0.538462    0.461538      20.0     1.0       1.0     20.0    0.050000   \n",
       "1300    0.916667    0.083333      30.0     3.0       0.0     30.0    0.100000   \n",
       "1258    0.400000    0.600000      56.0     3.0       2.0     56.0    0.053571   \n",
       "\n",
       "      Missrate27  Clicks28  Hits28  Misses28  Score28  Accuracy28  Missrate28  \\\n",
       "817     0.055556      24.0     2.0       1.0     24.0    0.083333    0.041667   \n",
       "51           NaN       NaN     NaN       NaN      NaN         NaN         NaN   \n",
       "636     0.050000      38.0     6.0       0.0     38.0    0.157895    0.000000   \n",
       "1300    0.000000      26.0     3.0       1.0     26.0    0.115385    0.038462   \n",
       "1258    0.035714      46.0     5.0       2.0     46.0    0.108696    0.043478   \n",
       "\n",
       "      Clicks30  Hits30  Misses30  Score30  Accuracy30  Missrate30  Clicks31  \\\n",
       "817       21.0     2.0       2.0     21.0    0.095238    0.095238       NaN   \n",
       "51        11.0     0.0       1.0     11.0    0.000000    0.090909       NaN   \n",
       "636       21.0     3.0       1.0     21.0    0.142857    0.047619       NaN   \n",
       "1300      21.0     2.0       2.0     21.0    0.095238    0.095238      35.0   \n",
       "1258      21.0     3.0       1.0     21.0    0.142857    0.047619      57.0   \n",
       "\n",
       "      Hits31  Misses31  Score31  Accuracy31  Missrate31  Clicks32  Hits32  \\\n",
       "817      NaN       NaN      NaN         NaN         NaN       NaN     NaN   \n",
       "51       NaN       NaN      NaN         NaN         NaN       NaN     NaN   \n",
       "636      NaN       NaN      NaN         NaN         NaN       NaN     NaN   \n",
       "1300     4.0       0.0     35.0    0.114286    0.000000      47.0     1.0   \n",
       "1258     4.0       4.0     57.0    0.070175    0.070175      40.0     4.0   \n",
       "\n",
       "      Misses32  Score32  Accuracy32  Missrate32  Dyslexia  \n",
       "817        NaN      NaN         NaN         NaN       0.0  \n",
       "51         NaN      NaN         NaN         NaN       0.0  \n",
       "636        NaN      NaN         NaN         NaN       0.0  \n",
       "1300      10.0     47.0    0.021277    0.212766       0.0  \n",
       "1258       4.0     40.0    0.100000    0.100000       0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder con el ajuste los valores nulos, para no influir erróneamente en el cálculo de la media y la mediana, se va a prescindir de todos los valores mayores a uno en las columnas *Accuracy* y *Missrate*. Los valores mencionados representan porcentajes, por lo que no pueden superar la unidad, sin embargo, si se estudia en detalle cada variable existen valores que no cumplen este requisito dando lugar a error si no se corrige."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_manually(df):\n",
    "    print(\"Old Shape: \", df.shape)\n",
    "    \n",
    "    #Accuracy and Missrate\n",
    "    for i in range(int(df.shape[1]/6)):\n",
    "        col_acc_rate = df.columns[8+6*i:10+6*i]\n",
    "        for j in col_acc_rate:\n",
    "            df.drop(df[df[j] > 1].index, inplace=True)\n",
    "    print(\"New Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Shape:  (296, 191)\n",
      "New Shape:  (211, 191)\n"
     ]
    }
   ],
   "source": [
    "remove_outliers_manually(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1 DROP\n",
    "drop_df = data.dropna()\n",
    "\n",
    "##2 ZEROS\n",
    "zero_df = data.fillna(0)\n",
    "\n",
    "##3 MEAN & MEDIAN\n",
    "#3.1 MEAN\n",
    "#Mean Fill\n",
    "mean_df = data.fillna(data.mean())\n",
    "\n",
    "#3.2 MEDIAN\n",
    "#Median Fill\n",
    "median_df = data.fillna(data.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar las modificaciones convenientes, se va a comprobar que ningún dataset contiene valores nulos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 DROP\n",
    "drop_df.head()\n",
    "null_col_drop = [col for col in drop_df.columns if drop_df[col].isnull().any()]\n",
    "null_col_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 ZEROS\n",
    "zero_df.head()\n",
    "null_col_zero = [col for col in zero_df.columns if zero_df[col].isnull().any()]\n",
    "null_col_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.1 MEAN\n",
    "mean_df.head()\n",
    "null_col_mean = [col for col in mean_df.columns if mean_df[col].isnull().any()]\n",
    "null_col_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.2 MEDIAN\n",
    "median_df.head()\n",
    "null_col_median = [col for col in median_df.columns if median_df[col].isnull().any()]\n",
    "null_col_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se va a proceder con la eliminación de los outliers, es decir, se va a prescindir de aquellos valores que se consideren anómalos. Para ello se van a emplear dos funciones *.describe()* y *sns.distplot(col)*. La primera  se utiliza para representar la distribución de los datos en un gráfico. Va a permitir visualizar la forma en que los datos están distribuidos en los datasets disponibles. A simple vista, se puede identificar como hay valores máximos que están muy alejados del percentil 75, por lo que se puede intuir que se trata de un outlier.\n",
    "\n",
    "A su vez, la función `countplot` es útil para identificar cuantos valores positivos y negativos hay de dislexia. Se va a representar visualmente, permitiendo comparar si la muestra que se está usando es representativa de la población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nativelang</th>\n",
       "      <th>Otherlang</th>\n",
       "      <th>Age</th>\n",
       "      <th>Clicks1</th>\n",
       "      <th>Hits1</th>\n",
       "      <th>Misses1</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Accuracy1</th>\n",
       "      <th>Missrate1</th>\n",
       "      <th>Clicks2</th>\n",
       "      <th>Hits2</th>\n",
       "      <th>Misses2</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Accuracy2</th>\n",
       "      <th>Missrate2</th>\n",
       "      <th>Clicks3</th>\n",
       "      <th>Hits3</th>\n",
       "      <th>Misses3</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Accuracy3</th>\n",
       "      <th>Missrate3</th>\n",
       "      <th>Clicks4</th>\n",
       "      <th>Hits4</th>\n",
       "      <th>Misses4</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Accuracy4</th>\n",
       "      <th>Missrate4</th>\n",
       "      <th>Clicks5</th>\n",
       "      <th>Hits5</th>\n",
       "      <th>Misses5</th>\n",
       "      <th>Score5</th>\n",
       "      <th>Accuracy5</th>\n",
       "      <th>Missrate5</th>\n",
       "      <th>Clicks6</th>\n",
       "      <th>Hits6</th>\n",
       "      <th>Misses6</th>\n",
       "      <th>Score6</th>\n",
       "      <th>Accuracy6</th>\n",
       "      <th>Missrate6</th>\n",
       "      <th>Clicks7</th>\n",
       "      <th>Hits7</th>\n",
       "      <th>Misses7</th>\n",
       "      <th>Score7</th>\n",
       "      <th>Accuracy7</th>\n",
       "      <th>Missrate7</th>\n",
       "      <th>Clicks8</th>\n",
       "      <th>Hits8</th>\n",
       "      <th>Misses8</th>\n",
       "      <th>Score8</th>\n",
       "      <th>Accuracy8</th>\n",
       "      <th>Missrate8</th>\n",
       "      <th>Clicks9</th>\n",
       "      <th>Hits9</th>\n",
       "      <th>Misses9</th>\n",
       "      <th>Score9</th>\n",
       "      <th>Accuracy9</th>\n",
       "      <th>Missrate9</th>\n",
       "      <th>Clicks10</th>\n",
       "      <th>Hits10</th>\n",
       "      <th>Misses10</th>\n",
       "      <th>Score10</th>\n",
       "      <th>Accuracy10</th>\n",
       "      <th>Missrate10</th>\n",
       "      <th>Clicks11</th>\n",
       "      <th>Hits11</th>\n",
       "      <th>Misses11</th>\n",
       "      <th>Score11</th>\n",
       "      <th>Accuracy11</th>\n",
       "      <th>Missrate11</th>\n",
       "      <th>Clicks12</th>\n",
       "      <th>Hits12</th>\n",
       "      <th>Misses12</th>\n",
       "      <th>Score12</th>\n",
       "      <th>Accuracy12</th>\n",
       "      <th>Missrate12</th>\n",
       "      <th>Clicks13</th>\n",
       "      <th>Hits13</th>\n",
       "      <th>Misses13</th>\n",
       "      <th>Score13</th>\n",
       "      <th>Accuracy13</th>\n",
       "      <th>Missrate13</th>\n",
       "      <th>Clicks14</th>\n",
       "      <th>Hits14</th>\n",
       "      <th>Misses14</th>\n",
       "      <th>Score14</th>\n",
       "      <th>Accuracy14</th>\n",
       "      <th>Missrate14</th>\n",
       "      <th>Clicks15</th>\n",
       "      <th>Hits15</th>\n",
       "      <th>Misses15</th>\n",
       "      <th>Score15</th>\n",
       "      <th>Accuracy15</th>\n",
       "      <th>Missrate15</th>\n",
       "      <th>Clicks16</th>\n",
       "      <th>Hits16</th>\n",
       "      <th>Misses16</th>\n",
       "      <th>Score16</th>\n",
       "      <th>Accuracy16</th>\n",
       "      <th>Missrate16</th>\n",
       "      <th>Clicks17</th>\n",
       "      <th>Hits17</th>\n",
       "      <th>Misses17</th>\n",
       "      <th>Score17</th>\n",
       "      <th>Accuracy17</th>\n",
       "      <th>Missrate17</th>\n",
       "      <th>Clicks18</th>\n",
       "      <th>Hits18</th>\n",
       "      <th>Misses18</th>\n",
       "      <th>Score18</th>\n",
       "      <th>Accuracy18</th>\n",
       "      <th>Missrate18</th>\n",
       "      <th>Clicks19</th>\n",
       "      <th>Hits19</th>\n",
       "      <th>Misses19</th>\n",
       "      <th>Score19</th>\n",
       "      <th>Accuracy19</th>\n",
       "      <th>Missrate19</th>\n",
       "      <th>Clicks20</th>\n",
       "      <th>Hits20</th>\n",
       "      <th>Misses20</th>\n",
       "      <th>Score20</th>\n",
       "      <th>Accuracy20</th>\n",
       "      <th>Missrate20</th>\n",
       "      <th>Clicks21</th>\n",
       "      <th>Hits21</th>\n",
       "      <th>Misses21</th>\n",
       "      <th>Score21</th>\n",
       "      <th>Accuracy21</th>\n",
       "      <th>Missrate21</th>\n",
       "      <th>Clicks22</th>\n",
       "      <th>Hits22</th>\n",
       "      <th>Misses22</th>\n",
       "      <th>Score22</th>\n",
       "      <th>Accuracy22</th>\n",
       "      <th>Missrate22</th>\n",
       "      <th>Clicks23</th>\n",
       "      <th>Hits23</th>\n",
       "      <th>Misses23</th>\n",
       "      <th>Score23</th>\n",
       "      <th>Accuracy23</th>\n",
       "      <th>Missrate23</th>\n",
       "      <th>Clicks24</th>\n",
       "      <th>Hits24</th>\n",
       "      <th>Misses24</th>\n",
       "      <th>Score24</th>\n",
       "      <th>Accuracy24</th>\n",
       "      <th>Missrate24</th>\n",
       "      <th>Clicks25</th>\n",
       "      <th>Hits25</th>\n",
       "      <th>Misses25</th>\n",
       "      <th>Score25</th>\n",
       "      <th>Accuracy25</th>\n",
       "      <th>Missrate25</th>\n",
       "      <th>Clicks26</th>\n",
       "      <th>Hits26</th>\n",
       "      <th>Misses26</th>\n",
       "      <th>Score26</th>\n",
       "      <th>Accuracy26</th>\n",
       "      <th>Missrate26</th>\n",
       "      <th>Clicks27</th>\n",
       "      <th>Hits27</th>\n",
       "      <th>Misses27</th>\n",
       "      <th>Score27</th>\n",
       "      <th>Accuracy27</th>\n",
       "      <th>Missrate27</th>\n",
       "      <th>Clicks28</th>\n",
       "      <th>Hits28</th>\n",
       "      <th>Misses28</th>\n",
       "      <th>Score28</th>\n",
       "      <th>Accuracy28</th>\n",
       "      <th>Missrate28</th>\n",
       "      <th>Clicks30</th>\n",
       "      <th>Hits30</th>\n",
       "      <th>Misses30</th>\n",
       "      <th>Score30</th>\n",
       "      <th>Accuracy30</th>\n",
       "      <th>Missrate30</th>\n",
       "      <th>Clicks31</th>\n",
       "      <th>Hits31</th>\n",
       "      <th>Misses31</th>\n",
       "      <th>Score31</th>\n",
       "      <th>Accuracy31</th>\n",
       "      <th>Missrate31</th>\n",
       "      <th>Clicks32</th>\n",
       "      <th>Hits32</th>\n",
       "      <th>Misses32</th>\n",
       "      <th>Score32</th>\n",
       "      <th>Accuracy32</th>\n",
       "      <th>Missrate32</th>\n",
       "      <th>Dyslexia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>129.00000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.00000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>211.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.526066</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.170616</td>\n",
       "      <td>9.691943</td>\n",
       "      <td>7.241706</td>\n",
       "      <td>6.985782</td>\n",
       "      <td>0.255924</td>\n",
       "      <td>7.241706</td>\n",
       "      <td>0.927884</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>6.691943</td>\n",
       "      <td>6.360190</td>\n",
       "      <td>0.331754</td>\n",
       "      <td>6.691943</td>\n",
       "      <td>0.930182</td>\n",
       "      <td>0.060339</td>\n",
       "      <td>5.720379</td>\n",
       "      <td>5.317536</td>\n",
       "      <td>0.402844</td>\n",
       "      <td>5.720379</td>\n",
       "      <td>0.927721</td>\n",
       "      <td>0.072279</td>\n",
       "      <td>3.502370</td>\n",
       "      <td>2.417062</td>\n",
       "      <td>1.085308</td>\n",
       "      <td>3.502370</td>\n",
       "      <td>0.755710</td>\n",
       "      <td>0.239551</td>\n",
       "      <td>4.298578</td>\n",
       "      <td>3.905213</td>\n",
       "      <td>0.393365</td>\n",
       "      <td>4.298578</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>0.138930</td>\n",
       "      <td>3.767773</td>\n",
       "      <td>2.663507</td>\n",
       "      <td>1.104265</td>\n",
       "      <td>3.767773</td>\n",
       "      <td>0.695785</td>\n",
       "      <td>0.304215</td>\n",
       "      <td>4.407583</td>\n",
       "      <td>4.109005</td>\n",
       "      <td>0.298578</td>\n",
       "      <td>4.407583</td>\n",
       "      <td>0.909588</td>\n",
       "      <td>0.080933</td>\n",
       "      <td>4.156398</td>\n",
       "      <td>3.554502</td>\n",
       "      <td>0.601896</td>\n",
       "      <td>4.156398</td>\n",
       "      <td>0.870005</td>\n",
       "      <td>0.129995</td>\n",
       "      <td>2.924171</td>\n",
       "      <td>1.834123</td>\n",
       "      <td>1.090047</td>\n",
       "      <td>2.924171</td>\n",
       "      <td>0.691827</td>\n",
       "      <td>0.308173</td>\n",
       "      <td>5.886256</td>\n",
       "      <td>5.014218</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>5.886256</td>\n",
       "      <td>0.845353</td>\n",
       "      <td>0.149907</td>\n",
       "      <td>3.635071</td>\n",
       "      <td>2.824645</td>\n",
       "      <td>0.810427</td>\n",
       "      <td>3.635071</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.228759</td>\n",
       "      <td>4.142180</td>\n",
       "      <td>3.066351</td>\n",
       "      <td>1.075829</td>\n",
       "      <td>4.142180</td>\n",
       "      <td>0.793491</td>\n",
       "      <td>0.206509</td>\n",
       "      <td>4.767442</td>\n",
       "      <td>3.255814</td>\n",
       "      <td>1.511628</td>\n",
       "      <td>4.767442</td>\n",
       "      <td>0.730082</td>\n",
       "      <td>0.269918</td>\n",
       "      <td>7.028436</td>\n",
       "      <td>6.715640</td>\n",
       "      <td>0.312796</td>\n",
       "      <td>7.028436</td>\n",
       "      <td>0.956942</td>\n",
       "      <td>0.043058</td>\n",
       "      <td>4.033175</td>\n",
       "      <td>3.725118</td>\n",
       "      <td>0.308057</td>\n",
       "      <td>4.033175</td>\n",
       "      <td>0.917016</td>\n",
       "      <td>0.073505</td>\n",
       "      <td>4.298578</td>\n",
       "      <td>4.132701</td>\n",
       "      <td>0.165877</td>\n",
       "      <td>4.298578</td>\n",
       "      <td>0.966109</td>\n",
       "      <td>0.033891</td>\n",
       "      <td>4.028436</td>\n",
       "      <td>3.554502</td>\n",
       "      <td>0.473934</td>\n",
       "      <td>4.028436</td>\n",
       "      <td>0.923494</td>\n",
       "      <td>0.071767</td>\n",
       "      <td>4.193798</td>\n",
       "      <td>2.945736</td>\n",
       "      <td>1.248062</td>\n",
       "      <td>4.193798</td>\n",
       "      <td>0.689424</td>\n",
       "      <td>0.295072</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.558140</td>\n",
       "      <td>1.775194</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.630575</td>\n",
       "      <td>0.369425</td>\n",
       "      <td>3.844961</td>\n",
       "      <td>1.108527</td>\n",
       "      <td>2.736434</td>\n",
       "      <td>3.844961</td>\n",
       "      <td>0.336065</td>\n",
       "      <td>0.663935</td>\n",
       "      <td>4.723404</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>3.659574</td>\n",
       "      <td>4.723404</td>\n",
       "      <td>0.345018</td>\n",
       "      <td>0.654982</td>\n",
       "      <td>4.459716</td>\n",
       "      <td>2.990521</td>\n",
       "      <td>1.469194</td>\n",
       "      <td>4.459716</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0.340557</td>\n",
       "      <td>5.535545</td>\n",
       "      <td>3.611374</td>\n",
       "      <td>1.924171</td>\n",
       "      <td>5.535545</td>\n",
       "      <td>0.698685</td>\n",
       "      <td>0.301315</td>\n",
       "      <td>4.20155</td>\n",
       "      <td>3.193798</td>\n",
       "      <td>1.007752</td>\n",
       "      <td>4.20155</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>0.246512</td>\n",
       "      <td>5.276596</td>\n",
       "      <td>3.659574</td>\n",
       "      <td>1.617021</td>\n",
       "      <td>5.276596</td>\n",
       "      <td>0.769814</td>\n",
       "      <td>0.208910</td>\n",
       "      <td>7.511628</td>\n",
       "      <td>4.829457</td>\n",
       "      <td>2.682171</td>\n",
       "      <td>7.511628</td>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.378892</td>\n",
       "      <td>30.635659</td>\n",
       "      <td>1.906977</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>30.635659</td>\n",
       "      <td>0.054973</td>\n",
       "      <td>0.028229</td>\n",
       "      <td>24.341085</td>\n",
       "      <td>2.449612</td>\n",
       "      <td>1.271318</td>\n",
       "      <td>24.341085</td>\n",
       "      <td>0.102496</td>\n",
       "      <td>0.051896</td>\n",
       "      <td>19.066351</td>\n",
       "      <td>1.127962</td>\n",
       "      <td>2.255924</td>\n",
       "      <td>19.066351</td>\n",
       "      <td>0.056214</td>\n",
       "      <td>0.115787</td>\n",
       "      <td>45.893617</td>\n",
       "      <td>3.361702</td>\n",
       "      <td>2.765957</td>\n",
       "      <td>45.893617</td>\n",
       "      <td>0.082811</td>\n",
       "      <td>0.044919</td>\n",
       "      <td>46.978723</td>\n",
       "      <td>2.765957</td>\n",
       "      <td>6.723404</td>\n",
       "      <td>46.978723</td>\n",
       "      <td>0.073879</td>\n",
       "      <td>0.119116</td>\n",
       "      <td>0.57346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500508</td>\n",
       "      <td>0.179520</td>\n",
       "      <td>0.377068</td>\n",
       "      <td>2.270910</td>\n",
       "      <td>3.352805</td>\n",
       "      <td>3.505749</td>\n",
       "      <td>1.009904</td>\n",
       "      <td>3.352805</td>\n",
       "      <td>0.231708</td>\n",
       "      <td>0.192425</td>\n",
       "      <td>2.764551</td>\n",
       "      <td>2.815455</td>\n",
       "      <td>1.296106</td>\n",
       "      <td>2.764551</td>\n",
       "      <td>0.210979</td>\n",
       "      <td>0.190336</td>\n",
       "      <td>2.800087</td>\n",
       "      <td>2.146675</td>\n",
       "      <td>2.446337</td>\n",
       "      <td>2.800087</td>\n",
       "      <td>0.227722</td>\n",
       "      <td>0.227722</td>\n",
       "      <td>1.795164</td>\n",
       "      <td>1.763787</td>\n",
       "      <td>2.098145</td>\n",
       "      <td>1.795164</td>\n",
       "      <td>0.392204</td>\n",
       "      <td>0.389058</td>\n",
       "      <td>1.721281</td>\n",
       "      <td>1.990578</td>\n",
       "      <td>0.763297</td>\n",
       "      <td>1.721281</td>\n",
       "      <td>0.286467</td>\n",
       "      <td>0.286467</td>\n",
       "      <td>2.044296</td>\n",
       "      <td>1.689053</td>\n",
       "      <td>1.720612</td>\n",
       "      <td>2.044296</td>\n",
       "      <td>0.348425</td>\n",
       "      <td>0.348425</td>\n",
       "      <td>3.867414</td>\n",
       "      <td>3.596621</td>\n",
       "      <td>1.370071</td>\n",
       "      <td>3.867414</td>\n",
       "      <td>0.258683</td>\n",
       "      <td>0.242951</td>\n",
       "      <td>2.259202</td>\n",
       "      <td>1.734967</td>\n",
       "      <td>1.746506</td>\n",
       "      <td>2.259202</td>\n",
       "      <td>0.234412</td>\n",
       "      <td>0.234412</td>\n",
       "      <td>2.221954</td>\n",
       "      <td>1.229003</td>\n",
       "      <td>2.174844</td>\n",
       "      <td>2.221954</td>\n",
       "      <td>0.379777</td>\n",
       "      <td>0.379777</td>\n",
       "      <td>2.946564</td>\n",
       "      <td>2.641209</td>\n",
       "      <td>2.531276</td>\n",
       "      <td>2.946564</td>\n",
       "      <td>0.307948</td>\n",
       "      <td>0.302524</td>\n",
       "      <td>2.038791</td>\n",
       "      <td>1.718959</td>\n",
       "      <td>1.428314</td>\n",
       "      <td>2.038791</td>\n",
       "      <td>0.310904</td>\n",
       "      <td>0.310904</td>\n",
       "      <td>3.586837</td>\n",
       "      <td>1.654821</td>\n",
       "      <td>3.345777</td>\n",
       "      <td>3.586837</td>\n",
       "      <td>0.287899</td>\n",
       "      <td>0.287899</td>\n",
       "      <td>4.469535</td>\n",
       "      <td>1.682999</td>\n",
       "      <td>4.008032</td>\n",
       "      <td>4.469535</td>\n",
       "      <td>0.282391</td>\n",
       "      <td>0.282391</td>\n",
       "      <td>2.348079</td>\n",
       "      <td>2.415169</td>\n",
       "      <td>1.456276</td>\n",
       "      <td>2.348079</td>\n",
       "      <td>0.152582</td>\n",
       "      <td>0.152582</td>\n",
       "      <td>2.107546</td>\n",
       "      <td>2.070262</td>\n",
       "      <td>1.300140</td>\n",
       "      <td>2.107546</td>\n",
       "      <td>0.232415</td>\n",
       "      <td>0.214437</td>\n",
       "      <td>1.667889</td>\n",
       "      <td>1.606956</td>\n",
       "      <td>0.673280</td>\n",
       "      <td>1.667889</td>\n",
       "      <td>0.108813</td>\n",
       "      <td>0.108813</td>\n",
       "      <td>3.425277</td>\n",
       "      <td>1.734967</td>\n",
       "      <td>3.337098</td>\n",
       "      <td>3.425277</td>\n",
       "      <td>0.199322</td>\n",
       "      <td>0.188874</td>\n",
       "      <td>2.899562</td>\n",
       "      <td>1.876292</td>\n",
       "      <td>2.407771</td>\n",
       "      <td>2.899562</td>\n",
       "      <td>0.359092</td>\n",
       "      <td>0.350408</td>\n",
       "      <td>3.065262</td>\n",
       "      <td>1.638916</td>\n",
       "      <td>2.937474</td>\n",
       "      <td>3.065262</td>\n",
       "      <td>0.325014</td>\n",
       "      <td>0.325014</td>\n",
       "      <td>2.843440</td>\n",
       "      <td>1.154071</td>\n",
       "      <td>2.824334</td>\n",
       "      <td>2.843440</td>\n",
       "      <td>0.323531</td>\n",
       "      <td>0.323531</td>\n",
       "      <td>7.828882</td>\n",
       "      <td>1.071453</td>\n",
       "      <td>7.352245</td>\n",
       "      <td>7.828882</td>\n",
       "      <td>0.348760</td>\n",
       "      <td>0.348760</td>\n",
       "      <td>2.107139</td>\n",
       "      <td>1.946891</td>\n",
       "      <td>1.480910</td>\n",
       "      <td>2.107139</td>\n",
       "      <td>0.309107</td>\n",
       "      <td>0.306678</td>\n",
       "      <td>4.906984</td>\n",
       "      <td>2.109088</td>\n",
       "      <td>4.106201</td>\n",
       "      <td>4.906984</td>\n",
       "      <td>0.292853</td>\n",
       "      <td>0.292853</td>\n",
       "      <td>2.32641</td>\n",
       "      <td>1.924665</td>\n",
       "      <td>1.646474</td>\n",
       "      <td>2.32641</td>\n",
       "      <td>0.306213</td>\n",
       "      <td>0.306213</td>\n",
       "      <td>3.848784</td>\n",
       "      <td>1.891360</td>\n",
       "      <td>3.680461</td>\n",
       "      <td>3.848784</td>\n",
       "      <td>0.289512</td>\n",
       "      <td>0.267625</td>\n",
       "      <td>3.733539</td>\n",
       "      <td>2.961007</td>\n",
       "      <td>2.417335</td>\n",
       "      <td>3.733539</td>\n",
       "      <td>0.273258</td>\n",
       "      <td>0.269886</td>\n",
       "      <td>19.342286</td>\n",
       "      <td>1.502300</td>\n",
       "      <td>1.371825</td>\n",
       "      <td>19.342286</td>\n",
       "      <td>0.036263</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>12.482798</td>\n",
       "      <td>1.681523</td>\n",
       "      <td>1.753354</td>\n",
       "      <td>12.482798</td>\n",
       "      <td>0.055883</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>3.391215</td>\n",
       "      <td>1.111723</td>\n",
       "      <td>1.163288</td>\n",
       "      <td>3.391215</td>\n",
       "      <td>0.053632</td>\n",
       "      <td>0.055772</td>\n",
       "      <td>16.949072</td>\n",
       "      <td>0.965166</td>\n",
       "      <td>3.990275</td>\n",
       "      <td>16.949072</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.052024</td>\n",
       "      <td>20.820652</td>\n",
       "      <td>0.937452</td>\n",
       "      <td>6.006164</td>\n",
       "      <td>20.820652</td>\n",
       "      <td>0.045290</td>\n",
       "      <td>0.074971</td>\n",
       "      <td>0.49575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.048438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>0.067816</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.148352</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.088008</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.101724</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender  Nativelang   Otherlang         Age     Clicks1       Hits1  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.526066    0.966825    0.170616    9.691943    7.241706    6.985782   \n",
       "std      0.500508    0.179520    0.377068    2.270910    3.352805    3.505749   \n",
       "min      0.000000    0.000000    0.000000    7.000000    0.000000    0.000000   \n",
       "25%      0.000000    1.000000    0.000000    8.000000    5.000000    5.000000   \n",
       "50%      1.000000    1.000000    0.000000    9.000000    7.000000    7.000000   \n",
       "75%      1.000000    1.000000    0.000000   11.000000   10.000000   10.000000   \n",
       "max      1.000000    1.000000    1.000000   17.000000   15.000000   15.000000   \n",
       "\n",
       "          Misses1      Score1   Accuracy1   Missrate1     Clicks2       Hits2  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.255924    7.241706    0.927884    0.053159    6.691943    6.360190   \n",
       "std      1.009904    3.352805    0.231708    0.192425    2.764551    2.815455   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    5.000000    1.000000    0.000000    5.000000    5.000000   \n",
       "50%      0.000000    7.000000    1.000000    0.000000    7.000000    6.000000   \n",
       "75%      0.000000   10.000000    1.000000    0.000000    9.000000    8.500000   \n",
       "max      9.000000   15.000000    1.000000    1.000000   19.000000   13.000000   \n",
       "\n",
       "          Misses2      Score2   Accuracy2   Missrate2     Clicks3       Hits3  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.331754    6.691943    0.930182    0.060339    5.720379    5.317536   \n",
       "std      1.296106    2.764551    0.210979    0.190336    2.800087    2.146675   \n",
       "min      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    5.000000    1.000000    0.000000    4.000000    4.000000   \n",
       "50%      0.000000    7.000000    1.000000    0.000000    6.000000    6.000000   \n",
       "75%      0.000000    9.000000    1.000000    0.000000    7.000000    7.000000   \n",
       "max     15.000000   19.000000    1.000000    1.000000   36.000000   10.000000   \n",
       "\n",
       "          Misses3      Score3   Accuracy3   Missrate3     Clicks4       Hits4  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.402844    5.720379    0.927721    0.072279    3.502370    2.417062   \n",
       "std      2.446337    2.800087    0.227722    0.227722    1.795164    1.763787   \n",
       "min      0.000000    1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    4.000000    1.000000    0.000000    2.000000    1.000000   \n",
       "50%      0.000000    6.000000    1.000000    0.000000    3.000000    2.000000   \n",
       "75%      0.000000    7.000000    1.000000    0.000000    5.000000    4.000000   \n",
       "max     34.000000   36.000000    1.000000    1.000000   11.000000    8.000000   \n",
       "\n",
       "          Misses4      Score4   Accuracy4   Missrate4     Clicks5       Hits5  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     1.085308    3.502370    0.755710    0.239551    4.298578    3.905213   \n",
       "std      2.098145    1.795164    0.392204    0.389058    1.721281    1.990578   \n",
       "min      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    2.000000    0.500000    0.000000    3.000000    2.500000   \n",
       "50%      0.000000    3.000000    1.000000    0.000000    4.000000    4.000000   \n",
       "75%      1.000000    5.000000    1.000000    0.500000    5.500000    5.000000   \n",
       "max     11.000000   11.000000    1.000000    1.000000    9.000000    9.000000   \n",
       "\n",
       "          Misses5      Score5   Accuracy5   Missrate5     Clicks6       Hits6  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.393365    4.298578    0.861070    0.138930    3.767773    2.663507   \n",
       "std      0.763297    1.721281    0.286467    0.286467    2.044296    1.689053   \n",
       "min      0.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    0.845238    0.000000    2.000000    1.000000   \n",
       "50%      0.000000    4.000000    1.000000    0.000000    4.000000    3.000000   \n",
       "75%      1.000000    5.500000    1.000000    0.154762    5.000000    4.000000   \n",
       "max      4.000000    9.000000    1.000000    1.000000   17.000000    7.000000   \n",
       "\n",
       "          Misses6      Score6   Accuracy6   Missrate6     Clicks7       Hits7  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     1.104265    3.767773    0.695785    0.304215    4.407583    4.109005   \n",
       "std      1.720612    2.044296    0.348425    0.348425    3.867414    3.596621   \n",
       "min      0.000000    1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000    0.500000    0.000000    3.000000    3.000000   \n",
       "50%      1.000000    4.000000    0.800000    0.200000    4.000000    4.000000   \n",
       "75%      1.000000    5.000000    1.000000    0.500000    6.000000    5.000000   \n",
       "max     12.000000   17.000000    1.000000    1.000000   51.000000   47.000000   \n",
       "\n",
       "          Misses7      Score7   Accuracy7   Missrate7     Clicks8       Hits8  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.298578    4.407583    0.909588    0.080933    4.156398    3.554502   \n",
       "std      1.370071    3.867414    0.258683    0.242951    2.259202    1.734967   \n",
       "min      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    1.000000    0.000000    3.000000    2.000000   \n",
       "50%      0.000000    4.000000    1.000000    0.000000    4.000000    4.000000   \n",
       "75%      0.000000    6.000000    1.000000    0.000000    5.000000    5.000000   \n",
       "max     17.000000   51.000000    1.000000    1.000000   24.000000    8.000000   \n",
       "\n",
       "          Misses8      Score8   Accuracy8   Missrate8     Clicks9       Hits9  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.601896    4.156398    0.870005    0.129995    2.924171    1.834123   \n",
       "std      1.746506    2.259202    0.234412    0.234412    2.221954    1.229003   \n",
       "min      0.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    0.800000    0.000000    2.000000    1.000000   \n",
       "50%      0.000000    4.000000    1.000000    0.000000    3.000000    2.000000   \n",
       "75%      1.000000    5.000000    1.000000    0.200000    3.000000    3.000000   \n",
       "max     19.000000   24.000000    1.000000    1.000000   21.000000    5.000000   \n",
       "\n",
       "          Misses9      Score9   Accuracy9   Missrate9    Clicks10      Hits10  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     1.090047    2.924171    0.691827    0.308173    5.886256    5.014218   \n",
       "std      2.174844    2.221954    0.379777    0.379777    2.946564    2.641209   \n",
       "min      0.000000    1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000    0.450000    0.000000    4.000000    3.000000   \n",
       "50%      0.000000    3.000000    1.000000    0.000000    6.000000    5.000000   \n",
       "75%      2.000000    3.000000    1.000000    0.550000    7.000000    7.000000   \n",
       "max     19.000000   21.000000    1.000000    1.000000   29.000000   11.000000   \n",
       "\n",
       "         Misses10     Score10  Accuracy10  Missrate10    Clicks11      Hits11  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.872038    5.886256    0.845353    0.149907    3.635071    2.824645   \n",
       "std      2.531276    2.946564    0.307948    0.302524    2.038791    1.718959   \n",
       "min      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    4.000000    0.845238    0.000000    2.000000    2.000000   \n",
       "50%      0.000000    6.000000    1.000000    0.000000    3.000000    3.000000   \n",
       "75%      1.000000    7.000000    1.000000    0.142857    5.000000    4.000000   \n",
       "max     26.000000   29.000000    1.000000    1.000000   18.000000    7.000000   \n",
       "\n",
       "         Misses11     Score11  Accuracy11  Missrate11    Clicks12      Hits12  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.810427    3.635071    0.771241    0.228759    4.142180    3.066351   \n",
       "std      1.428314    2.038791    0.310904    0.310904    3.586837    1.654821   \n",
       "min      0.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    2.000000    0.666667    0.000000    3.000000    2.000000   \n",
       "50%      0.000000    3.000000    1.000000    0.000000    4.000000    3.000000   \n",
       "75%      1.000000    5.000000    1.000000    0.333333    5.000000    4.000000   \n",
       "max     14.000000   18.000000    1.000000    1.000000   43.000000    8.000000   \n",
       "\n",
       "         Misses12     Score12  Accuracy12  Missrate12    Clicks13      Hits13  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  129.000000  129.000000   \n",
       "mean     1.075829    4.142180    0.793491    0.206509    4.767442    3.255814   \n",
       "std      3.345777    3.586837    0.287899    0.287899    4.469535    1.682999   \n",
       "min      0.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    0.666667    0.000000    3.000000    2.000000   \n",
       "50%      0.000000    4.000000    1.000000    0.000000    4.000000    3.000000   \n",
       "75%      1.000000    5.000000    1.000000    0.333333    6.000000    4.000000   \n",
       "max     38.000000   43.000000    1.000000    1.000000   51.000000    7.000000   \n",
       "\n",
       "         Misses13     Score13  Accuracy13  Missrate13    Clicks14      Hits14  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  211.000000  211.000000   \n",
       "mean     1.511628    4.767442    0.730082    0.269918    7.028436    6.715640   \n",
       "std      4.008032    4.469535    0.282391    0.282391    2.348079    2.415169   \n",
       "min      0.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    0.600000    0.000000    5.000000    5.000000   \n",
       "50%      1.000000    4.000000    0.750000    0.250000    7.000000    7.000000   \n",
       "75%      2.000000    6.000000    1.000000    0.400000    9.000000    9.000000   \n",
       "max     44.000000   51.000000    1.000000    1.000000   17.000000   12.000000   \n",
       "\n",
       "         Misses14     Score14  Accuracy14  Missrate14    Clicks15      Hits15  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.312796    7.028436    0.956942    0.043058    4.033175    3.725118   \n",
       "std      1.456276    2.348079    0.152582    0.152582    2.107546    2.070262   \n",
       "min      0.000000    1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    5.000000    1.000000    0.000000    3.000000    2.000000   \n",
       "50%      0.000000    7.000000    1.000000    0.000000    4.000000    4.000000   \n",
       "75%      0.000000    9.000000    1.000000    0.000000    5.000000    5.000000   \n",
       "max     15.000000   17.000000    1.000000    1.000000   13.000000    9.000000   \n",
       "\n",
       "         Misses15     Score15  Accuracy15  Missrate15    Clicks16      Hits16  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.308057    4.033175    0.917016    0.073505    4.298578    4.132701   \n",
       "std      1.300140    2.107546    0.232415    0.214437    1.667889    1.606956   \n",
       "min      0.000000    0.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "25%      0.000000    3.000000    1.000000    0.000000    3.000000    3.000000   \n",
       "50%      0.000000    4.000000    1.000000    0.000000    4.000000    4.000000   \n",
       "75%      0.000000    5.000000    1.000000    0.000000    5.000000    5.000000   \n",
       "max     13.000000   13.000000    1.000000    1.000000   11.000000    9.000000   \n",
       "\n",
       "         Misses16     Score16  Accuracy16  Missrate16    Clicks17      Hits17  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.165877    4.298578    0.966109    0.033891    4.028436    3.554502   \n",
       "std      0.673280    1.667889    0.108813    0.108813    3.425277    1.734967   \n",
       "min      0.000000    1.000000    0.272727    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    3.000000    1.000000    0.000000    3.000000    2.000000   \n",
       "50%      0.000000    4.000000    1.000000    0.000000    4.000000    3.000000   \n",
       "75%      0.000000    5.000000    1.000000    0.000000    4.000000    4.000000   \n",
       "max      8.000000   11.000000    1.000000    0.727273   46.000000    9.000000   \n",
       "\n",
       "         Misses17     Score17  Accuracy17  Missrate17    Clicks18      Hits18  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  129.000000  129.000000   \n",
       "mean     0.473934    4.028436    0.923494    0.071767    4.193798    2.945736   \n",
       "std      3.337098    3.425277    0.199322    0.188874    2.899562    1.876292   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    3.000000    1.000000    0.000000    3.000000    2.000000   \n",
       "50%      0.000000    4.000000    1.000000    0.000000    4.000000    3.000000   \n",
       "75%      0.000000    4.000000    1.000000    0.000000    5.000000    4.000000   \n",
       "max     46.000000   46.000000    1.000000    1.000000   32.000000    8.000000   \n",
       "\n",
       "         Misses18     Score18  Accuracy18  Missrate18    Clicks19      Hits19  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
       "mean     1.248062    4.193798    0.689424    0.295072    4.333333    2.558140   \n",
       "std      2.407771    2.899562    0.359092    0.350408    3.065262    1.638916   \n",
       "min      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    0.500000    0.000000    3.000000    1.000000   \n",
       "50%      1.000000    4.000000    0.800000    0.200000    4.000000    2.000000   \n",
       "75%      2.000000    5.000000    1.000000    0.500000    5.000000    4.000000   \n",
       "max     24.000000   32.000000    1.000000    1.000000   33.000000    7.000000   \n",
       "\n",
       "         Misses19     Score19  Accuracy19  Missrate19    Clicks20      Hits20  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
       "mean     1.775194    4.333333    0.630575    0.369425    3.844961    1.108527   \n",
       "std      2.937474    3.065262    0.325014    0.325014    2.843440    1.154071   \n",
       "min      0.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    0.400000    0.000000    2.000000    0.000000   \n",
       "50%      1.000000    4.000000    0.666667    0.333333    3.000000    1.000000   \n",
       "75%      2.000000    5.000000    1.000000    0.600000    5.000000    2.000000   \n",
       "max     29.000000   33.000000    1.000000    1.000000   24.000000    6.000000   \n",
       "\n",
       "         Misses20     Score20  Accuracy20  Missrate20   Clicks21     Hits21  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  47.000000  47.000000   \n",
       "mean     2.736434    3.844961    0.336065    0.663935   4.723404   1.063830   \n",
       "std      2.824334    2.843440    0.323531    0.323531   7.828882   1.071453   \n",
       "min      0.000000    1.000000    0.000000    0.000000   1.000000   0.000000   \n",
       "25%      1.000000    2.000000    0.000000    0.500000   2.000000   0.000000   \n",
       "50%      2.000000    3.000000    0.333333    0.666667   3.000000   1.000000   \n",
       "75%      3.000000    5.000000    0.500000    1.000000   4.000000   2.000000   \n",
       "max     22.000000   24.000000    1.000000    1.000000  52.000000   5.000000   \n",
       "\n",
       "        Misses21    Score21  Accuracy21  Missrate21    Clicks22      Hits22  \\\n",
       "count  47.000000  47.000000   47.000000   47.000000  211.000000  211.000000   \n",
       "mean    3.659574   4.723404    0.345018    0.654982    4.459716    2.990521   \n",
       "std     7.352245   7.828882    0.348760    0.348760    2.107139    1.946891   \n",
       "min     0.000000   1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     1.000000   2.000000    0.000000    0.333333    3.000000    2.000000   \n",
       "50%     2.000000   3.000000    0.250000    0.750000    4.000000    3.000000   \n",
       "75%     3.000000   4.000000    0.666667    1.000000    5.000000    4.000000   \n",
       "max    47.000000  52.000000    1.000000    1.000000   14.000000   13.000000   \n",
       "\n",
       "         Misses22     Score22  Accuracy22  Missrate22    Clicks23      Hits23  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     1.469194    4.459716    0.654703    0.340557    5.535545    3.611374   \n",
       "std      1.480910    2.107139    0.309107    0.306678    4.906984    2.109088   \n",
       "min      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000    3.000000    0.500000    0.000000    3.000000    2.000000   \n",
       "50%      1.000000    4.000000    0.714286    0.285714    5.000000    3.000000   \n",
       "75%      2.000000    5.000000    1.000000    0.500000    6.000000    5.000000   \n",
       "max      8.000000   14.000000    1.000000    1.000000   65.000000   13.000000   \n",
       "\n",
       "         Misses23     Score23  Accuracy23  Missrate23   Clicks24      Hits24  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  129.00000  129.000000   \n",
       "mean     1.924171    5.535545    0.698685    0.301315    4.20155    3.193798   \n",
       "std      4.106201    4.906984    0.292853    0.292853    2.32641    1.924665   \n",
       "min      0.000000    1.000000    0.000000    0.000000    1.00000    0.000000   \n",
       "25%      0.000000    3.000000    0.500000    0.000000    3.00000    2.000000   \n",
       "50%      1.000000    5.000000    0.750000    0.250000    4.00000    3.000000   \n",
       "75%      2.000000    6.000000    1.000000    0.500000    6.00000    5.000000   \n",
       "max     52.000000   65.000000    1.000000    1.000000   15.00000    8.000000   \n",
       "\n",
       "         Misses24    Score24  Accuracy24  Missrate24   Clicks25     Hits25  \\\n",
       "count  129.000000  129.00000  129.000000  129.000000  47.000000  47.000000   \n",
       "mean     1.007752    4.20155    0.753488    0.246512   5.276596   3.659574   \n",
       "std      1.646474    2.32641    0.306213    0.306213   3.848784   1.891360   \n",
       "min      0.000000    1.00000    0.000000    0.000000   0.000000   0.000000   \n",
       "25%      0.000000    3.00000    0.500000    0.000000   3.000000   2.000000   \n",
       "50%      1.000000    4.00000    0.857143    0.142857   5.000000   3.000000   \n",
       "75%      1.000000    6.00000    1.000000    0.500000   6.000000   5.500000   \n",
       "max     10.000000   15.00000    1.000000    1.000000  22.000000   7.000000   \n",
       "\n",
       "        Misses25    Score25  Accuracy25  Missrate25    Clicks26      Hits26  \\\n",
       "count  47.000000  47.000000   47.000000   47.000000  129.000000  129.000000   \n",
       "mean    1.617021   5.276596    0.769814    0.208910    7.511628    4.829457   \n",
       "std     3.680461   3.848784    0.289512    0.267625    3.733539    2.961007   \n",
       "min     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     0.000000   3.000000    0.666667    0.000000    5.000000    2.000000   \n",
       "50%     1.000000   5.000000    0.833333    0.142857    7.000000    5.000000   \n",
       "75%     1.000000   6.000000    1.000000    0.291667   10.000000    7.000000   \n",
       "max    20.000000  22.000000    1.000000    0.909091   28.000000   15.000000   \n",
       "\n",
       "         Misses26     Score26  Accuracy26  Missrate26    Clicks27      Hits27  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
       "mean     2.682171    7.511628    0.613356    0.378892   30.635659    1.906977   \n",
       "std      2.417335    3.733539    0.273258    0.269886   19.342286    1.502300   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    5.000000    0.428571    0.200000   18.000000    1.000000   \n",
       "50%      2.000000    7.000000    0.666667    0.333333   30.000000    2.000000   \n",
       "75%      4.000000   10.000000    0.777778    0.555556   42.000000    3.000000   \n",
       "max     22.000000   28.000000    1.000000    1.000000  148.000000    6.000000   \n",
       "\n",
       "         Misses27     Score27  Accuracy27  Missrate27    Clicks28      Hits28  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
       "mean     0.906977   30.635659    0.054973    0.028229   24.341085    2.449612   \n",
       "std      1.371825   19.342286    0.036263    0.030689   12.482798    1.681523   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   18.000000    0.033333    0.000000   18.000000    1.000000   \n",
       "50%      1.000000   30.000000    0.057692    0.022727   24.000000    2.000000   \n",
       "75%      1.000000   42.000000    0.083333    0.050000   32.000000    3.000000   \n",
       "max     13.000000  148.000000    0.111111    0.111111  102.000000    6.000000   \n",
       "\n",
       "         Misses28     Score28  Accuracy28  Missrate28    Clicks30      Hits30  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  211.000000  211.000000   \n",
       "mean     1.271318   24.341085    0.102496    0.051896   19.066351    1.127962   \n",
       "std      1.753354   12.482798    0.055883    0.053155    3.391215    1.111723   \n",
       "min      0.000000    0.000000    0.000000    0.000000    3.000000    0.000000   \n",
       "25%      0.000000   18.000000    0.055556    0.000000   18.000000    0.000000   \n",
       "50%      1.000000   24.000000    0.111111    0.041667   21.000000    1.000000   \n",
       "75%      2.000000   32.000000    0.156250    0.083333   21.000000    2.000000   \n",
       "max     14.000000  102.000000    0.166667    0.166667   21.000000    4.000000   \n",
       "\n",
       "         Misses30     Score30  Accuracy30  Missrate30    Clicks31     Hits31  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000   47.000000  47.000000   \n",
       "mean     2.255924   19.066351    0.056214    0.115787   45.893617   3.361702   \n",
       "std      1.163288    3.391215    0.053632    0.055772   16.949072   0.965166   \n",
       "min      0.000000    3.000000    0.000000    0.000000   34.000000   1.000000   \n",
       "25%      1.000000   18.000000    0.000000    0.090909   35.000000   3.000000   \n",
       "50%      2.000000   21.000000    0.047619    0.117647   35.000000   4.000000   \n",
       "75%      3.000000   21.000000    0.095238    0.148352   52.500000   4.000000   \n",
       "max      4.000000   21.000000    0.190476    0.200000  124.000000   4.000000   \n",
       "\n",
       "        Misses31     Score31  Accuracy31  Missrate31    Clicks32     Hits32  \\\n",
       "count  47.000000   47.000000   47.000000   47.000000   47.000000  47.000000   \n",
       "mean    2.765957   45.893617    0.082811    0.044919   46.978723   2.765957   \n",
       "std     3.990275   16.949072    0.036187    0.052024   20.820652   0.937452   \n",
       "min     0.000000   34.000000    0.016667    0.000000   23.000000   0.000000   \n",
       "25%     0.000000   35.000000    0.048438    0.000000   31.500000   2.000000   \n",
       "50%     0.000000   35.000000    0.114286    0.000000   43.000000   3.000000   \n",
       "75%     4.000000   52.500000    0.114286    0.088008   56.000000   3.000000   \n",
       "max    20.000000  124.000000    0.114286    0.169014  112.000000   4.000000   \n",
       "\n",
       "        Misses32     Score32  Accuracy32  Missrate32   Dyslexia  \n",
       "count  47.000000   47.000000   47.000000   47.000000  211.00000  \n",
       "mean    6.723404   46.978723    0.073879    0.119116    0.57346  \n",
       "std     6.006164   20.820652    0.045290    0.074971    0.49575  \n",
       "min     0.000000   23.000000    0.000000    0.000000    0.00000  \n",
       "25%     2.000000   31.500000    0.042572    0.067816    0.00000  \n",
       "50%     6.000000   43.000000    0.063830    0.133333    1.00000  \n",
       "75%    10.000000   56.000000    0.101724    0.171053    1.00000  \n",
       "max    24.000000  112.000000    0.153846    0.315789    1.00000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras observar la distribución de los *dataset* originales y comprobar como sí presentan outliers, se va a proceder con el análisis y la eliminación de aquellos valores que no aporten información válida y vayan a afectar negativamente al modelo.\n",
    "\n",
    "La función `distplot` se va a emplear para identificar la forma en que los datos están distribuidos, verificando si siguen una distribución normal o no, como afecta la presencia de outliers a la distribución y cual es la media y la desviación estándar. Es decir, se va a representar visualmente la distribución de los datos de cada variable.\n",
    "\n",
    "La función `boxplot`representa el rango intercuartílico (IQR) de los datos. La caja (gráfico) va desde el primer cuartil (Q1) hasta el tercer cuartil (Q3), y su longitud representa el rango intercuartílico (IQR = Q3 - Q1). Los valores atípicos (outliers) son aquellos que están fuera del rango definido por 1,5 veces el IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(df):\n",
    "    \n",
    "    rest = df.shape[1] % 4\n",
    "    rows = df.shape[1]//4\n",
    "    \n",
    "    if rest == 0:\n",
    "        rows = rows\n",
    "    else:\n",
    "        rows = rows + 1\n",
    "        \n",
    "    fig, ax = plt.subplots(ncols = 4, nrows = rows, figsize = (15, 150))\n",
    "    i = 0\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for col in df.columns:\n",
    "        plt.title(col)\n",
    "        sns.distplot(df[col], ax=ax[i])\n",
    "        i+=1\n",
    "    plt.tight_layout(pad = 0.5, w_pad = 0.7, h_pad = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_whisker(df):\n",
    "    \n",
    "    rest = df.shape[1] % 4\n",
    "    rows = df.shape[1]//4\n",
    "    \n",
    "    if rest == 0:\n",
    "        rows = rows\n",
    "    else:\n",
    "        rows = rows + 1\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 4, nrows = rows, figsize = (15, 150))\n",
    "    i = 0\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        plt.title(col)\n",
    "        df.boxplot([col], ax=ax[i])\n",
    "        i+=1\n",
    "    plt.tight_layout(pad = 0.5, w_pad = 0.7, h_pad = 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de aplicar ningún método de detección de outliers se van a eliminar aquellos valores de *Accuracy* y *Missrate* mayores a 1. Estas variables representan porcentajes, ya que se obtienen de dividir los aciertos y fallos entre el número de cliks, respectivamente. Por ello, de forma manual se van a limpiar los *dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 DROP\n",
    "drop_Q = drop_df.drop(columns = ['Gender','Nativelang','Otherlang','Age','Dyslexia'], axis = 1)\n",
    "\n",
    "#2 ZEROS\n",
    "zero_Q = zero_df.drop(columns = ['Gender','Nativelang','Otherlang','Age','Dyslexia'], axis = 1)\n",
    "\n",
    "#3.1 MEAN\n",
    "mean_Q = mean_df.drop(columns = ['Gender','Nativelang','Otherlang','Age','Dyslexia'], axis = 1)\n",
    "\n",
    "#3.2 MEDIAN\n",
    "median_Q = median_df.drop(columns = ['Gender','Nativelang','Otherlang','Age','Dyslexia'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_dist(drop_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box_whisker(drop_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(zero_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box_whisker(zero_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(mean_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box_whisker(mean_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(median_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box_whisker(median_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentile method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la eleminación de outliers existen varias técnicas, como Z-score method, Inter Quartile Range Method o Percentile method. la técnica que se ha elegido es el método de percentil ya que es fácil de entender y aplicar, y no requiere de una distribución específica. Como se ha podido observar, no todas las variables tienen la misma distribución, lo que podría suponer un problema utilizando Z-score o el método del Intercuartil.\n",
    "\n",
    "Se trata de un método robusto a la presencia de valores atípicos en los datos, lo que lo hace menos propenso a ser afectado por ellos, y permite ajustar los límites al dataset con el que se esté trabajando. En este caso, para no prescindir de un gran número de datos, aun eliminando aquellos datos que influían negativamente al modelo, se han establecido como umbral superior el 0.999 e inferior el 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(ds):\n",
    "    print(\"Old Shape: \", ds.shape)\n",
    "    \n",
    "    rng = ds.columns\n",
    "    for col in rng:\n",
    "        #first percentile\n",
    "        min_threshold = ds[col].quantile(0.001)\n",
    "        #third percentile\n",
    "        max_threshold = ds[col].quantile(0.999)\n",
    "        \n",
    "        ds.drop(ds[(ds[col] < min_threshold) | (ds[col] > max_threshold)].index, inplace=True)\n",
    "        \n",
    "    print(\"New Shape: \", ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP\n",
      "ZEROS\n",
      "Old Shape:  (211, 186)\n",
      "New Shape:  (132, 186)\n",
      "MEAN\n",
      "Old Shape:  (211, 186)\n",
      "New Shape:  (126, 186)\n",
      "MEDIAN\n",
      "Old Shape:  (211, 186)\n",
      "New Shape:  (127, 186)\n"
     ]
    }
   ],
   "source": [
    "#1 DROP\n",
    "print(\"DROP\")\n",
    "#remove_outliers(drop_Q) \n",
    "\n",
    "#2 ZEROS\n",
    "print(\"ZEROS\")\n",
    "remove_outliers(zero_Q)\n",
    "\n",
    "#3.1 MEAN\n",
    "print(\"MEAN\")\n",
    "remove_outliers(mean_Q)\n",
    "\n",
    "#3.2 MEDIAN\n",
    "print(\"MEDIAN\")\n",
    "remove_outliers(median_Q) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representando de nuevo los gráficos de distribución se puede observar como la presencia de outliers ha disminuido considerablemente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_dist(drop_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(zero_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_dist(train_mean_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MEDIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_dist(median_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan aquellas filas que contienen valores anómalos de los datasets inciales, recuperando las columnas: 'Gender', 'Nativelang', 'Otherlang', 'Age', 'Dyslexia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 DROP\n",
    "drop_df = drop_df.loc[drop_Q.index]\n",
    "\n",
    "#2 ZEROS\n",
    "zero_df = zero_df.loc[zero_Q.index]\n",
    "\n",
    "#3.1 MEAN\n",
    "mean_df = mean_df.loc[mean_Q.index]\n",
    "\n",
    "#3.2 MEDIAN\n",
    "median_df = median_df.loc[median_Q.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se van a definir dos funciones nuevas, `corr_hit_miss`y `corr_acc_missrate`, para comparar como de correladas están las variables *Clicks*, *Hits*, *Misses* y *Score* y la suma de las variables *Hits y Misses* con *Clicks*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_hit_miss(ds, nombre):\n",
    "    print(nombre+\" dataset\")\n",
    "    for i in range(32):\n",
    "        try:        \n",
    "            print(\"Question\", str(i+1))\n",
    "            #Pearson correlation coef\n",
    "            correlation_misses = ds['Clicks'+str(i+1)].corr(ds['Misses'+str(i+1)])\n",
    "            correlation_hits = ds['Clicks'+str(i+1)].corr(ds['Hits'+str(i+1)])\n",
    "            correlation_score = ds['Clicks'+str(i+1)].corr(ds['Score'+str(i+1)])\n",
    "\n",
    "            ds['Hits + Misses'+str(i+1)] = ds['Hits'+str(i+1)] + ds['Misses'+str(i+1)]\n",
    "            correlation_sum = ds['Clicks'+str(i+1)].corr(ds['Hits + Misses'+str(i+1)])\n",
    "\n",
    "            print(\"Misses\", str(i+1), correlation_misses)\n",
    "            print(\"Hits\", str(i+1), correlation_hits)\n",
    "            print(\"Score\", str(i+1), correlation_score)\n",
    "            print(\"Hits + Misses\", str(i+1), correlation_sum)\n",
    "        except KeyError:\n",
    "            print(\"Question \"+str(i+1)+\" not in the dataset\")\n",
    "            \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_acc_missrate(ds, nombre):\n",
    "    print(nombre+\" dataset\")\n",
    "    for i in  range(32):\n",
    "        try:\n",
    "            print(\"Question\"+str(i+1))\n",
    "            #Pearson correlation coeff\n",
    "            correlation_acc = ds['Hits'+str(i+1)].corr(ds['Accuracy'+str(i+1)])\n",
    "            correlation_missrate = ds['Misses'+str(i+1)].corr(ds['Missrate'+str(i+1)])\n",
    "            correlation_accs_rate = ds['Accuracy'+str(i+1)].corr(ds['Missrate'+str(i+1)])\n",
    "\n",
    "            print(\"Accuracy\"+str(i+1),correlation_acc)\n",
    "            print(\"Missrate\"+str(i+1),correlation_missrate)\n",
    "            print(\"Between Accuracy and Missrate\"+str(i+1),correlation_accs_rate)\n",
    "        except KeyError:\n",
    "            print(\"Question \"+str(i+1)+\" not in the dataset\")\n",
    "            \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprobará tanto para los dataset de entrenamiento, como de prueba y diferenciando entre los cuatro casos distintos tras aplicar las técnicas de gestión de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP\n",
      "Model dataset\n",
      "Question 1\n",
      "Misses 1 -0.0740750198254977\n",
      "Hits 1 0.9911811392136236\n",
      "Score 1 1.0\n",
      "Hits + Misses 1 1.0\n",
      "Question 2\n",
      "Misses 2 0.15963744349324951\n",
      "Hits 2 0.9813625239389863\n",
      "Score 2 1.0\n",
      "Hits + Misses 2 1.0\n",
      "Question 3\n",
      "Misses 3 -0.25236239879926425\n",
      "Hits 3 0.9726745113942238\n",
      "Score 3 1.0\n",
      "Hits + Misses 3 1.0\n",
      "Question 4\n",
      "Misses 4 0.6033094628070051\n",
      "Hits 4 0.1356861060969638\n",
      "Score 4 1.0\n",
      "Hits + Misses 4 1.0\n",
      "Question 5\n",
      "Misses 5 -0.28538076169283944\n",
      "Hits 5 0.969788520929003\n",
      "Score 5 1.0\n",
      "Hits + Misses 5 1.0\n",
      "Question 6\n",
      "Misses 6 -0.11449097997310631\n",
      "Hits 6 0.818889176999509\n",
      "Score 6 0.9999999999999998\n",
      "Hits + Misses 6 0.9999999999999998\n",
      "Question 7\n",
      "Misses 7 0.8962281190858729\n",
      "Hits 7 0.9990842317545451\n",
      "Score 7 0.9999999999999999\n",
      "Hits + Misses 7 0.9999999999999999\n",
      "Question 8\n",
      "Misses 8 -0.03612110375055235\n",
      "Hits 8 0.9353870660210596\n",
      "Score 8 1.0\n",
      "Hits + Misses 8 1.0\n",
      "Question 9\n",
      "Misses 9 0.8773113220258905\n",
      "Hits 9 0.25663059364841645\n",
      "Score 9 0.9999999999999998\n",
      "Hits + Misses 9 0.9999999999999998\n",
      "Question 10\n",
      "Misses 10 0.7256286881181414\n",
      "Hits 10 0.32345799025581606\n",
      "Score 10 1.0\n",
      "Hits + Misses 10 1.0\n",
      "Question 11\n",
      "Misses 11 0.5300883501905415\n",
      "Hits 11 0.7184051772139369\n",
      "Score 11 1.0\n",
      "Hits + Misses 11 1.0\n",
      "Question 12\n",
      "Misses 12 0.9622393411783176\n",
      "Hits 12 0.2904722518033831\n",
      "Score 12 1.0\n",
      "Hits + Misses 12 1.0\n",
      "Question 13\n",
      "Misses 13 0.9748114241833467\n",
      "Hits 13 0.40438655239458116\n",
      "Score 13 0.9999999999999999\n",
      "Hits + Misses 13 0.9999999999999999\n",
      "Question 14\n",
      "Misses 14 -0.05206826946220599\n",
      "Hits 14 0.9851901881019564\n",
      "Score 14 1.0\n",
      "Hits + Misses 14 1.0\n",
      "Question 15\n",
      "Misses 15 0.013956150333291114\n",
      "Hits 15 0.9386260269702271\n",
      "Score 15 1.0\n",
      "Hits + Misses 15 1.0\n",
      "Question 16\n",
      "Misses 16 -0.14374046179474712\n",
      "Hits 16 0.9774753017329807\n",
      "Score 16 1.0\n",
      "Hits + Misses 16 1.0\n",
      "Question 17\n",
      "Misses 17 0.9580788014323403\n",
      "Hits 17 -0.11060224960505445\n",
      "Score 17 1.0\n",
      "Hits + Misses 17 1.0\n",
      "Question 18\n",
      "Misses 18 0.9065457136282712\n",
      "Hits 18 0.5945670189756221\n",
      "Score 18 1.0\n",
      "Hits + Misses 18 1.0\n",
      "Question 19\n",
      "Misses 19 0.9218394525271345\n",
      "Hits 19 0.27680531464846464\n",
      "Score 19 1.0\n",
      "Hits + Misses 19 1.0\n",
      "Question 20\n",
      "Misses 20 0.939363974156528\n",
      "Hits 20 0.3184860699709887\n",
      "Score 20 1.0\n",
      "Hits + Misses 20 1.0\n",
      "Question 21\n",
      "Misses 21 0.9920011278500913\n",
      "Hits 21 0.49973928027831416\n",
      "Score 21 0.9999999999999999\n",
      "Hits + Misses 21 0.9999999999999999\n",
      "Question 22\n",
      "Misses 22 0.16326216024245477\n",
      "Hits 22 0.867697647282693\n",
      "Score 22 1.0\n",
      "Hits + Misses 22 1.0\n",
      "Question 23\n",
      "Misses 23 0.733072798219358\n",
      "Hits 23 0.778105441261219\n",
      "Score 23 1.0\n",
      "Hits + Misses 23 1.0\n",
      "Question 24\n",
      "Misses 24 0.5922909739655153\n",
      "Hits 24 0.7210358563283388\n",
      "Score 24 0.9999999999999998\n",
      "Hits + Misses 24 0.9999999999999998\n",
      "Question 25\n",
      "Misses 25 0.8747322197642495\n",
      "Hits 25 0.3327584865514329\n",
      "Score 25 1.0\n",
      "Hits + Misses 25 1.0\n",
      "Question 26\n",
      "Misses 26 0.31665635884983945\n",
      "Hits 26 0.833106319967195\n",
      "Score 26 1.0\n",
      "Hits + Misses 26 1.0\n",
      "Question 27\n",
      "Misses 27 0.7232376923280538\n",
      "Hits 27 0.4331805967954089\n",
      "Score 27 1.0\n",
      "Hits + Misses 27 0.989356130739672\n",
      "Question 28\n",
      "Misses 28 0.22649450691831904\n",
      "Hits 28 0.6269539170859446\n",
      "Score 28 1.0\n",
      "Hits + Misses 28 0.9792695943290608\n",
      "Question 29\n",
      "Question 29 not in the dataset\n",
      "Question 30\n",
      "Misses 30 -0.03939286667920323\n",
      "Hits 30 0.2739087976659108\n",
      "Score 30 0.9999999999999999\n",
      "Hits + Misses 30 0.9964325991239529\n",
      "Question 31\n",
      "Misses 31 0.9629651138101011\n",
      "Hits 31 -0.4215177610997045\n",
      "Score 31 0.9999999999999998\n",
      "Hits + Misses 31 0.9698694122507044\n",
      "Question 32\n",
      "Misses 32 0.9360823683462905\n",
      "Hits 32 -0.5014610696231678\n",
      "Score 32 1.0\n",
      "Hits + Misses 32 0.9504333069650225\n",
      "\n",
      "\n",
      "ZEROS\n",
      "Model dataset\n",
      "Question 1\n",
      "Misses 1 -0.0624292187647756\n",
      "Hits 1 0.9808662389314846\n",
      "Score 1 0.9999999999999999\n",
      "Hits + Misses 1 0.9999999999999999\n",
      "Question 2\n",
      "Misses 2 -0.10075022140643977\n",
      "Hits 2 0.9388941217553523\n",
      "Score 2 0.9999999999999998\n",
      "Hits + Misses 2 0.9999999999999998\n",
      "Question 3\n",
      "Misses 3 -0.1707612853135727\n",
      "Hits 3 0.942373003956698\n",
      "Score 3 1.0\n",
      "Hits + Misses 3 1.0\n",
      "Question 4\n",
      "Misses 4 0.46260990765901466\n",
      "Hits 4 0.4565553869661478\n",
      "Score 4 1.0\n",
      "Hits + Misses 4 1.0\n",
      "Question 5\n",
      "Misses 5 -0.15805260796204695\n",
      "Hits 5 0.9213065711181426\n",
      "Score 5 1.0\n",
      "Hits + Misses 5 1.0\n",
      "Question 6\n",
      "Misses 6 0.2202208834273445\n",
      "Hits 6 0.7513761808974286\n",
      "Score 6 0.9999999999999999\n",
      "Hits + Misses 6 0.9999999999999999\n",
      "Question 7\n",
      "Misses 7 -0.12341492063417621\n",
      "Hits 7 0.9759488595573947\n",
      "Score 7 1.0\n",
      "Hits + Misses 7 1.0\n",
      "Question 8\n",
      "Misses 8 0.004160603057502727\n",
      "Hits 8 0.9392070827583351\n",
      "Score 8 1.0\n",
      "Hits + Misses 8 1.0\n",
      "Question 9\n",
      "Misses 9 0.38644920243978537\n",
      "Hits 9 0.5666391256236578\n",
      "Score 9 1.0\n",
      "Hits + Misses 9 1.0\n",
      "Question 10\n",
      "Misses 10 -0.18415399458845763\n",
      "Hits 10 0.9082879286481023\n",
      "Score 10 0.9999999999999999\n",
      "Hits + Misses 10 0.9999999999999999\n",
      "Question 11\n",
      "Misses 11 0.23472802687449426\n",
      "Hits 11 0.8641021927912601\n",
      "Score 11 0.9999999999999999\n",
      "Hits + Misses 11 0.9999999999999999\n",
      "Question 12\n",
      "Misses 12 0.2489109738498528\n",
      "Hits 12 0.8248087234922185\n",
      "Score 12 1.0\n",
      "Hits + Misses 12 1.0\n",
      "Question 13\n",
      "Misses 13 0.6568022714629362\n",
      "Hits 13 0.9421358692726208\n",
      "Score 13 1.0\n",
      "Hits + Misses 13 1.0\n",
      "Question 14\n",
      "Misses 14 -0.10049105270236865\n",
      "Hits 14 0.9879969833552156\n",
      "Score 14 1.0\n",
      "Hits + Misses 14 1.0\n",
      "Question 15\n",
      "Misses 15 -0.07587294430385147\n",
      "Hits 15 0.9670328969950212\n",
      "Score 15 0.9999999999999999\n",
      "Hits + Misses 15 0.9999999999999999\n",
      "Question 16\n",
      "Misses 16 0.17329044324888881\n",
      "Hits 16 0.9796924961171223\n",
      "Score 16 0.9999999999999998\n",
      "Hits + Misses 16 0.9999999999999998\n",
      "Question 17\n",
      "Misses 17 0.045280887157651974\n",
      "Hits 17 0.9611199835898991\n",
      "Score 17 1.0\n",
      "Hits + Misses 17 1.0\n",
      "Question 18\n",
      "Misses 18 0.4731772625196921\n",
      "Hits 18 0.9134375746682626\n",
      "Score 18 0.9999999999999998\n",
      "Hits + Misses 18 0.9999999999999998\n",
      "Question 19\n",
      "Misses 19 0.7659777817811114\n",
      "Hits 19 0.8394665946187491\n",
      "Score 19 1.0\n",
      "Hits + Misses 19 1.0\n",
      "Question 20\n",
      "Misses 20 0.9165687949701952\n",
      "Hits 20 0.5946766553946918\n",
      "Score 20 0.9999999999999999\n",
      "Hits + Misses 20 0.9999999999999999\n",
      "Question 21\n",
      "Misses 21 0.8826197028040697\n",
      "Hits 21 0.7991616882951005\n",
      "Score 21 0.9999999999999999\n",
      "Hits + Misses 21 0.9999999999999999\n",
      "Question 22\n",
      "Misses 22 0.37217420364964643\n",
      "Hits 22 0.7148561665350762\n",
      "Score 22 1.0\n",
      "Hits + Misses 22 1.0\n",
      "Question 23\n",
      "Misses 23 0.2835106956108063\n",
      "Hits 23 0.7638621158757938\n",
      "Score 23 1.0\n",
      "Hits + Misses 23 1.0\n",
      "Question 24\n",
      "Misses 24 0.4228399399501631\n",
      "Hits 24 0.9434139315790524\n",
      "Score 24 1.0\n",
      "Hits + Misses 24 1.0\n",
      "Question 25\n",
      "Misses 25 0.7294970871218162\n",
      "Hits 25 0.9863436832133291\n",
      "Score 25 1.0\n",
      "Hits + Misses 25 1.0\n",
      "Question 26\n",
      "Misses 26 0.7045409339487622\n",
      "Hits 26 0.9314951482326419\n",
      "Score 26 1.0\n",
      "Hits + Misses 26 1.0\n",
      "Question 27\n",
      "Misses 27 0.6302435177688324\n",
      "Hits 27 0.9252670752832679\n",
      "Score 27 1.0\n",
      "Hits + Misses 27 0.9895939559533546\n",
      "Question 28\n",
      "Misses 28 0.5119537359876578\n",
      "Hits 28 0.8408953736729842\n",
      "Score 28 1.0\n",
      "Hits + Misses 28 0.995556570797803\n",
      "Question 29\n",
      "Question 29 not in the dataset\n",
      "Question 30\n",
      "Misses 30 0.5848026502120792\n",
      "Hits 30 0.3682175211856391\n",
      "Score 30 1.0\n",
      "Hits + Misses 30 0.9533451354879396\n",
      "Question 31\n",
      "Misses 31 0.7933200041806946\n",
      "Hits 31 0.9127761188375915\n",
      "Score 31 1.0\n",
      "Hits + Misses 31 0.9949978901692091\n",
      "Question 32\n",
      "Misses 32 0.9114887044926073\n",
      "Hits 32 0.9353625481886597\n",
      "Score 32 0.9999999999999999\n",
      "Hits + Misses 32 0.993946888830608\n",
      "\n",
      "\n",
      "MEAN\n",
      "Model dataset\n",
      "Question 1\n",
      "Misses 1 -0.06634670784257327\n",
      "Hits 1 0.9802572889820698\n",
      "Score 1 0.9999999999999999\n",
      "Hits + Misses 1 0.9999999999999999\n",
      "Question 2\n",
      "Misses 2 -0.10090694459065534\n",
      "Hits 2 0.9389576974554962\n",
      "Score 2 1.0\n",
      "Hits + Misses 2 1.0\n",
      "Question 3\n",
      "Misses 3 -0.17517027120047904\n",
      "Hits 3 0.942326340117174\n",
      "Score 3 1.0\n",
      "Hits + Misses 3 1.0\n",
      "Question 4\n",
      "Misses 4 0.5040557804327817\n",
      "Hits 4 0.40156114477952076\n",
      "Score 4 1.0\n",
      "Hits + Misses 4 1.0\n",
      "Question 5\n",
      "Misses 5 -0.1475100645611052\n",
      "Hits 5 0.9196117555993795\n",
      "Score 5 0.9999999999999999\n",
      "Hits + Misses 5 0.9999999999999999\n",
      "Question 6\n",
      "Misses 6 0.23181427222286544\n",
      "Hits 6 0.7467074826437213\n",
      "Score 6 1.0\n",
      "Hits + Misses 6 1.0\n",
      "Question 7\n",
      "Misses 7 -0.11199600589815767\n",
      "Hits 7 0.9747098822972224\n",
      "Score 7 1.0\n",
      "Hits + Misses 7 1.0\n",
      "Question 8\n",
      "Misses 8 0.017256537885612676\n",
      "Hits 8 0.9366728312132618\n",
      "Score 8 1.0\n",
      "Hits + Misses 8 1.0\n",
      "Question 9\n",
      "Misses 9 0.39572342025120527\n",
      "Hits 9 0.5657743810528296\n",
      "Score 9 1.0\n",
      "Hits + Misses 9 1.0\n",
      "Question 10\n",
      "Misses 10 -0.1723346227386518\n",
      "Hits 10 0.9039773270199497\n",
      "Score 10 1.0\n",
      "Hits + Misses 10 1.0\n",
      "Question 11\n",
      "Misses 11 0.2767696922476725\n",
      "Hits 11 0.8500475040519245\n",
      "Score 11 0.9999999999999999\n",
      "Hits + Misses 11 0.9999999999999999\n",
      "Question 12\n",
      "Misses 12 0.2777581322642522\n",
      "Hits 12 0.8149965664701209\n",
      "Score 12 1.0\n",
      "Hits + Misses 12 1.0\n",
      "Question 13\n",
      "Misses 13 0.4240913522394101\n",
      "Hits 13 0.7917629499585542\n",
      "Score 13 1.0\n",
      "Hits + Misses 13 1.0\n",
      "Question 14\n",
      "Misses 14 -0.1023381882873523\n",
      "Hits 14 0.9873964907297276\n",
      "Score 14 0.9999999999999999\n",
      "Hits + Misses 14 0.9999999999999999\n",
      "Question 15\n",
      "Misses 15 -0.07019848786457222\n",
      "Hits 15 0.9661685300512146\n",
      "Score 15 1.0\n",
      "Hits + Misses 15 1.0\n",
      "Question 16\n",
      "Misses 16 0.18340616899381856\n",
      "Hits 16 0.9781064155778757\n",
      "Score 16 0.9999999999999998\n",
      "Hits + Misses 16 0.9999999999999998\n",
      "Question 17\n",
      "Misses 17 0.04651737425355512\n",
      "Hits 17 0.9614505410625028\n",
      "Score 17 1.0\n",
      "Hits + Misses 17 1.0\n",
      "Question 18\n",
      "Misses 18 0.0847569815457244\n",
      "Hits 18 0.7499254887567338\n",
      "Score 18 1.0\n",
      "Hits + Misses 18 1.0\n",
      "Question 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misses 19 0.628562208062806\n",
      "Hits 19 0.5665761077972185\n",
      "Score 19 1.0\n",
      "Hits + Misses 19 1.0\n",
      "Question 20\n",
      "Misses 20 0.8431580265684702\n",
      "Hits 20 0.3304030574630059\n",
      "Score 20 0.9999999999999998\n",
      "Hits + Misses 20 0.9999999999999998\n",
      "Question 21\n",
      "Misses 21 0.9726392323968461\n",
      "Hits 21 0.15015357585087552\n",
      "Score 21 1.0\n",
      "Hits + Misses 21 1.0\n",
      "Question 22\n",
      "Misses 22 0.3721947672864184\n",
      "Hits 22 0.7121541579294548\n",
      "Score 22 1.0\n",
      "Hits + Misses 22 1.0\n",
      "Question 23\n",
      "Misses 23 0.3027057446200675\n",
      "Hits 23 0.7641591564103671\n",
      "Score 23 1.0\n",
      "Hits + Misses 23 1.0\n",
      "Question 24\n",
      "Misses 24 0.04409014267935615\n",
      "Hits 24 0.8764444831676921\n",
      "Score 24 1.0\n",
      "Hits + Misses 24 1.0\n",
      "Question 25\n",
      "Misses 25 0.5771232347521483\n",
      "Hits 25 0.8915789767796825\n",
      "Score 25 1.0\n",
      "Hits + Misses 25 1.0\n",
      "Question 26\n",
      "Misses 26 0.3509142889680914\n",
      "Hits 26 0.8485997897256582\n",
      "Score 26 1.0\n",
      "Hits + Misses 26 0.9999999999999996\n",
      "Question 27\n",
      "Misses 27 0.34564922170735735\n",
      "Hits 27 0.8775107306857463\n",
      "Score 27 1.0\n",
      "Hits + Misses 27 0.9775244153353067\n",
      "Question 28\n",
      "Misses 28 0.21320728287576857\n",
      "Hits 28 0.6685085265985456\n",
      "Score 28 1.0\n",
      "Hits + Misses 28 0.9855226720206257\n",
      "Question 29\n",
      "Question 29 not in the dataset\n",
      "Question 30\n",
      "Misses 30 0.5854800827722701\n",
      "Hits 30 0.38783670784210844\n",
      "Score 30 0.9999999999999999\n",
      "Hits + Misses 30 0.9525775770348934\n",
      "Question 31\n",
      "Misses 31 0.9741127613373468\n",
      "Hits 31 -0.709823638382711\n",
      "Score 31 1.0\n",
      "Hits + Misses 31 0.9779442825690662\n",
      "Question 32\n",
      "Misses 32 0.9879994014207303\n",
      "Hits 32 -0.9396145020771004\n",
      "Score 32 1.0\n",
      "Hits + Misses 32 0.9806591205335807\n",
      "\n",
      "\n",
      "MEDIAN\n",
      "Model dataset\n",
      "Question 1\n",
      "Misses 1 -0.06586012873203209\n",
      "Hits 1 0.980250291198428\n",
      "Score 1 1.0\n",
      "Hits + Misses 1 1.0\n",
      "Question 2\n",
      "Misses 2 -0.1018070312207652\n",
      "Hits 2 0.939016656560734\n",
      "Score 2 1.0\n",
      "Hits + Misses 2 1.0\n",
      "Question 3\n",
      "Misses 3 -0.17480418209386658\n",
      "Hits 3 0.9422720907962442\n",
      "Score 3 1.0\n",
      "Hits + Misses 3 1.0\n",
      "Question 4\n",
      "Misses 4 0.49623350934625515\n",
      "Hits 4 0.4096795557548372\n",
      "Score 4 1.0\n",
      "Hits + Misses 4 1.0\n",
      "Question 5\n",
      "Misses 5 -0.14722966616297273\n",
      "Hits 5 0.9194423155427792\n",
      "Score 5 1.0\n",
      "Hits + Misses 5 1.0\n",
      "Question 6\n",
      "Misses 6 0.22293923847066074\n",
      "Hits 6 0.749561154949078\n",
      "Score 6 1.0\n",
      "Hits + Misses 6 1.0\n",
      "Question 7\n",
      "Misses 7 -0.11628518866174439\n",
      "Hits 7 0.9753926635659939\n",
      "Score 7 0.9999999999999999\n",
      "Hits + Misses 7 0.9999999999999999\n",
      "Question 8\n",
      "Misses 8 0.012964540571442033\n",
      "Hits 8 0.9371061057468887\n",
      "Score 8 1.0\n",
      "Hits + Misses 8 1.0\n",
      "Question 9\n",
      "Misses 9 0.3972426956943281\n",
      "Hits 9 0.5641456089142693\n",
      "Score 9 1.0\n",
      "Hits + Misses 9 1.0\n",
      "Question 10\n",
      "Misses 10 -0.17475650323118866\n",
      "Hits 10 0.9047488906485885\n",
      "Score 10 1.0\n",
      "Hits + Misses 10 1.0\n",
      "Question 11\n",
      "Misses 11 0.25587442734196375\n",
      "Hits 11 0.8569400112701806\n",
      "Score 11 1.0\n",
      "Hits + Misses 11 1.0\n",
      "Question 12\n",
      "Misses 12 0.26950105326501994\n",
      "Hits 12 0.8171641094067482\n",
      "Score 12 1.0\n",
      "Hits + Misses 12 1.0\n",
      "Question 13\n",
      "Misses 13 0.35394580637864964\n",
      "Hits 13 0.8014996991453758\n",
      "Score 13 1.0\n",
      "Hits + Misses 13 1.0\n",
      "Question 14\n",
      "Misses 14 -0.10441423358834426\n",
      "Hits 14 0.9875812672040102\n",
      "Score 14 1.0\n",
      "Hits + Misses 14 1.0\n",
      "Question 15\n",
      "Misses 15 -0.07176443499988504\n",
      "Hits 15 0.9663383121492379\n",
      "Score 15 1.0\n",
      "Hits + Misses 15 1.0\n",
      "Question 16\n",
      "Misses 16 0.17391938987210728\n",
      "Hits 16 0.9790549119528412\n",
      "Score 16 1.0\n",
      "Hits + Misses 16 1.0\n",
      "Question 17\n",
      "Misses 17 0.04293280267260042\n",
      "Hits 17 0.9618116536332563\n",
      "Score 17 1.0\n",
      "Hits + Misses 17 1.0\n",
      "Question 18\n",
      "Misses 18 0.006515309188119656\n",
      "Hits 18 0.7828571700910417\n",
      "Score 18 1.0\n",
      "Hits + Misses 18 1.0\n",
      "Question 19\n",
      "Misses 19 0.5125518932585827\n",
      "Hits 19 0.4819104130665281\n",
      "Score 19 1.0\n",
      "Hits + Misses 19 0.8772952830493849\n",
      "Question 20\n",
      "Misses 20 0.8368284540468419\n",
      "Hits 20 0.2816059922176294\n",
      "Score 20 1.0\n",
      "Hits + Misses 20 1.0\n",
      "Question 21\n",
      "Misses 21 0.8515865213769533\n",
      "Hits 21 0.22913337282769267\n",
      "Score 21 0.9999999999999999\n",
      "Hits + Misses 21 0.9999999999999999\n",
      "Question 22\n",
      "Misses 22 0.3749944497268937\n",
      "Hits 22 0.7181116954530434\n",
      "Score 22 1.0\n",
      "Hits + Misses 22 1.0\n",
      "Question 23\n",
      "Misses 23 0.3033403991172734\n",
      "Hits 23 0.7607352871837487\n",
      "Score 23 1.0\n",
      "Hits + Misses 23 1.0\n",
      "Question 24\n",
      "Misses 24 -0.0003743520251604119\n",
      "Hits 24 0.8775310062437778\n",
      "Score 24 1.0\n",
      "Hits + Misses 24 1.0\n",
      "Question 25\n",
      "Misses 25 0.2498190511639892\n",
      "Hits 25 0.7401970314985438\n",
      "Score 25 1.0\n",
      "Hits + Misses 25 0.8660047979399312\n",
      "Question 26\n",
      "Misses 26 0.2871204059036024\n",
      "Hits 26 0.8509679731879097\n",
      "Score 26 0.9999999999999999\n",
      "Hits + Misses 26 0.9999999999999999\n",
      "Question 27\n",
      "Misses 27 0.35319147883188357\n",
      "Hits 27 0.8849729599923005\n",
      "Score 27 1.0\n",
      "Hits + Misses 27 0.9741552727594717\n",
      "Question 28\n",
      "Misses 28 0.19513022253057555\n",
      "Hits 28 0.5901951228898104\n",
      "Score 28 1.0\n",
      "Hits + Misses 28 0.9186342092422286\n",
      "Question 29\n",
      "Question 29 not in the dataset\n",
      "Question 30\n",
      "Misses 30 0.587419483722544\n",
      "Hits 30 0.3802152061443783\n",
      "Score 30 1.0\n",
      "Hits + Misses 30 0.9527694257787926\n",
      "Question 31\n",
      "Misses 31 0.9994388477467346\n",
      "Hits 31 -0.801899178443154\n",
      "Score 31 1.0\n",
      "Hits + Misses 31 0.9916132123508643\n",
      "Question 32\n",
      "Misses 32 0.9669130451752608\n",
      "Hits 32 -0.9021187371763315\n",
      "Score 32 1.0\n",
      "Hits + Misses 32 0.953927286315582\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 DROP\n",
    "print(\"DROP\")\n",
    "corr_hit_miss(drop_df, \"Model\")\n",
    "#2 ZEROS\n",
    "print(\"ZEROS\")\n",
    "corr_hit_miss(zero_df, \"Model\")\n",
    "#3.1 MEAN\n",
    "print(\"MEAN\")\n",
    "corr_hit_miss(mean_df, \"Model\")\n",
    "#3.2 MEDIAN\n",
    "print(\"MEDIAN\")\n",
    "corr_hit_miss(median_df, \"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP\n",
      "Model dataset\n",
      "Question1\n",
      "Accuracy1 0.3162468068852099\n",
      "Missrate1 0.9185820543563346\n",
      "Between Accuracy and Missrate1 -0.9999999999999998\n",
      "Question2\n",
      "Accuracy2 0.36524668161993307\n",
      "Missrate2 0.8360396173257485\n",
      "Between Accuracy and Missrate2 -1.0\n",
      "Question3\n",
      "Accuracy3 0.5060104464870424\n",
      "Missrate3 0.9684670065139164\n",
      "Between Accuracy and Missrate3 -1.0\n",
      "Question4\n",
      "Accuracy4 0.7545371164659278\n",
      "Missrate4 0.9485347438097929\n",
      "Between Accuracy and Missrate4 -1.0\n",
      "Question5\n",
      "Accuracy5 0.5763314337760771\n",
      "Missrate5 0.9209683157837184\n",
      "Between Accuracy and Missrate5 -1.0\n",
      "Question6\n",
      "Accuracy6 0.8177252508422692\n",
      "Missrate6 0.8857300985609566\n",
      "Between Accuracy and Missrate6 -1.0\n",
      "Question7\n",
      "Accuracy7 -0.08052619098944436\n",
      "Missrate7 0.479381626698205\n",
      "Between Accuracy and Missrate7 -0.9999999999999996\n",
      "Question8\n",
      "Accuracy8 0.5578131825513736\n",
      "Missrate8 0.8960870493753768\n",
      "Between Accuracy and Missrate8 -1.0\n",
      "Question9\n",
      "Accuracy9 0.5784152997841773\n",
      "Missrate9 0.6507608623544796\n",
      "Between Accuracy and Missrate9 -1.0\n",
      "Question10\n",
      "Accuracy10 0.769722881338787\n",
      "Missrate10 0.6980029617281656\n",
      "Between Accuracy and Missrate10 -1.0\n",
      "Question11\n",
      "Accuracy11 0.6159248847833961\n",
      "Missrate11 0.6575900544133535\n",
      "Between Accuracy and Missrate11 -1.0\n",
      "Question12\n",
      "Accuracy12 0.48157241446609245\n",
      "Missrate12 0.6059382952401673\n",
      "Between Accuracy and Missrate12 -0.9999999999999998\n",
      "Question13\n",
      "Accuracy13 0.47617325620972695\n",
      "Missrate13 0.5297140002808847\n",
      "Between Accuracy and Missrate13 -0.9999999999999998\n",
      "Question14\n",
      "Accuracy14 0.4722493831536771\n",
      "Missrate14 0.833826850726904\n",
      "Between Accuracy and Missrate14 -1.0\n",
      "Question15\n",
      "Accuracy15 0.4530291097967732\n",
      "Missrate15 0.7835355868160936\n",
      "Between Accuracy and Missrate15 -1.0\n",
      "Question16\n",
      "Accuracy16 0.3872311670476326\n",
      "Missrate16 0.9586673365672534\n",
      "Between Accuracy and Missrate16 -1.0\n",
      "Question17\n",
      "Accuracy17 0.4796489371634181\n",
      "Missrate17 0.9017174250615302\n",
      "Between Accuracy and Missrate17 -0.9999999999999998\n",
      "Question18\n",
      "Accuracy18 0.5491690919214156\n",
      "Missrate18 0.4783838310134471\n",
      "Between Accuracy and Missrate18 -1.0\n",
      "Question19\n",
      "Accuracy19 0.6822612069346996\n",
      "Missrate19 0.5494942171073508\n",
      "Between Accuracy and Missrate19 -1.0\n",
      "Question20\n",
      "Accuracy20 0.7134404711909329\n",
      "Missrate20 0.4647298069654561\n",
      "Between Accuracy and Missrate20 -0.9999999999999994\n",
      "Question21\n",
      "Accuracy21 0.5962770670342239\n",
      "Missrate21 0.3123605042733147\n",
      "Between Accuracy and Missrate21 -1.0\n",
      "Question22\n",
      "Accuracy22 0.557844896971231\n",
      "Missrate22 0.9170645070702464\n",
      "Between Accuracy and Missrate22 -0.9999999999999996\n",
      "Question23\n",
      "Accuracy23 0.28847974552262734\n",
      "Missrate23 0.7934161412637963\n",
      "Between Accuracy and Missrate23 -1.0\n",
      "Question24\n",
      "Accuracy24 0.5129483637035516\n",
      "Missrate24 0.6830627020493607\n",
      "Between Accuracy and Missrate24 -1.0\n",
      "Question25\n",
      "Accuracy25 0.5810162303240021\n",
      "Missrate25 0.7761232908864321\n",
      "Between Accuracy and Missrate25 -0.8657884781133179\n",
      "Question26\n",
      "Accuracy26 0.6658437550840822\n",
      "Missrate26 0.8030315262909196\n",
      "Between Accuracy and Missrate26 -1.0\n",
      "Question27\n",
      "Accuracy27 0.7043817467719033\n",
      "Missrate27 0.7300153040352372\n",
      "Between Accuracy and Missrate27 -0.5439158179357951\n",
      "Question28\n",
      "Accuracy28 0.7563401184824782\n",
      "Missrate28 0.8363405130312567\n",
      "Between Accuracy and Missrate28 -0.9743115609772248\n",
      "Question29\n",
      "Question 29 not in the dataset\n",
      "Question30\n",
      "Accuracy30 1.0\n",
      "Missrate30 0.9779398230263142\n",
      "Between Accuracy and Missrate30 -0.9993741627144969\n",
      "Question31\n",
      "Accuracy31 0.8917283265220534\n",
      "Missrate31 0.9113326128462664\n",
      "Between Accuracy and Missrate31 -0.9458637115286935\n",
      "Question32\n",
      "Accuracy32 0.8543888480266382\n",
      "Missrate32 0.8896120593012142\n",
      "Between Accuracy and Missrate32 -0.9340096252759621\n",
      "\n",
      "\n",
      "ZEROS\n",
      "Model dataset\n",
      "Question1\n",
      "Accuracy1 0.4689606861780328\n",
      "Missrate1 0.7994871803969653\n",
      "Between Accuracy and Missrate1 -0.7943393567310688\n",
      "Question2\n",
      "Accuracy2 0.585469241036895\n",
      "Missrate2 0.8880396086564498\n",
      "Between Accuracy and Missrate2 -0.9167674294358366\n",
      "Question3\n",
      "Accuracy3 0.5628633819743478\n",
      "Missrate3 0.8963467395568544\n",
      "Between Accuracy and Missrate3 -1.0\n",
      "Question4\n",
      "Accuracy4 0.6592599773714932\n",
      "Missrate4 0.9029200269684677\n",
      "Between Accuracy and Missrate4 -0.9999999999999997\n",
      "Question5\n",
      "Accuracy5 0.6777146409589332\n",
      "Missrate5 0.8354920668484096\n",
      "Between Accuracy and Missrate5 -0.9999999999999998\n",
      "Question6\n",
      "Accuracy6 0.7508286857422656\n",
      "Missrate6 0.785212972506915\n",
      "Between Accuracy and Missrate6 -0.9999999999999997\n",
      "Question7\n",
      "Accuracy7 0.5233809560990952\n",
      "Missrate7 0.8016593400578298\n",
      "Between Accuracy and Missrate7 -0.9363104526020702\n",
      "Question8\n",
      "Accuracy8 0.4843372898898232\n",
      "Missrate8 0.8861750670855052\n",
      "Between Accuracy and Missrate8 -1.0\n",
      "Question9\n",
      "Accuracy9 0.7200768959614217\n",
      "Missrate9 0.8593250308464023\n",
      "Between Accuracy and Missrate9 -0.9999999999999999\n",
      "Question10\n",
      "Accuracy10 0.6779368812070478\n",
      "Missrate10 0.8764355478436787\n",
      "Between Accuracy and Missrate10 -1.0\n",
      "Question11\n",
      "Accuracy11 0.5949157639958734\n",
      "Missrate11 0.7504691960078878\n",
      "Between Accuracy and Missrate11 -0.9999999999999998\n",
      "Question12\n",
      "Accuracy12 0.5365179338951288\n",
      "Missrate12 0.8391966924027097\n",
      "Between Accuracy and Missrate12 -1.0\n",
      "Question13\n",
      "Accuracy13 0.8822331894150323\n",
      "Missrate13 0.9248040785608476\n",
      "Between Accuracy and Missrate13 0.23389872016153723\n",
      "Question14\n",
      "Accuracy14 0.32804720043945024\n",
      "Missrate14 0.9503456858546416\n",
      "Between Accuracy and Missrate14 -1.0\n",
      "Question15\n",
      "Accuracy15 0.37382554130446555\n",
      "Missrate15 0.9127698099892496\n",
      "Between Accuracy and Missrate15 -1.0\n",
      "Question16\n",
      "Accuracy16 0.10479362321627551\n",
      "Missrate16 0.9594297895720036\n",
      "Between Accuracy and Missrate16 -0.9999999999999998\n",
      "Question17\n",
      "Accuracy17 0.31562258943719945\n",
      "Missrate17 0.9359923710603857\n",
      "Between Accuracy and Missrate17 -1.0\n",
      "Question18\n",
      "Accuracy18 0.8991807130381007\n",
      "Missrate18 0.9114416255081588\n",
      "Between Accuracy and Missrate18 -0.0337176303561419\n",
      "Question19\n",
      "Accuracy19 0.8684926019917845\n",
      "Missrate19 0.8873245538922282\n",
      "Between Accuracy and Missrate19 0.11116034208800217\n",
      "Question20\n",
      "Accuracy20 0.8484282584862106\n",
      "Missrate20 0.8345425061742296\n",
      "Between Accuracy and Missrate20 0.03244804131066645\n",
      "Question21\n",
      "Accuracy21 0.8989790157436732\n",
      "Missrate21 0.9410894013972287\n",
      "Between Accuracy and Missrate21 0.26175520599980795\n",
      "Question22\n",
      "Accuracy22 0.7270466953868159\n",
      "Missrate22 0.753474776202509\n",
      "Between Accuracy and Missrate22 -1.0\n",
      "Question23\n",
      "Accuracy23 0.6661084363431284\n",
      "Missrate23 0.8113006455177051\n",
      "Between Accuracy and Missrate23 -1.0\n",
      "Question24\n",
      "Accuracy24 0.8767602535808928\n",
      "Missrate24 0.8792834792231115\n",
      "Between Accuracy and Missrate24 -0.04234293898883222\n",
      "Question25\n",
      "Accuracy25 0.9340346201718792\n",
      "Missrate25 0.919004509450041\n",
      "Between Accuracy and Missrate25 0.5289176395108891\n",
      "Question26\n",
      "Accuracy26 0.8972786039543595\n",
      "Missrate26 0.8161533800936625\n",
      "Between Accuracy and Missrate26 0.1388414925605159\n",
      "Question27\n",
      "Accuracy27 0.8922004037365548\n",
      "Missrate27 0.8797141789683376\n",
      "Between Accuracy and Missrate27 0.1361390775320526\n",
      "Question28\n",
      "Accuracy28 0.858388488271121\n",
      "Missrate28 0.8924404339224797\n",
      "Between Accuracy and Missrate28 -0.07549650141126688\n",
      "Question29\n",
      "Question 29 not in the dataset\n",
      "Question30\n",
      "Accuracy30 0.9800166537581875\n",
      "Missrate30 0.9535382805866346\n",
      "Between Accuracy and Missrate30 -0.6891975130592217\n",
      "Question31\n",
      "Accuracy31 0.9825117279313468\n",
      "Missrate31 0.9883897178712135\n",
      "Between Accuracy and Missrate31 0.3386705651535406\n",
      "Question32\n",
      "Accuracy32 0.9790343300295246\n",
      "Missrate32 0.9933678137485944\n",
      "Between Accuracy and Missrate32 0.6157385615745892\n",
      "\n",
      "\n",
      "MEAN\n",
      "Model dataset\n",
      "Question1\n",
      "Accuracy1 0.48015205486954965\n",
      "Missrate1 0.7989012525028564\n",
      "Between Accuracy and Missrate1 -0.7936901007755705\n",
      "Question2\n",
      "Accuracy2 0.5861827789100691\n",
      "Missrate2 0.8874556263872634\n",
      "Between Accuracy and Missrate2 -0.9163181486710582\n",
      "Question3\n",
      "Accuracy3 0.5670503642865885\n",
      "Missrate3 0.8959189822576711\n",
      "Between Accuracy and Missrate3 -1.0\n",
      "Question4\n",
      "Accuracy4 0.6735649572826989\n",
      "Missrate4 0.9015707138948355\n",
      "Between Accuracy and Missrate4 -1.0\n",
      "Question5\n",
      "Accuracy5 0.6758347444103934\n",
      "Missrate5 0.8334861887630044\n",
      "Between Accuracy and Missrate5 -1.0\n",
      "Question6\n",
      "Accuracy6 0.7565001995409997\n",
      "Missrate6 0.779406788808932\n",
      "Between Accuracy and Missrate6 -0.9999999999999996\n",
      "Question7\n",
      "Accuracy7 0.5251807383836655\n",
      "Missrate7 0.8004902739085976\n",
      "Between Accuracy and Missrate7 -0.935964643813903\n",
      "Question8\n",
      "Accuracy8 0.4852965719127835\n",
      "Missrate8 0.8848147619732639\n",
      "Between Accuracy and Missrate8 -1.0\n",
      "Question9\n",
      "Accuracy9 0.7157809222499419\n",
      "Missrate9 0.8566844301877123\n",
      "Between Accuracy and Missrate9 -1.0\n",
      "Question10\n",
      "Accuracy10 0.6789549530383604\n",
      "Missrate10 0.8754915690894953\n",
      "Between Accuracy and Missrate10 -1.0\n",
      "Question11\n",
      "Accuracy11 0.6028285647497377\n",
      "Missrate11 0.7456443659630476\n",
      "Between Accuracy and Missrate11 -0.9999999999999998\n",
      "Question12\n",
      "Accuracy12 0.5319169991671783\n",
      "Missrate12 0.8368305919878448\n",
      "Between Accuracy and Missrate12 -1.0\n",
      "Question13\n",
      "Accuracy13 0.5399223983960965\n",
      "Missrate13 0.8510656948944929\n",
      "Between Accuracy and Missrate13 -0.9999999999999993\n",
      "Question14\n",
      "Accuracy14 0.3356536756577617\n",
      "Missrate14 0.9501840116769029\n",
      "Between Accuracy and Missrate14 -0.9999999999999998\n",
      "Question15\n",
      "Accuracy15 0.37401395279189453\n",
      "Missrate15 0.9107866470933187\n",
      "Between Accuracy and Missrate15 -1.0\n",
      "Question16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy16 0.10579739099115076\n",
      "Missrate16 0.9592803938874235\n",
      "Between Accuracy and Missrate16 -1.0\n",
      "Question17\n",
      "Accuracy17 0.31479757525412255\n",
      "Missrate17 0.9348878833419126\n",
      "Between Accuracy and Missrate17 -1.0\n",
      "Question18\n",
      "Accuracy18 0.7672909630879019\n",
      "Missrate18 0.8639354183921659\n",
      "Between Accuracy and Missrate18 -0.9994307862466365\n",
      "Question19\n",
      "Accuracy19 0.6132460720773197\n",
      "Missrate19 0.7879090424269755\n",
      "Between Accuracy and Missrate19 -0.9999999999999999\n",
      "Question20\n",
      "Accuracy20 0.7708908319865329\n",
      "Missrate20 0.5726840283468102\n",
      "Between Accuracy and Missrate20 -1.0\n",
      "Question21\n",
      "Accuracy21 0.5959281013190307\n",
      "Missrate21 0.6960588806398837\n",
      "Between Accuracy and Missrate21 -1.0\n",
      "Question22\n",
      "Accuracy22 0.7313457723625\n",
      "Missrate22 0.7488730335383876\n",
      "Between Accuracy and Missrate22 -1.0\n",
      "Question23\n",
      "Accuracy23 0.6577240677082863\n",
      "Missrate23 0.8051922228381465\n",
      "Between Accuracy and Missrate23 -0.9999999999999997\n",
      "Question24\n",
      "Accuracy24 0.6967891971811913\n",
      "Missrate24 0.8290890446750498\n",
      "Between Accuracy and Missrate24 -1.0\n",
      "Question25\n",
      "Accuracy25 0.7491708721759187\n",
      "Missrate25 0.23007799914892207\n",
      "Between Accuracy and Missrate25 -0.9948118320267143\n",
      "Question26\n",
      "Accuracy26 0.7482253853853482\n",
      "Missrate26 0.6173697877061073\n",
      "Between Accuracy and Missrate26 -0.9998334392638393\n",
      "Question27\n",
      "Accuracy27 0.7889053897943482\n",
      "Missrate27 0.7903080979814758\n",
      "Between Accuracy and Missrate27 -0.49094476355638134\n",
      "Question28\n",
      "Accuracy28 0.6991718212926867\n",
      "Missrate28 0.8361646357130244\n",
      "Between Accuracy and Missrate28 -0.9773711909834234\n",
      "Question29\n",
      "Question 29 not in the dataset\n",
      "Question30\n",
      "Accuracy30 0.9792055927655501\n",
      "Missrate30 0.9506714292247566\n",
      "Between Accuracy and Missrate30 -0.675733284611842\n",
      "Question31\n",
      "Accuracy31 0.8610924221462848\n",
      "Missrate31 0.9918741008502882\n",
      "Between Accuracy and Missrate31 -0.9758358436505222\n",
      "Question32\n",
      "Accuracy32 0.9305822724741559\n",
      "Missrate32 0.9605103689459963\n",
      "Between Accuracy and Missrate32 -0.9665899798763022\n",
      "\n",
      "\n",
      "MEDIAN\n",
      "Model dataset\n",
      "Question1\n",
      "Accuracy1 0.4795710766727966\n",
      "Missrate1 0.7990029969311436\n",
      "Between Accuracy and Missrate1 -0.7938028654141157\n",
      "Question2\n",
      "Accuracy2 0.5866803458392182\n",
      "Missrate2 0.8875572245405456\n",
      "Between Accuracy and Missrate2 -0.9163963240244146\n",
      "Question3\n",
      "Accuracy3 0.5668671135704213\n",
      "Missrate3 0.8959933350729247\n",
      "Between Accuracy and Missrate3 -0.9999999999999999\n",
      "Question4\n",
      "Accuracy4 0.6733601349344717\n",
      "Missrate4 0.9018071396347317\n",
      "Between Accuracy and Missrate4 -0.9999999999999999\n",
      "Question5\n",
      "Accuracy5 0.6757996532312397\n",
      "Missrate5 0.8338371619731392\n",
      "Between Accuracy and Missrate5 -1.0\n",
      "Question6\n",
      "Accuracy6 0.7576253768640285\n",
      "Missrate6 0.7806237239541768\n",
      "Between Accuracy and Missrate6 -1.0\n",
      "Question7\n",
      "Accuracy7 0.5229586782310031\n",
      "Missrate7 0.8006937859828744\n",
      "Between Accuracy and Missrate7 -0.9360248165235305\n",
      "Question8\n",
      "Accuracy8 0.48681505605811703\n",
      "Missrate8 0.8850527376301984\n",
      "Between Accuracy and Missrate8 -1.0\n",
      "Question9\n",
      "Accuracy9 0.7154707310548296\n",
      "Missrate9 0.857391853080781\n",
      "Between Accuracy and Missrate9 -0.9999999999999999\n",
      "Question10\n",
      "Accuracy10 0.6790536725245334\n",
      "Missrate10 0.8756561246318019\n",
      "Between Accuracy and Missrate10 -0.9999999999999998\n",
      "Question11\n",
      "Accuracy11 0.5998143072433275\n",
      "Missrate11 0.7468234039158756\n",
      "Between Accuracy and Missrate11 -1.0\n",
      "Question12\n",
      "Accuracy12 0.5341623059797657\n",
      "Missrate12 0.8374206378893116\n",
      "Between Accuracy and Missrate12 -1.0\n",
      "Question13\n",
      "Accuracy13 0.5540943802573504\n",
      "Missrate13 0.8865799276484795\n",
      "Between Accuracy and Missrate13 -1.0\n",
      "Question14\n",
      "Accuracy14 0.335982540835191\n",
      "Missrate14 0.950212093583658\n",
      "Between Accuracy and Missrate14 -0.9999999999999999\n",
      "Question15\n",
      "Accuracy15 0.37469092334978477\n",
      "Missrate15 0.910841236633677\n",
      "Between Accuracy and Missrate15 -1.0\n",
      "Question16\n",
      "Accuracy16 0.10866510579149803\n",
      "Missrate16 0.959306352229702\n",
      "Between Accuracy and Missrate16 -1.0\n",
      "Question17\n",
      "Accuracy17 0.3164630599559391\n",
      "Missrate17 0.9349648948326684\n",
      "Between Accuracy and Missrate17 -1.0\n",
      "Question18\n",
      "Accuracy18 0.7609894880250349\n",
      "Missrate18 0.8564842318561078\n",
      "Between Accuracy and Missrate18 -1.0\n",
      "Question19\n",
      "Accuracy19 0.6316860819352349\n",
      "Missrate19 0.8133383627177893\n",
      "Between Accuracy and Missrate19 -1.0\n",
      "Question20\n",
      "Accuracy20 0.7734684232686944\n",
      "Missrate20 0.6077591124370407\n",
      "Between Accuracy and Missrate20 -1.0\n",
      "Question21\n",
      "Accuracy21 0.5759049345429786\n",
      "Missrate21 0.8874005710343815\n",
      "Between Accuracy and Missrate21 -0.9999999999999998\n",
      "Question22\n",
      "Accuracy22 0.7273706582445988\n",
      "Missrate22 0.7467456278392\n",
      "Between Accuracy and Missrate22 -1.0\n",
      "Question23\n",
      "Accuracy23 0.6594796300426703\n",
      "Missrate23 0.8072782612435396\n",
      "Between Accuracy and Missrate23 -1.0\n",
      "Question24\n",
      "Accuracy24 0.7038219518970174\n",
      "Missrate24 0.7561283958583118\n",
      "Between Accuracy and Missrate24 -1.0\n",
      "Question25\n",
      "Accuracy25 0.7177521581114777\n",
      "Missrate25 0.38105948871909506\n",
      "Between Accuracy and Missrate25 -0.9947305031295003\n",
      "Question26\n",
      "Accuracy26 0.7621201106777166\n",
      "Missrate26 0.6460276993140058\n",
      "Between Accuracy and Missrate26 -1.0\n",
      "Question27\n",
      "Accuracy27 0.7908091095390607\n",
      "Missrate27 0.7197437650871632\n",
      "Between Accuracy and Missrate27 -0.4953577162359569\n",
      "Question28\n",
      "Accuracy28 0.7050616611491709\n",
      "Missrate28 0.8431184178343593\n",
      "Between Accuracy and Missrate28 -0.9768951101679377\n",
      "Question29\n",
      "Question 29 not in the dataset\n",
      "Question30\n",
      "Accuracy30 0.9793611024779547\n",
      "Missrate30 0.9513857216344845\n",
      "Between Accuracy and Missrate30 -0.6788825923313818\n",
      "Question31\n",
      "Accuracy31 0.9106950170120675\n",
      "Missrate31 0.9948644577240016\n",
      "Between Accuracy and Missrate31 -0.9849453796464984\n",
      "Question32\n",
      "Accuracy32 0.9485492449992021\n",
      "Missrate32 0.9930110458712845\n",
      "Between Accuracy and Missrate32 -0.9751233235667252\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 DROP\n",
    "print(\"DROP\")\n",
    "corr_acc_missrate(drop_df, \"Model\")\n",
    "#2 ZEROS\n",
    "print(\"ZEROS\")\n",
    "corr_acc_missrate(zero_df, \"Model\")\n",
    "#3.1 MEAN\n",
    "print(\"MEAN\")\n",
    "corr_acc_missrate(mean_df, \"Model\")\n",
    "#3.2 MEDIAN\n",
    "print(\"MEDIAN\")\n",
    "corr_acc_missrate(median_df, \"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colmuns not found:  ['Accuracy29', 'Missrate29', 'Score29']\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    columns = ['Accuracy'+str(i+1), 'Missrate'+str(i+1), 'Score'+str(i+1)]\n",
    "    try:\n",
    "        # 1 DROP\n",
    "        drop_df.drop(columns, axis=1)\n",
    "\n",
    "        # 2 ZEROS\n",
    "        zero_df.drop(columns, axis=1)\n",
    "\n",
    "        # 3.1 MEAN\n",
    "        mean_df.drop(columns, axis=1)\n",
    "\n",
    "        # 3.2 MEDIAN\n",
    "        median_df.drop(columns, axis=1)\n",
    "    except KeyError:\n",
    "        print(\"Colmuns not found: \",columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar la limpieza y preparar los datos que se van a emplear para diseñar el modelo, se va a proceder con la separación entre las variables que se van a empelar para entrenar el modelo y la variable que se quiere predecir. Es decir, se va a diferenciar entre **X**, set con todas las variables excepto si una persona es disléxica o no, e **y**, set que contiene los valores corresondientes a la variable *Dyslexia*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#1 DROP\n",
    "y_drop_pre = drop_df['Dyslexia']\n",
    "X_drop_pre = drop_df.loc[:, drop_df.columns != 'Dyslexia']\n",
    "X_drop, X_test_drop, y_drop, y_test_drop = train_test_split(X_drop_pre, y_drop_pre, test_size=0.2, random_state=4)\n",
    "\n",
    "#2 ZEROS\n",
    "y_zero_pre = zero_df['Dyslexia']\n",
    "X_zero_pre = zero_df.loc[:, zero_df.columns != 'Dyslexia']\n",
    "X_zero, X_test_zero, y_zero, y_test_zero = train_test_split(X_zero_pre, y_zero_pre, test_size=0.2, random_state=4, stratify = y_zero_pre)\n",
    "\n",
    "#3.1 MEAN\n",
    "y_mean_pre = mean_df['Dyslexia']\n",
    "X_mean_pre = mean_df.loc[:, mean_df.columns != 'Dyslexia']\n",
    "X_mean, X_test_mean, y_mean, y_test_mean = train_test_split(X_mean_pre, y_mean_pre, test_size=0.2, random_state=4, stratify = y_mean_pre)\n",
    "\n",
    "#3.2 MEDIAN\n",
    "y_median_pre = median_df['Dyslexia']\n",
    "X_median_pre = median_df.loc[:, median_df.columns != 'Dyslexia']\n",
    "X_median, X_test_median, y_median, y_test_median = train_test_split(X_median_pre, y_median_pre, test_size=0.2, random_state=4, stratify = y_median_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a proceder a entrenar el modelo. Como se mencionó al inicio del documento se van a emplear cinco algoritmos distintos de Machine Learning, de los cuales se eligirá el que prediga los casos positivos y negativos.\n",
    "\n",
    "Antes de comenzar con el entrenamiento del modelo se van a definir varias funciones con el objetivo de simplificar el código:\n",
    "\n",
    "- `plot_confusion_matrix(cm, classes)`: toma como argumentos de entrada la matriz de confusión del modelo y los valores que se quieren evaluar, en este caso 0's y 1's. Mostrará por pantalla la representación de los aciertos y fallos comparando que casos se han predicho correctamente y cuales no.\n",
    "- `knn_accuracy(X_train, y_train, X_test, y_test, Ks)`: uno de los algoritmos de Machine Learning que se va a entrenar es K-Nearest Neighbors, por lo que es necesario escoger cuidadosamente el número de clusters con el que se va a entrenar el modelo. Mediante esta función, pasando como argumentos de entrada los datos usados para el train y el test y el máximo de clusters que se quieren probar, se imprimirá por pantalla la exactitud (*accuracy*) que tiene el modelo en función de los distintos valores de k\n",
    "- `k_fold_cv(X, y, n, model)`: K-fold  cross-validation se emplea como técnica de evaluación del modelo recursiva. Pasando como argumentos de entrada los datos, el modelo que se quiere testear y la cantidad de iteración que se van a realizar, la función va a dividir de diferente forma los datos n veces y calcular la media de los resultados obtenidos en cada iteración al final. Se ha especificado que devuelva la excatitud del modelo (*score*) y el F1-score de las dos clases, es decir, tanto de los 0's como de los 1's\n",
    "- `evaluate_model(X_train, y_train, X_test, y_test, model)`: esta función va a devolver distintas evaluaciones del modelo, como por ejemplo *Recall*, *Accuracy*, *Jaccard index* o *F1-score*, así como la representación de la matriz de confusión del modelo que se especifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, cmap='Blues')\n",
    "\n",
    "    #add value count to each cell\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 3.\n",
    "    \n",
    "    #labels value count\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #set axis labels\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "\n",
    "    #colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate nº clusters KNN\n",
    "def knn_accuracy(X_train, y_train, X_test, y_test, Ks):\n",
    "    \n",
    "    for n in range(1,Ks):\n",
    "        model = KNeighborsClassifier(n_neighbors=n).fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        acc = metrics.accuracy_score(y_test, y_hat)\n",
    "        print(f\"Value of k: {n} - Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(X, y, n, model):\n",
    "    kf = KFold(n_splits = n)\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    #accuracy\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index].values, X.iloc[test_index].values\n",
    "        y_train, y_test = y.iloc[train_index].values, y.iloc[test_index].values\n",
    "        #model prediction \n",
    "        y_hat = model.predict(X_test)\n",
    "        #evaluate the performance of a model (accuracy score)\n",
    "        score = model.score(X_test,y_test)\n",
    "        scores.append(score)\n",
    "          \n",
    "    return \"Accuracy: \"+str(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    #different evaluations\n",
    "    print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, model.predict(X_train)))\n",
    "    print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_hat))\n",
    "    print(\"F1 score: \", f1_score(y_test, y_hat))\n",
    "    print(\"Recall 0's: \", recall_score(y_test, y_hat, pos_label=0))\n",
    "    print(\"Recall 1's: \", recall_score(y_test, y_hat, pos_label=1))\n",
    "    print(\"Jaccard index 0's: \", jaccard_score(y_test, y_hat, pos_label = 0))\n",
    "    print(\"Jaccard index 1's: \", jaccard_score(y_test, y_hat, pos_label = 1))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #classification report\n",
    "    print (classification_report(y_test, y_hat))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_hat, labels=[0,1])\n",
    "    np.set_printoptions(precision = 2)\n",
    "\n",
    "    #plot confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=['No = 0','Yes = 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Drop Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_drop, y_drop\n",
    "# Values used to test the model: X_test_drop, y_test_drop\n",
    "\n",
    "# Data Standardization -> Good practice working with KNN (based on the distance)\n",
    "X_drop_KNN = preprocessing.StandardScaler().fit(X_drop).transform(X_drop.astype(float))\n",
    "X_test_drop_KNN = preprocessing.StandardScaler().fit(X_test_drop).transform(X_test_drop.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k: 1 - Accuracy: 0.70\n",
      "Value of k: 2 - Accuracy: 0.60\n",
      "Value of k: 3 - Accuracy: 0.40\n",
      "Value of k: 4 - Accuracy: 0.60\n",
      "Value of k: 5 - Accuracy: 0.60\n",
      "Value of k: 6 - Accuracy: 0.60\n",
      "Value of k: 7 - Accuracy: 0.70\n",
      "Value of k: 8 - Accuracy: 0.60\n",
      "Value of k: 9 - Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy(X_drop_KNN, y_drop, X_test_drop_KNN, y_test_drop, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "#Train Model and Predict  \n",
    "neigh_drop = KNeighborsClassifier(n_neighbors = k).fit(X_drop_KNN,y_drop)\n",
    "y_hat_drop_KNN = neigh_drop.predict(X_test_drop_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.725'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X_drop_KNN, y_drop, 10, neigh_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.7297297297297297\n",
      "Test set Accuracy:  0.6\n",
      "F1 score:  0.3333333333333333\n",
      "Recall 0's:  0.7142857142857143\n",
      "Recall 1's:  0.3333333333333333\n",
      "Jaccard index 0's:  0.5555555555555556\n",
      "Jaccard index 1's:  0.2\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.71      0.71         7\n",
      "         1.0       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.52      0.52      0.52        10\n",
      "weighted avg       0.60      0.60      0.60        10\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_drop_KNN, y_drop, X_test_drop_KNN, y_test_drop, neigh_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_zero, y_zero\n",
    "# Values used to test the model: X_test_zero, y_test_zero\n",
    "\n",
    "# Data Standardization -> Good practice working with KNN (based on the distance)\n",
    "X_zero_KNN = preprocessing.StandardScaler().fit(X_zero).transform(X_zero.astype(float))\n",
    "X_test_zero_KNN = preprocessing.StandardScaler().fit(X_test_zero).transform(X_test_zero.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k: 1 - Accuracy: 0.52\n",
      "Value of k: 2 - Accuracy: 0.59\n",
      "Value of k: 3 - Accuracy: 0.59\n",
      "Value of k: 4 - Accuracy: 0.56\n",
      "Value of k: 5 - Accuracy: 0.59\n",
      "Value of k: 6 - Accuracy: 0.74\n",
      "Value of k: 7 - Accuracy: 0.59\n",
      "Value of k: 8 - Accuracy: 0.63\n",
      "Value of k: 9 - Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy(X_zero_KNN, y_zero, X_test_zero_KNN, y_test_zero, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "#Train Model and Predict  \n",
    "neigh_zero = KNeighborsClassifier(n_neighbors = k).fit(X_zero_KNN,y_zero)\n",
    "y_hat_zero_KNN = neigh_zero.predict(X_test_zero_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.6954545454545455'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X_zero_KNN, y_zero, 10, neigh_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.6952380952380952\n",
      "Test set Accuracy:  0.5925925925925926\n",
      "F1 score:  0.56\n",
      "Recall 0's:  0.8181818181818182\n",
      "Recall 1's:  0.4375\n",
      "Jaccard index 0's:  0.45\n",
      "Jaccard index 1's:  0.3888888888888889\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.82      0.62        11\n",
      "         1.0       0.78      0.44      0.56        16\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.64      0.63      0.59        27\n",
      "weighted avg       0.66      0.59      0.58        27\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_zero_KNN, y_zero, X_test_zero_KNN, y_test_zero, neigh_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_mean, y_mean\n",
    "# Values used to test the model: X_test_mean, y_test_mean\n",
    "\n",
    "# Data Standardization -> Good practice working with KNN (based on the distance)\n",
    "X_mean_KNN = preprocessing.StandardScaler().fit(X_mean).transform(X_mean.astype(float))\n",
    "X_test_mean_KNN = preprocessing.StandardScaler().fit(X_test_mean).transform(X_test_mean.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k: 1 - Accuracy: 0.42\n",
      "Value of k: 2 - Accuracy: 0.38\n",
      "Value of k: 3 - Accuracy: 0.50\n",
      "Value of k: 4 - Accuracy: 0.42\n",
      "Value of k: 5 - Accuracy: 0.46\n",
      "Value of k: 6 - Accuracy: 0.50\n",
      "Value of k: 7 - Accuracy: 0.54\n",
      "Value of k: 8 - Accuracy: 0.50\n",
      "Value of k: 9 - Accuracy: 0.46\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy(X_mean_KNN, y_mean, X_test_mean_KNN, y_test_mean, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "#Train Model and Predict  \n",
    "neigh_mean = KNeighborsClassifier(n_neighbors = k).fit(X_mean_KNN,y_mean)\n",
    "y_hat_mean_KNN = neigh_mean.predict(X_test_mean_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.72'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X_mean_KNN, y_mean, 10, neigh_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.72\n",
      "Test set Accuracy:  0.38461538461538464\n",
      "F1 score:  0.1111111111111111\n",
      "Recall 0's:  0.8181818181818182\n",
      "Recall 1's:  0.06666666666666667\n",
      "Jaccard index 0's:  0.36\n",
      "Jaccard index 1's:  0.058823529411764705\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.82      0.53        11\n",
      "         1.0       0.33      0.07      0.11        15\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.36      0.44      0.32        26\n",
      "weighted avg       0.36      0.38      0.29        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_mean_KNN, y_mean, X_test_mean_KNN, y_test_mean, neigh_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_median, y_median\n",
    "# Values used to test the model: X_test_median, y_test_median\n",
    "\n",
    "# Data Standardization -> Good practice working with KNN (based on the distance)\n",
    "X_median_KNN = preprocessing.StandardScaler().fit(X_median).transform(X_median.astype(float))\n",
    "X_test_median_KNN = preprocessing.StandardScaler().fit(X_test_median).transform(X_test_median.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k: 1 - Accuracy: 0.46\n",
      "Value of k: 2 - Accuracy: 0.46\n",
      "Value of k: 3 - Accuracy: 0.58\n",
      "Value of k: 4 - Accuracy: 0.46\n",
      "Value of k: 5 - Accuracy: 0.50\n",
      "Value of k: 6 - Accuracy: 0.58\n",
      "Value of k: 7 - Accuracy: 0.62\n",
      "Value of k: 8 - Accuracy: 0.62\n",
      "Value of k: 9 - Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy(X_median_KNN, y_median, X_test_median_KNN, y_test_median, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "#Train Model and Predict  \n",
    "neigh_median = KNeighborsClassifier(n_neighbors = k).fit(X_median_KNN,y_median)\n",
    "y_hat_median_KNN = neigh_median.predict(X_test_median_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.6918181818181819'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X_median_KNN, y_median, 10, neigh_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.693069306930693\n",
      "Test set Accuracy:  0.46153846153846156\n",
      "F1 score:  0.2222222222222222\n",
      "Recall 0's:  0.9090909090909091\n",
      "Recall 1's:  0.13333333333333333\n",
      "Jaccard index 0's:  0.4166666666666667\n",
      "Jaccard index 1's:  0.125\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.91      0.59        11\n",
      "         1.0       0.67      0.13      0.22        15\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.55      0.52      0.41        26\n",
      "weighted avg       0.57      0.46      0.38        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_median_KNN, y_median, X_test_median_KNN, y_test_median, neigh_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Drop Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_drop, y_drop\n",
    "# Values used to test the model: X_test_drop, y_test_drop\n",
    "\n",
    "# Data Standardization (algorithm based on the distance)\n",
    "X_drop_LR = preprocessing.StandardScaler().fit(X_drop).transform(X_drop.astype(float))\n",
    "X_test_drop_LR = preprocessing.StandardScaler().fit(X_test_drop).transform(X_test_drop.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict  \n",
    "LR_drop = LogisticRegression(C=0.01, solver='liblinear').fit(X_drop_LR,y_drop)\n",
    "y_hat_drop_LR = LR_drop.predict(X_test_drop_LR)\n",
    "\n",
    "# Predict the probability of each class for a given input\n",
    "y_hat_prob_drop_LR = LR_drop.predict_proba(X_test_drop_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.8833333333333332'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_cv(X_drop_LR, y_drop, 10, LR_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.8918918918918919\n",
      "Test set Accuracy:  0.7\n",
      "F1 score:  0.5714285714285715\n",
      "Recall 0's:  0.7142857142857143\n",
      "Recall 1's:  0.6666666666666666\n",
      "Jaccard index 0's:  0.625\n",
      "Jaccard index 1's:  0.4\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.71      0.77         7\n",
      "         1.0       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.67      0.69      0.67        10\n",
      "weighted avg       0.73      0.70      0.71        10\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_drop_LR, y_drop, X_test_drop_LR, y_test_drop, LR_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_zero, y_zero\n",
    "# Values used to test the model: X_test_zero, y_test_zero\n",
    "\n",
    "# Data Standardization (algorithm based on the distance)\n",
    "X_zero_LR = preprocessing.StandardScaler().fit(X_zero).transform(X_zero.astype(float))\n",
    "X_test_zero_LR = preprocessing.StandardScaler().fit(X_test_zero).transform(X_test_zero.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict  \n",
    "LR_zero = LogisticRegression(C=0.01, solver='liblinear').fit(X_zero_LR,y_zero)\n",
    "y_hat_zero_LR = LR_zero.predict(X_test_zero_LR)\n",
    "\n",
    "# Predict the probability of each class for a given input\n",
    "y_hat_prob_zero_LR = LR_zero.predict_proba(X_test_zero_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.8285714285714286\n",
      "Test set Accuracy:  0.7037037037037037\n",
      "F1 score:  0.7142857142857143\n",
      "Recall 0's:  0.8181818181818182\n",
      "Recall 1's:  0.625\n",
      "Jaccard index 0's:  0.5294117647058824\n",
      "Jaccard index 1's:  0.5555555555555556\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.82      0.69        11\n",
      "         1.0       0.83      0.62      0.71        16\n",
      "\n",
      "    accuracy                           0.70        27\n",
      "   macro avg       0.72      0.72      0.70        27\n",
      "weighted avg       0.74      0.70      0.71        27\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_zero_LR, y_zero, X_test_zero_LR, y_test_zero, LR_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_mean, y_mean\n",
    "# Values used to test the model: X_test_mean, y_test_mean\n",
    "\n",
    "# Data Standardization (algorithm based on the distance)\n",
    "X_mean_LR = preprocessing.StandardScaler().fit(X_mean).transform(X_mean.astype(float))\n",
    "X_test_mean_LR = preprocessing.StandardScaler().fit(X_test_mean).transform(X_test_mean.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict  \n",
    "LR_mean = LogisticRegression(C=0.01, solver='liblinear').fit(X_mean_LR,y_mean)\n",
    "y_hat_mean_LR = LR_mean.predict(X_test_mean_LR)\n",
    "\n",
    "# Predict the probability of each class for a given input\n",
    "y_hat_prob_mean_LR = LR_mean.predict_proba(X_test_mean_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.8\n",
      "Test set Accuracy:  0.6923076923076923\n",
      "F1 score:  0.7142857142857142\n",
      "Recall 0's:  0.7272727272727273\n",
      "Recall 1's:  0.6666666666666666\n",
      "Jaccard index 0's:  0.5\n",
      "Jaccard index 1's:  0.5555555555555556\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.73      0.67        11\n",
      "         1.0       0.77      0.67      0.71        15\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.69      0.70      0.69        26\n",
      "weighted avg       0.70      0.69      0.69        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_mean_LR, y_mean, X_test_mean_LR, y_test_mean, LR_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_median, y_median\n",
    "# Values used to test the model: X_test_median, y_test_median\n",
    "\n",
    "# Data Standardization (algorithm based on the distance)\n",
    "X_median_LR = preprocessing.StandardScaler().fit(X_median).transform(X_median.astype(float))\n",
    "X_test_median_LR = preprocessing.StandardScaler().fit(X_test_median).transform(X_test_median.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and Predict  \n",
    "LR_median = LogisticRegression(C=0.01, solver='liblinear').fit(X_median_LR,y_median)\n",
    "y_hat_median_LR = LR_median.predict(X_test_median_LR)\n",
    "\n",
    "# Predict the probability of each class for a given input\n",
    "y_hat_prob_median_LR = LR_median.predict_proba(X_test_median_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.801980198019802\n",
      "Test set Accuracy:  0.7307692307692307\n",
      "F1 score:  0.7586206896551724\n",
      "Recall 0's:  0.7272727272727273\n",
      "Recall 1's:  0.7333333333333333\n",
      "Jaccard index 0's:  0.5333333333333333\n",
      "Jaccard index 1's:  0.6111111111111112\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.73      0.70        11\n",
      "         1.0       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.73      0.73      0.73        26\n",
      "weighted avg       0.74      0.73      0.73        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_median_LR, y_median, X_test_median_LR, y_test_median, LR_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: svm.SVC(kernel='rbf')\n",
    "# kernel='rbf'\" where 'rbf' stands for radial basis function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Drop Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_drop, y_drop\n",
    "# Values used to test the model: X_test_drop, y_test_drop\n",
    "\n",
    "# Train Model and Predict \n",
    "svm_drop = svm.SVC(kernel='rbf').fit(X_drop, y_drop) \n",
    "y_hat_drop_SVM = svm_drop.predict(X_test_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.5945945945945946\n",
      "Test set Accuracy:  0.3\n",
      "F1 score:  0.4615384615384615\n",
      "Recall 0's:  0.0\n",
      "Recall 1's:  1.0\n",
      "Jaccard index 0's:  0.0\n",
      "Jaccard index 1's:  0.3\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.30      1.00      0.46         3\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.15      0.50      0.23        10\n",
      "weighted avg       0.09      0.30      0.14        10\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_drop, y_drop, X_test_drop, y_test_drop, svm_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_zero, y_zero\n",
    "# Values used to test the model: X_test_zero, y_test_zero\n",
    "\n",
    "# Train Model and Predict  \n",
    "svm_zero = svm.SVC(kernel='rbf').fit(X_zero, y_zero) \n",
    "y_hat_zero_SVM = svm_zero.predict(X_test_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.6761904761904762\n",
      "Test set Accuracy:  0.6296296296296297\n",
      "F1 score:  0.7222222222222223\n",
      "Recall 0's:  0.36363636363636365\n",
      "Recall 1's:  0.8125\n",
      "Jaccard index 0's:  0.2857142857142857\n",
      "Jaccard index 1's:  0.5652173913043478\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.36      0.44        11\n",
      "         1.0       0.65      0.81      0.72        16\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.61      0.59      0.58        27\n",
      "weighted avg       0.62      0.63      0.61        27\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_zero, y_zero, X_test_zero, y_test_zero, svm_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_mean, y_mean\n",
    "# Values used to test the model: X_test_mean, y_test_mean\n",
    "\n",
    "# Train Model and Predict  \n",
    "svm_mean = svm.SVC(kernel='rbf').fit(X_mean, y_mean) \n",
    "y_hat_mean_SVM = svm_mean.predict(X_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.65\n",
      "Test set Accuracy:  0.6538461538461539\n",
      "F1 score:  0.7692307692307693\n",
      "Recall 0's:  0.18181818181818182\n",
      "Recall 1's:  1.0\n",
      "Jaccard index 0's:  0.18181818181818182\n",
      "Jaccard index 1's:  0.625\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.18      0.31        11\n",
      "         1.0       0.62      1.00      0.77        15\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.81      0.59      0.54        26\n",
      "weighted avg       0.78      0.65      0.57        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_mean, y_mean, X_test_mean, y_test_mean, svm_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_median, y_median\n",
    "# Values used to test the model: X_test_median, y_test_median\n",
    "\n",
    "# Train Model and Predict  \n",
    "svm_median = svm.SVC(kernel='rbf').fit(X_median, y_median) \n",
    "y_hat_median_SVM = svm_median.predict(X_test_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.6732673267326733\n",
      "Test set Accuracy:  0.5769230769230769\n",
      "F1 score:  0.7027027027027029\n",
      "Recall 0's:  0.18181818181818182\n",
      "Recall 1's:  0.8666666666666667\n",
      "Jaccard index 0's:  0.15384615384615385\n",
      "Jaccard index 1's:  0.5416666666666666\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.18      0.27        11\n",
      "         1.0       0.59      0.87      0.70        15\n",
      "\n",
      "    accuracy                           0.58        26\n",
      "   macro avg       0.55      0.52      0.48        26\n",
      "weighted avg       0.55      0.58      0.52        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_median, y_median, X_test_median, y_test_median, svm_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Drop Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_drop, y_drop\n",
    "# Values used to test the model: X_test_drop, y_test_drop\n",
    "\n",
    "# Train Model and Predict \n",
    "rfc_drop = RandomForestClassifier(n_estimators = 30, max_depth = 7, min_samples_leaf = 6).fit(X_drop , y_drop)\n",
    "y_hat_drop_RF = rfc_drop.predict(X_test_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.918918918918919\n",
      "Test set Accuracy:  0.6\n",
      "F1 score:  0.5\n",
      "Recall 0's:  0.5714285714285714\n",
      "Recall 1's:  0.6666666666666666\n",
      "Jaccard index 0's:  0.5\n",
      "Jaccard index 1's:  0.3333333333333333\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.57      0.67         7\n",
      "         1.0       0.40      0.67      0.50         3\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.60      0.62      0.58        10\n",
      "weighted avg       0.68      0.60      0.62        10\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_drop, y_drop, X_test_drop, y_test_drop, rfc_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_zero, y_zero\n",
    "# Values used to test the model: X_test_zero, y_test_zero\n",
    "\n",
    "# Train Model and Predict  \n",
    "rfc_zero = RandomForestClassifier(n_estimators = 30, max_depth = 7, min_samples_leaf = 6).fit(X_zero , y_zero)\n",
    "y_hat_zero_RF = rfc_zero.predict(X_test_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.8761904761904762\n",
      "Test set Accuracy:  0.7407407407407407\n",
      "F1 score:  0.787878787878788\n",
      "Recall 0's:  0.6363636363636364\n",
      "Recall 1's:  0.8125\n",
      "Jaccard index 0's:  0.5\n",
      "Jaccard index 1's:  0.65\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.64      0.67        11\n",
      "         1.0       0.76      0.81      0.79        16\n",
      "\n",
      "    accuracy                           0.74        27\n",
      "   macro avg       0.73      0.72      0.73        27\n",
      "weighted avg       0.74      0.74      0.74        27\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_zero, y_zero, X_test_zero, y_test_zero, rfc_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_mean, y_mean\n",
    "# Values used to test the model: X_test_mean, y_test_mean\n",
    "\n",
    "# Train Model and Predict \n",
    "rfc_mean = RandomForestClassifier(n_estimators = 30, max_depth = 7, min_samples_leaf = 6).fit(X_mean , y_mean)\n",
    "y_hat_mean_RF = rfc_mean.predict(X_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.84\n",
      "Test set Accuracy:  0.7692307692307693\n",
      "F1 score:  0.7857142857142856\n",
      "Recall 0's:  0.8181818181818182\n",
      "Recall 1's:  0.7333333333333333\n",
      "Jaccard index 0's:  0.6\n",
      "Jaccard index 1's:  0.6470588235294118\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.82      0.75        11\n",
      "         1.0       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.77      0.78      0.77        26\n",
      "weighted avg       0.78      0.77      0.77        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_mean, y_mean, X_test_mean, y_test_mean, rfc_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_median, y_median\n",
    "# Values used to test the model: X_test_median, y_test_median\n",
    "\n",
    "# Train Model and Predict \n",
    "rfc_median = RandomForestClassifier(n_estimators = 30, max_depth = 7, min_samples_leaf = 6).fit(X_median , y_median)\n",
    "y_hat_median_RF = rfc_median.predict(X_test_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.8811881188118812\n",
      "Test set Accuracy:  0.6923076923076923\n",
      "F1 score:  0.7333333333333333\n",
      "Recall 0's:  0.6363636363636364\n",
      "Recall 1's:  0.7333333333333333\n",
      "Jaccard index 0's:  0.4666666666666667\n",
      "Jaccard index 1's:  0.5789473684210527\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.64      0.64        11\n",
      "         1.0       0.73      0.73      0.73        15\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.68      0.68      0.68        26\n",
      "weighted avg       0.69      0.69      0.69        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_median, y_median, X_test_median, y_test_median, rfc_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tree Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Drop Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_drop, y_drop\n",
    "# Values used to test the model: X_test_drop, y_test_drop\n",
    "\n",
    "# Train Model and Predict \n",
    "tree_drop = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 4).fit(X_drop, y_drop)\n",
    "y_hat_drop_tree = tree_drop.predict(X_test_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  1.0\n",
      "Test set Accuracy:  0.3\n",
      "F1 score:  0.36363636363636365\n",
      "Recall 0's:  0.14285714285714285\n",
      "Recall 1's:  0.6666666666666666\n",
      "Jaccard index 0's:  0.125\n",
      "Jaccard index 1's:  0.2222222222222222\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.14      0.22         7\n",
      "         1.0       0.25      0.67      0.36         3\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.38      0.40      0.29        10\n",
      "weighted avg       0.42      0.30      0.26        10\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_drop, y_drop, X_test_drop, y_test_drop, tree_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_zero, y_zero\n",
    "# Values used to test the model: X_test_zero, y_test_zero\n",
    "\n",
    "# Train Model and Predict \n",
    "tree_zero = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 4).fit(X_zero, y_zero)\n",
    "y_hat_zero_tree = tree_zero.predict(X_test_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.8476190476190476\n",
      "Test set Accuracy:  0.5185185185185185\n",
      "F1 score:  0.5806451612903225\n",
      "Recall 0's:  0.45454545454545453\n",
      "Recall 1's:  0.5625\n",
      "Jaccard index 0's:  0.2777777777777778\n",
      "Jaccard index 1's:  0.4090909090909091\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.45      0.43        11\n",
      "         1.0       0.60      0.56      0.58        16\n",
      "\n",
      "    accuracy                           0.52        27\n",
      "   macro avg       0.51      0.51      0.51        27\n",
      "weighted avg       0.53      0.52      0.52        27\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_zero, y_zero, X_test_zero, y_test_zero, tree_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_mean, y_mean\n",
    "# Values used to test the model: X_test_mean, y_test_mean\n",
    "\n",
    "# Train Model and Predict \n",
    "tree_mean = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 4).fit(X_mean, y_mean)\n",
    "y_hat_mean_tree = tree_mean.predict(X_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.81\n",
      "Test set Accuracy:  0.6153846153846154\n",
      "F1 score:  0.7058823529411765\n",
      "Recall 0's:  0.36363636363636365\n",
      "Recall 1's:  0.8\n",
      "Jaccard index 0's:  0.2857142857142857\n",
      "Jaccard index 1's:  0.5454545454545454\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.36      0.44        11\n",
      "         1.0       0.63      0.80      0.71        15\n",
      "\n",
      "    accuracy                           0.62        26\n",
      "   macro avg       0.60      0.58      0.58        26\n",
      "weighted avg       0.61      0.62      0.60        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_mean, y_mean, X_test_mean, y_test_mean, tree_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to train the model: X_median, y_median\n",
    "# Values used to test the model: X_test_median, y_test_median\n",
    "\n",
    "# Train Model and Predict \n",
    "tree_median = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 4).fit(X_median, y_median)\n",
    "y_hat_median_tree = tree_median.predict(X_test_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.7920792079207921\n",
      "Test set Accuracy:  0.6923076923076923\n",
      "F1 score:  0.7142857142857142\n",
      "Recall 0's:  0.7272727272727273\n",
      "Recall 1's:  0.6666666666666666\n",
      "Jaccard index 0's:  0.5\n",
      "Jaccard index 1's:  0.5555555555555556\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.73      0.67        11\n",
      "         1.0       0.77      0.67      0.71        15\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.69      0.70      0.69        26\n",
      "weighted avg       0.70      0.69      0.69        26\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(X_median, y_median, X_test_median, y_test_median, tree_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar como los resultados obtenidos dejan mucho que desear. Esto se debe a que al reducir los datos al número de casos positivos de disexia con los que contaba el dataset, no se tienen suficientes datos como para entrenar correctamente el modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b3ceb9cdc9e4988f0fdc2300d52460555128c53d0379f640b7e6e7ff57007f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
